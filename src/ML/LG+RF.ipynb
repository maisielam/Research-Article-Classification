{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import and preprocess the dataset**"
      ],
      "metadata": {
        "id": "X7wqcRSFS4UQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYDc5rJHP1Q0",
        "outputId": "6a75addb-00c5-49ed-dbe5-f8c7319fcc57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Is Physics Sick? [In Praise of Classical Physics]   \n",
            "1    Modern Mathematical Physics: what it should be?   \n",
            "2                                Topology in Physics   \n",
            "3       Contents of Physics Related E-Print Archives   \n",
            "4        Fundamental Dilemmas in Theoretical Physics   \n",
            "\n",
            "                                             authors  \\\n",
            "0                                     Hisham Ghassib   \n",
            "1                                     Ludwig Faddeev   \n",
            "2                                          R. Jackiw   \n",
            "3  E. R. Prakasan, Anil Kumar, Anil Sagar, Lalit ...   \n",
            "4                                     Hisham Ghassib   \n",
            "\n",
            "                                             summary             published  \\\n",
            "0  In this paper, it is argued that theoretical p...  2012-09-04T10:32:56Z   \n",
            "1  Personal view of author on goals and content o...  2000-02-08T13:13:00Z   \n",
            "2  The phenomenon of quantum number fractionaliza...  2005-03-15T16:00:59Z   \n",
            "3  The frontiers of physics related e-print archi...  2003-08-28T13:12:57Z   \n",
            "4  In this paper, we argue that there are foundat...  2014-05-22T07:49:09Z   \n",
            "\n",
            "                updated                                    link  \\\n",
            "0  2012-09-04T10:32:56Z        http://arxiv.org/abs/1209.0592v1   \n",
            "1  2000-02-10T10:14:56Z  http://arxiv.org/abs/math-ph/0002018v2   \n",
            "2  2005-03-15T16:00:59Z  http://arxiv.org/abs/math-ph/0503039v1   \n",
            "3  2003-08-28T13:12:57Z  http://arxiv.org/abs/physics/0308107v1   \n",
            "4  2014-05-22T07:49:09Z        http://arxiv.org/abs/1405.5530v1   \n",
            "\n",
            "                                  pdf_url  \\\n",
            "0        http://arxiv.org/pdf/1209.0592v1   \n",
            "1  http://arxiv.org/pdf/math-ph/0002018v2   \n",
            "2  http://arxiv.org/pdf/math-ph/0503039v1   \n",
            "3  http://arxiv.org/pdf/physics/0308107v1   \n",
            "4        http://arxiv.org/pdf/1405.5530v1   \n",
            "\n",
            "                                          categories             target  \n",
            "0                    physics.gen-ph, physics.hist-ph             physic  \n",
            "1                           math-ph, hep-th, math.MP  math-stats,physic  \n",
            "2  math-ph, cond-mat.mes-hall, math.MP, physics.c...  math-stats,physic  \n",
            "3                                    physics.data-an             physic  \n",
            "4                                    physics.hist-ph             physic  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet('/Users/tomorrowcute/DSCI521/MSDS_2024_2026/Winter_2025/DSCI521/Project/data_final.parquet')\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikZqdd2UP1Q3",
        "outputId": "c4fa7cc2-1cbf-49c4-d456-eee8d31d9e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              target\n",
            "0             physic\n",
            "1  math-stats,physic\n",
            "2  math-stats,physic\n",
            "3             physic\n",
            "4             physic\n",
            "5             physic\n",
            "6             physic\n",
            "7  math-stats,physic\n",
            "8  math-stats,physic\n",
            "9  math-stats,physic\n"
          ]
        }
      ],
      "source": [
        "print(df[['target']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ2CGKI6P1Q4",
        "outputId": "faa26f72-b72a-45a5-dcce-d2b0e1904eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Is Physics Sick? [In Praise of Classical Physics]   \n",
            "1    Modern Mathematical Physics: what it should be?   \n",
            "2                                Topology in Physics   \n",
            "3       Contents of Physics Related E-Print Archives   \n",
            "4        Fundamental Dilemmas in Theoretical Physics   \n",
            "\n",
            "                                             summary  \\\n",
            "0  In this paper, it is argued that theoretical p...   \n",
            "1  Personal view of author on goals and content o...   \n",
            "2  The phenomenon of quantum number fractionaliza...   \n",
            "3  The frontiers of physics related e-print archi...   \n",
            "4  In this paper, we argue that there are foundat...   \n",
            "\n",
            "                                            combined  \n",
            "0  Is Physics Sick? [In Praise of Classical Physi...  \n",
            "1  Modern Mathematical Physics: what it should be...  \n",
            "2  Topology in Physics The phenomenon of quantum ...  \n",
            "3  Contents of Physics Related E-Print Archives T...  \n",
            "4  Fundamental Dilemmas in Theoretical Physics In...  \n"
          ]
        }
      ],
      "source": [
        "df['combined'] = df['title'] + ' ' + df['summary']\n",
        "\n",
        "print(df[['title', 'summary', 'combined']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOIwBcbHP1Q4",
        "outputId": "13684c22-5cad-4a54-dd3f-ec793a60d580"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150171"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2hqLdX5P1Q4",
        "outputId": "964e48ef-7b65-426f-d7ea-1d8bb7f5cb03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/tomorrowcute/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/tomorrowcute/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK data (run once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the tokenizer, lemmatizer, stemmer\n",
        "wpt = WordPunctTokenizer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Create a stopwords set\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def normalized_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', ' ', text)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub(r'<.*?>+', ' ', text)\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', ' ', text)\n",
        "    tokens = wpt.tokenize(text)\n",
        "\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    lemma_stem_tokens = [stemmer.stem(lemmatizer.lemmatize(token)) for token in filtered_tokens]\n",
        "\n",
        "    cleaned_text = ' '.join(lemma_stem_tokens)\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgynr3FHP1Q5"
      },
      "outputs": [],
      "source": [
        "df['cleaned'] = df['combined'].apply(lambda x: normalized_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO4R8yMkP1Q5",
        "outputId": "791248d3-62b3-413a-899a-5651939f5130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     physic sick paper argu theoret physic akin org...\n",
            "1     modern mathemat physic person view author goal...\n",
            "2     topolog physic phenomenon quantum number fract...\n",
            "3     content physic relat e print archiv frontier p...\n",
            "4     fundament dilemma theoret physic paper argu fo...\n",
            "5     physic heavi quark select problem heavi quark ...\n",
            "6     linear collid prospect electroweak physic pros...\n",
            "7     topolog aspect gaug theori appear encyclopedia...\n",
            "8     p adic mathemat physic brief review select top...\n",
            "9     invari physic group theori short review herita...\n",
            "10    physic divers world spheric cow model physic t...\n",
            "11    quest understand relativist quantum physic dis...\n",
            "12    physic structur form physic field manifold pro...\n",
            "13    quantum glove physic inform slogan inform phys...\n",
            "14    b physic experi past year flavor physic made i...\n",
            "15    classic physic agre quantum physic quantum phe...\n",
            "16    space matter topolog old branch mathemat topol...\n",
            "17    method analyz pathway physic major physic educ...\n",
            "18    topolog electron liquid chern simon theori qua...\n",
            "19    physic flavor flavor physic summari talk inter...\n",
            "Name: cleaned, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df[\"cleaned\"].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iweMPARP1Q5",
        "outputId": "63e95556-3ba9-48d3-b7d2-5a883ff60b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['title', 'authors', 'summary', 'published', 'updated', 'link',\n",
            "       'pdf_url', 'categories', 'target', 'year', 'month', 'day', 'combined',\n",
            "       'cleaned'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOVgXb9TP1Q6",
        "outputId": "85669cea-74ae-4b7f-f5c7-bcdb5bd8914f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['physic', 'math-stats,physic', 'cs,physic', 'cs,eess', 'cs',\n",
              "       'math-stats', 'bio,math-stats,physic', 'cs,math-stats,physic',\n",
              "       'cs,math-stats', 'bio', 'econ-qfin,physic', 'bio,physic',\n",
              "       'bio,cs,physic', 'cs,eess,physic', 'bio,cs',\n",
              "       'econ-qfin,math-stats', 'econ-qfin', 'cs,eess,math-stats',\n",
              "       'bio,math-stats', 'bio,cs,math-stats', 'bio,econ-qfin,math-stats',\n",
              "       'bio,cs,math-stats,physic', 'bio,cs,eess,physic', 'bio,cs,eess',\n",
              "       'eess', 'eess,physic', 'cs,econ-qfin,math-stats', 'bio,eess',\n",
              "       'cs,econ-qfin,physic', 'bio,cs,eess,math-stats', 'eess,math-stats',\n",
              "       'bio,econ-qfin,physic', 'bio,eess,math-stats',\n",
              "       'eess,math-stats,physic', 'cs,econ-qfin,math-stats,physic',\n",
              "       'bio,cs,eess,math-stats,physic', 'bio,econ-qfin,math-stats,physic',\n",
              "       'bio,eess,physic', 'cs,econ-qfin', 'cs,eess,math-stats,physic',\n",
              "       'bio,cs,econ-qfin,physic', 'cs,econ-qfin,eess', 'bio,cs,econ-qfin',\n",
              "       'cs,econ-qfin,eess,math-stats', 'bio,econ-qfin',\n",
              "       'econ-qfin,math-stats,physic', 'cs,econ-qfin,eess,physic',\n",
              "       'econ-qfin,eess', 'econ-qfin,eess,math-stats',\n",
              "       'econ-qfin,eess,math-stats,physic',\n",
              "       'cs,econ-qfin,eess,math-stats,physic',\n",
              "       'bio,eess,math-stats,physic'], dtype=object)"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"target\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing multi-label encoding for the target column. This method for multi-label classification, where each data point may belong to multiple categories."
      ],
      "metadata": {
        "id": "g1J9x3CaSfRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaOoqzDhP1Q6",
        "outputId": "2ce6b2a7-a606-4462-b0dd-6c362e7fc331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique individual labels: ['physic' 'math-stats' 'cs' 'eess' 'bio' 'econ-qfin']\n",
            "Mapping: {'bio': 0, 'cs': 1, 'econ-qfin': 2, 'eess': 3, 'math-stats': 4, 'physic': 5}\n",
            "              target target_encoded\n",
            "0             physic            [5]\n",
            "1  math-stats,physic         [4, 5]\n",
            "2  math-stats,physic         [4, 5]\n",
            "3             physic            [5]\n",
            "4             physic            [5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/0y/bq59rz2n4zxfzszy9jqtf5d80000gn/T/ipykernel_3458/1099691599.py:2: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
            "  unique_labels = pd.unique(all_labels)\n"
          ]
        }
      ],
      "source": [
        "all_labels = [label.strip() for entry in df['target'].dropna() for label in entry.split(',')]\n",
        "unique_labels = pd.unique(all_labels)\n",
        "print(\"Unique individual labels:\", unique_labels)\n",
        "\n",
        "# Create a mapping from each unique label to an integer.\n",
        "mapping = {label: idx for idx, label in enumerate(sorted(unique_labels))}\n",
        "print(\"Mapping:\", mapping)\n",
        "\n",
        "# Define a function to encode a row (split by comma and mapping each label)\n",
        "def encode_labels(row):\n",
        "    labels = [x.strip() for x in row.split(',')]\n",
        "    encoded = [mapping[label] for label in labels if label in mapping]\n",
        "    return encoded\n",
        "\n",
        "# Apply the function to create a new column \"target_encoded\"\n",
        "df['target_encoded'] = df['target'].apply(encode_labels)\n",
        "\n",
        "# Display the first few rows with original and encoded target values.\n",
        "print(df[['target', 'target_encoded']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frwlY5h8P1Q6",
        "outputId": "b7d1c024-f2a6-495a-b1c7-2e14de684e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       [5]\n",
            "1    [4, 5]\n",
            "2    [4, 5]\n",
            "3       [5]\n",
            "4       [5]\n",
            "5       [5]\n",
            "6       [5]\n",
            "7    [4, 5]\n",
            "8    [4, 5]\n",
            "9    [4, 5]\n",
            "Name: target_encoded, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df[\"target_encoded\"].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6Brnce_P1Q6",
        "outputId": "d3c998e6-ff66-47ee-9866-4db3defbf8ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequency of each encoded label (numeric): {0: 10371, 1: 56996, 2: 12432, 3: 9866, 4: 55456, 5: 54223}\n",
            "Frequency of each label (names): {'bio': 10371, 'cs': 56996, 'econ-qfin': 12432, 'eess': 9866, 'math-stats': 55456, 'physic': 54223}\n"
          ]
        }
      ],
      "source": [
        "#See frequency of each label\n",
        "import numpy as np\n",
        "# Flatten all encoded labels into a single array.\n",
        "all_encoded = np.concatenate(df['target_encoded'].values)\n",
        "\n",
        "# Get unique encoded labels and their counts.\n",
        "unique_encoded, counts = np.unique(all_encoded, return_counts=True)\n",
        "mapping_count = dict(zip(unique_encoded, counts))\n",
        "print(\"Frequency of each encoded label (numeric):\", mapping_count)\n",
        "\n",
        "# The frequencies with the original label names,\n",
        "# Create an inverse mapping from integer to label.\n",
        "inverse_mapping = {v: k for k, v in mapping.items()}\n",
        "mapping_count_named = {inverse_mapping[k]: v for k, v in mapping_count.items()}\n",
        "print(\"Frequency of each label (names):\", mapping_count_named)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the data before training model**"
      ],
      "metadata": {
        "id": "bPpldWKrQhr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2CyZfUpP1Q6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"combined\"]\n",
        "y = df[\"target_encoded\"]\n",
        "\n",
        "# 1. Split the data:\n",
        "# First, split 10% for testing.\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "# Then, split the remaining 90% into training (80% total) and validation (10%).\n",
        "# Get a validation set that is 10% of the entire data, use test_size=1/9\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1/9, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv-hKeInP1Q6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# 2. TF-IDF Transformation:\n",
        "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf   = tfidf.transform(X_val)\n",
        "X_test_tfidf  = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keqzK81CP1Q6"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "# 3. Dimensionality Reduction with Truncated SVD (LSA):\n",
        "svd = TruncatedSVD(n_components=300, random_state=42)\n",
        "normalizer = Normalizer(copy=False)\n",
        "lsa = make_pipeline(svd, normalizer)\n",
        "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
        "X_val_lsa   = lsa.transform(X_val_tfidf)\n",
        "X_test_lsa  = lsa.transform(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "246M0JyzP1Q6",
        "outputId": "c4344b40-081c-4bb7-ee14-8748fc77b07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels: [0 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "# 4. Convert multi-label target representation into binary matrices:\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train_bin = mlb.fit_transform(y_train)\n",
        "y_val_bin  = mlb.transform(y_val)\n",
        "y_test_bin  = mlb.transform(y_test)\n",
        "print(\"Labels:\", mlb.classes_)  # Shows the order of labels in the binary matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Logistic Regression Model**"
      ],
      "metadata": {
        "id": "t-nSw7p7QsmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdmzMFd7P1Q6",
        "outputId": "595a7088-7c0d-48f4-d7b9-60444f576b13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                                 max_iter=1000,\n",
              "                                                 random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneVsRestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                                 max_iter=1000,\n",
              "                                                 random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
              "                                                 max_iter=1000,\n",
              "                                                 random_state=42))"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# 5. Train a multi-label classifier using OneVsRestClassifier with Logistic Regression:\n",
        "model = OneVsRestClassifier(\n",
        "    LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
        ")\n",
        "model.fit(X_train_lsa, y_train_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChGrI6jgP1Q7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# 6. Predict on training, validation, and test data:\n",
        "y_pred_train = model.predict(X_train_lsa)\n",
        "y_pred_val   = model.predict(X_val_lsa)\n",
        "y_pred_test  = model.predict(X_test_lsa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWZaGsh3P1Q7",
        "outputId": "daa1569e-9358-4ae7-cf60-08423dbdc147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.88      0.54      8326\n",
            "           1       0.82      0.88      0.85     45400\n",
            "           2       0.54      0.92      0.68      9907\n",
            "           3       0.32      0.88      0.47      7911\n",
            "           4       0.76      0.82      0.79     44445\n",
            "           5       0.83      0.86      0.84     43432\n",
            "\n",
            "   micro avg       0.69      0.86      0.76    159421\n",
            "   macro avg       0.61      0.87      0.70    159421\n",
            "weighted avg       0.74      0.86      0.78    159421\n",
            " samples avg       0.76      0.89      0.79    159421\n",
            "\n",
            "=== Test Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.85      0.52      1027\n",
            "           1       0.83      0.88      0.85      5819\n",
            "           2       0.55      0.91      0.69      1284\n",
            "           3       0.31      0.88      0.46       960\n",
            "           4       0.76      0.81      0.78      5458\n",
            "           5       0.83      0.86      0.84      5468\n",
            "\n",
            "   micro avg       0.69      0.85      0.76     20016\n",
            "   macro avg       0.61      0.86      0.69     20016\n",
            "weighted avg       0.74      0.85      0.78     20016\n",
            " samples avg       0.76      0.89      0.79     20016\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# 7. Print classification reports:\n",
        "print(\"=== Training Data Classification Report ===\")\n",
        "print(classification_report(y_train_bin, y_pred_train, target_names=[str(label) for label in mlb.classes_]))\n",
        "\n",
        "print(\"=== Test Data Classification Report ===\")\n",
        "print(classification_report(y_test_bin, y_pred_test, target_names=[str(label) for label in mlb.classes_]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AazHNQMCP1Q7",
        "outputId": "b2aeb77b-6970-484a-af05-3435fb3606de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Validation Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.87      0.53      1018\n",
            "           1       0.83      0.88      0.85      5777\n",
            "           2       0.52      0.91      0.66      1241\n",
            "           3       0.32      0.88      0.47       995\n",
            "           4       0.75      0.81      0.78      5553\n",
            "           5       0.81      0.86      0.83      5323\n",
            "\n",
            "   micro avg       0.68      0.85      0.76     19907\n",
            "   macro avg       0.60      0.87      0.69     19907\n",
            "weighted avg       0.74      0.85      0.78     19907\n",
            " samples avg       0.76      0.89      0.79     19907\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Validation Data Classification Report ===\")\n",
        "print(classification_report(y_val_bin, y_pred_val, target_names=[str(label) for label in mlb.classes_]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cPE9i1DP1Q7"
      },
      "source": [
        "**Improve Logistics regression model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCRkL6pNP1Q7",
        "outputId": "383af157-348c-4463-ec2f-2e723762008e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV] END ...........estimator__C=0.01, estimator__penalty=l2; total time=   4.0s\n",
            "[CV] END ...........estimator__C=0.01, estimator__penalty=l2; total time=   4.4s\n",
            "[CV] END ...........estimator__C=0.01, estimator__penalty=l2; total time=   4.4s\n",
            "[CV] END ............estimator__C=0.1, estimator__penalty=l2; total time=   5.2s\n",
            "[CV] END ............estimator__C=0.1, estimator__penalty=l2; total time=   5.4s\n",
            "[CV] END ............estimator__C=0.1, estimator__penalty=l2; total time=   5.5s\n",
            "[CV] END ..............estimator__C=1, estimator__penalty=l2; total time=   5.8s\n",
            "[CV] END ..............estimator__C=1, estimator__penalty=l2; total time=   5.8s\n",
            "[CV] END ..............estimator__C=1, estimator__penalty=l2; total time=   4.2s\n",
            "[CV] END .............estimator__C=10, estimator__penalty=l2; total time=   4.2s\n",
            "[CV] END .............estimator__C=10, estimator__penalty=l2; total time=   3.4s\n",
            "[CV] END .............estimator__C=10, estimator__penalty=l2; total time=   4.3s\n",
            "Best Params: {'estimator__C': 1, 'estimator__penalty': 'l2'}\n",
            "Best Score: 0.6912303021653723\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.87      0.53      1018\n",
            "           1       0.83      0.88      0.85      5777\n",
            "           2       0.52      0.91      0.66      1241\n",
            "           3       0.32      0.88      0.47       995\n",
            "           4       0.75      0.81      0.78      5553\n",
            "           5       0.81      0.86      0.83      5323\n",
            "\n",
            "   micro avg       0.68      0.85      0.76     19907\n",
            "   macro avg       0.60      0.87      0.69     19907\n",
            "weighted avg       0.74      0.85      0.78     19907\n",
            " samples avg       0.76      0.89      0.79     19907\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter tuning on val data\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Build a logistic regression wrapped in OneVsRestClassifier\n",
        "logreg_pipeline = OneVsRestClassifier(\n",
        "    LogisticRegression(random_state=42, class_weight='balanced')\n",
        ")\n",
        "\n",
        "# Parameter grid for logistic regression\n",
        "param_grid = {\n",
        "    'estimator__C': [0.01, 0.1, 1, 10],\n",
        "    'estimator__penalty': ['l2'],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    logreg_pipeline,\n",
        "    param_grid,\n",
        "    scoring='f1_macro',\n",
        "    cv=3,                # 3-fold cross-validation\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "grid_search.fit(X_train_lsa, y_train_bin)\n",
        "\n",
        "print(\"Best Params:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_pred_val_best = grid_search.predict(X_val_lsa)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val_bin, y_pred_val_best, target_names=[str(label) for label in mlb.classes_]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EptcoeGCP1Q7"
      },
      "source": [
        "C is like a setting that controls how flexible the or model is\n",
        "The program tested different values of “C” for logistic regression (like 0.01, 0.1, 1, 10).\n",
        "For each value of C, it measured how good the model was (using macro F1 score).\n",
        "It found that C=1 gave the best balance overall.\n",
        "small C: might lead to lower recall but higher precision\n",
        "large C: improve recall but could lead to overfitting and lower precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha3sH4ajP1Q8",
        "outputId": "bd54497d-5ab8-4a09-a339-7c40a17df01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-Class Thresholds: [0.9 0.5 0.8 0.9 0.5 0.5]\n",
            "=== Training Data Classification Report with Per-Class Threshold Adjustment ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.60      0.64      8326\n",
            "           1       0.82      0.88      0.85     45400\n",
            "           2       0.73      0.80      0.76      9907\n",
            "           3       0.59      0.54      0.57      7911\n",
            "           4       0.76      0.82      0.79     44445\n",
            "           5       0.83      0.86      0.84     43432\n",
            "\n",
            "   micro avg       0.78      0.82      0.80    159421\n",
            "   macro avg       0.74      0.75      0.74    159421\n",
            "weighted avg       0.78      0.82      0.80    159421\n",
            " samples avg       0.83      0.86      0.82    159421\n",
            "\n",
            "=== Test Data Classification Report with Per-Class Threshold Adjustment ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.59      0.63      1027\n",
            "           1       0.83      0.88      0.85      5819\n",
            "           2       0.72      0.80      0.76      1284\n",
            "           3       0.59      0.55      0.57       960\n",
            "           4       0.76      0.81      0.78      5458\n",
            "           5       0.83      0.86      0.84      5468\n",
            "\n",
            "   micro avg       0.78      0.82      0.80     20016\n",
            "   macro avg       0.73      0.75      0.74     20016\n",
            "weighted avg       0.78      0.82      0.80     20016\n",
            " samples avg       0.83      0.86      0.82     20016\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define a function to adjust per-class threshold\n",
        "def apply_per_class_threshold(model, X, thresholds):\n",
        "    \"\"\"\n",
        "    Predict probabilities then convert them to binary predictions\n",
        "    using per-class thresholds.\n",
        "\n",
        "    Parameters:\n",
        "      model: multi-label model (supports predict_proba)\n",
        "      X: feature matrix (LSA-transformed)\n",
        "      thresholds\n",
        "\n",
        "    Returns:\n",
        "      y_pred_adjusted: binary predictions after threshold adjustment\n",
        "    \"\"\"\n",
        "    # Get probability estimates\n",
        "    y_proba = model.predict_proba(X)\n",
        "    n_classes = y_proba.shape[1]\n",
        "    y_pred_adjusted = np.zeros_like(y_proba, dtype=int)\n",
        "    for i in range(n_classes):\n",
        "        y_pred_adjusted[:, i] = (y_proba[:, i] >= thresholds[i]).astype(int)\n",
        "    return y_pred_adjusted\n",
        "\n",
        "# Define a default threshold of 0.5 for all classes\n",
        "default_threshold = 0.5\n",
        "n_classes = y_train_bin.shape[1]\n",
        "thresholds = np.full(n_classes, default_threshold)\n",
        "\n",
        "# Adjust thresholds for classes 0, 3, and 2 to balance precision/recall\n",
        "thresholds[0] = 0.9\n",
        "thresholds[3] = 0.9\n",
        "thresholds[2] = 0.8\n",
        "print(\"Per-Class Thresholds:\", thresholds)\n",
        "\n",
        "# Apply the threshold adjustment to each dataset:\n",
        "y_pred_train_adjusted = apply_per_class_threshold(model, X_train_lsa, thresholds)\n",
        "y_pred_val_adjusted   = apply_per_class_threshold(model, X_val_lsa, thresholds)\n",
        "y_pred_test_adjusted  = apply_per_class_threshold(model, X_test_lsa, thresholds)\n",
        "\n",
        "# Print classification reports:\n",
        "print(\"=== Training Data Classification Report with Per-Class Threshold Adjustment ===\")\n",
        "print(classification_report(y_train_bin, y_pred_train_adjusted, target_names=[str(label) for label in mlb.classes_]))\n",
        "\n",
        "print(\"=== Test Data Classification Report with Per-Class Threshold Adjustment ===\")\n",
        "print(classification_report(y_test_bin, y_pred_test_adjusted, target_names=[str(label) for label in mlb.classes_]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AFE2muAP1Q8",
        "outputId": "09080dd7-b2ff-4914-fae2-51c866fe4f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Validation Data Classification Report with Per-Class Threshold Adjustment ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.60      0.64      1018\n",
            "           1       0.83      0.88      0.85      5777\n",
            "           2       0.71      0.78      0.74      1241\n",
            "           3       0.59      0.54      0.56       995\n",
            "           4       0.75      0.81      0.78      5553\n",
            "           5       0.81      0.86      0.83      5323\n",
            "\n",
            "   micro avg       0.78      0.82      0.80     19907\n",
            "   macro avg       0.73      0.74      0.74     19907\n",
            "weighted avg       0.78      0.82      0.80     19907\n",
            " samples avg       0.82      0.86      0.82     19907\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Validation Data Classification Report with Per-Class Threshold Adjustment ===\")\n",
        "print(classification_report(y_val_bin, y_pred_val_adjusted, target_names=[str(label) for label in mlb.classes_]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RplHBf64P1Q8",
        "outputId": "8216c442-a412-4513-a958-4c87e35f6d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Metrics ===\n",
            "Average Precision (macro): 0.7365574775810018\n",
            "Average Recall (macro): 0.7473292308290039\n",
            "Average F1 (macro): 0.7405097761523338\n",
            "Jaccard Score (samples): 0.7644667987392066\n",
            "Hamming Loss: 0.09011592417482409\n",
            "\n",
            "=== Test Metrics ===\n",
            "Average Precision (macro): 0.7335743084026287\n",
            "Average Recall (macro): 0.7474809299561169\n",
            "Average F1 (macro): 0.7392220887537507\n",
            "Jaccard Score (samples): 0.7651629156123763\n",
            "Hamming Loss: 0.09040262795756204\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, hamming_loss\n",
        "\n",
        "# For Training Data:\n",
        "avg_precision_train = precision_score(y_train_bin, y_pred_train_adjusted, average='macro')\n",
        "avg_recall_train    = recall_score(y_train_bin, y_pred_train_adjusted, average='macro')\n",
        "avg_f1_train        = f1_score(y_train_bin, y_pred_train_adjusted, average='macro')\n",
        "jaccard_train       = jaccard_score(y_train_bin, y_pred_train_adjusted, average='samples')\n",
        "ham_loss_train      = hamming_loss(y_train_bin, y_pred_train_adjusted)\n",
        "\n",
        "# For Test Data:\n",
        "avg_precision_test = precision_score(y_test_bin, y_pred_test_adjusted, average='macro')\n",
        "avg_recall_test    = recall_score(y_test_bin, y_pred_test_adjusted, average='macro')\n",
        "avg_f1_test        = f1_score(y_test_bin, y_pred_test_adjusted, average='macro')\n",
        "jaccard_test       = jaccard_score(y_test_bin, y_pred_test_adjusted, average='samples')\n",
        "ham_loss_test      = hamming_loss(y_test_bin, y_pred_test_adjusted)\n",
        "\n",
        "print(\"=== Training Metrics ===\")\n",
        "print(\"Average Precision (macro):\", avg_precision_train)\n",
        "print(\"Average Recall (macro):\", avg_recall_train)\n",
        "print(\"Average F1 (macro):\", avg_f1_train)\n",
        "print(\"Jaccard Score (samples):\", jaccard_train)\n",
        "print(\"Hamming Loss:\", ham_loss_train)\n",
        "\n",
        "print(\"\\n=== Test Metrics ===\")\n",
        "print(\"Average Precision (macro):\", avg_precision_test)\n",
        "print(\"Average Recall (macro):\", avg_recall_test)\n",
        "print(\"Average F1 (macro):\", avg_f1_test)\n",
        "print(\"Jaccard Score (samples):\", jaccard_test)\n",
        "print(\"Hamming Loss:\", ham_loss_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKRq6MWZP1Q8",
        "outputId": "6b2f7910-7b08-4cd6-d495-35ad4f5ca142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Validation Metrics ===\n",
            "Average Precision (macro): 0.7301810985664448\n",
            "Average Recall (macro): 0.7433841132675097\n",
            "Average F1 (macro): 0.7354531664084093\n",
            "Jaccard Score (samples): 0.7602783512019711\n",
            "Hamming Loss: 0.09187365430290116\n"
          ]
        }
      ],
      "source": [
        "# For Validation Data:\n",
        "avg_precision_val = precision_score(y_val_bin, y_pred_val_adjusted, average='macro')\n",
        "avg_recall_val    = recall_score(y_val_bin, y_pred_val_adjusted, average='macro')\n",
        "avg_f1_val        = f1_score(y_val_bin, y_pred_val_adjusted, average='macro')\n",
        "jaccard_val       = jaccard_score(y_val_bin, y_pred_val_adjusted, average='samples')\n",
        "ham_loss_val      = hamming_loss(y_val_bin, y_pred_val_adjusted)\n",
        "\n",
        "print(\"\\n=== Validation Metrics ===\")\n",
        "print(\"Average Precision (macro):\", avg_precision_val)\n",
        "print(\"Average Recall (macro):\", avg_recall_val)\n",
        "print(\"Average F1 (macro):\", avg_f1_val)\n",
        "print(\"Jaccard Score (samples):\", jaccard_val)\n",
        "print(\"Hamming Loss:\", ham_loss_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo4_gR8jP1Q8"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B7L_xApP1Q8",
        "outputId": "5ba8f229-6be9-440a-a61f-7da37e183508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Random Forest: Training Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.80      0.46      8326\n",
            "           1       0.77      0.83      0.80     45400\n",
            "           2       0.46      0.85      0.60      9907\n",
            "           3       0.28      0.85      0.42      7911\n",
            "           4       0.77      0.69      0.73     44445\n",
            "           5       0.79      0.73      0.76     43432\n",
            "\n",
            "   micro avg       0.64      0.76      0.69    159421\n",
            "   macro avg       0.57      0.79      0.63    159421\n",
            "weighted avg       0.71      0.76      0.72    159421\n",
            " samples avg       0.71      0.81      0.73    159421\n",
            "\n",
            "=== Random Forest: Test Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.75      0.43      1027\n",
            "           1       0.77      0.82      0.80      5819\n",
            "           2       0.46      0.84      0.59      1284\n",
            "           3       0.26      0.83      0.40       960\n",
            "           4       0.77      0.68      0.72      5458\n",
            "           5       0.78      0.73      0.75      5468\n",
            "\n",
            "   micro avg       0.63      0.76      0.69     20016\n",
            "   macro avg       0.56      0.77      0.62     20016\n",
            "weighted avg       0.71      0.76      0.71     20016\n",
            " samples avg       0.71      0.80      0.72     20016\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Train Random Forest Model\n",
        "# -------------------------------\n",
        "# X_train_lsa, X_val_lsa, X_test_lsa, y_train_bin, y_val_bin, y_test_bin, and mlb.\n",
        "# (These come from TF-IDF, LSA, and MultiLabelBinarizer processing steps above)\n",
        "\n",
        "model_rf = OneVsRestClassifier(\n",
        "    RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,           # Limit tree depth to reduce overfitting\n",
        "        min_samples_split=10,  # Require at least 10 samples to split a node\n",
        "        min_samples_leaf=5,    # Each leaf must have at least 5 samples\n",
        "        max_features='sqrt',   # Use square root of the total features at each split\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "model_rf.fit(X_train_lsa, y_train_bin)\n",
        "\n",
        "# Step 1: Predict on Data Splits and preprocessing\n",
        "y_pred_train_rf = model_rf.predict(X_train_lsa)\n",
        "y_pred_val_rf   = model_rf.predict(X_val_lsa)\n",
        "y_pred_test_rf  = model_rf.predict(X_test_lsa)\n",
        "\n",
        "# Step 2: Print Classification Reports\n",
        "print(\"=== Random Forest: Training Data Classification Report ===\")\n",
        "print(classification_report(y_train_bin, y_pred_train_rf, target_names=[str(label) for label in mlb.classes_]))\n",
        "\n",
        "print(\"=== Random Forest: Test Data Classification Report ===\")\n",
        "print(classification_report(y_test_bin, y_pred_test_rf, target_names=[str(label) for label in mlb.classes_]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6Ne-gXXP1Q8",
        "outputId": "e2d51996-8da1-49a8-eb7a-24065f239ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Random Forest: Validation Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.75      0.43      1018\n",
            "           1       0.77      0.83      0.80      5777\n",
            "           2       0.45      0.84      0.59      1241\n",
            "           3       0.27      0.84      0.40       995\n",
            "           4       0.77      0.68      0.72      5553\n",
            "           5       0.78      0.73      0.75      5323\n",
            "\n",
            "   micro avg       0.63      0.76      0.69     19907\n",
            "   macro avg       0.56      0.78      0.62     19907\n",
            "weighted avg       0.70      0.76      0.71     19907\n",
            " samples avg       0.71      0.80      0.72     19907\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"=== Random Forest: Validation Data Classification Report ===\")\n",
        "print(classification_report(y_val_bin, y_pred_val_rf, target_names=[str(label) for label in mlb.classes_]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmu2Uqp9P1Q8"
      },
      "source": [
        "**Improve model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qivPNpBzP1Q8",
        "outputId": "971a8745-d336-4a0e-b41a-8e427877bdf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-Class Thresholds: [0.6  0.5  0.6  0.63 0.5  0.5 ]\n",
            "=== Random Forest with Adjusted Thresholds: Training Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.52      0.53      8326\n",
            "           1       0.77      0.83      0.80     45400\n",
            "           2       0.68      0.70      0.69      9907\n",
            "           3       0.53      0.54      0.53      7911\n",
            "           4       0.77      0.69      0.73     44445\n",
            "           5       0.79      0.73      0.76     43432\n",
            "\n",
            "   micro avg       0.75      0.73      0.74    159421\n",
            "   macro avg       0.68      0.67      0.67    159421\n",
            "weighted avg       0.75      0.73      0.74    159421\n",
            " samples avg       0.78      0.78      0.75    159421\n",
            "\n",
            "=== Random Forest with Adjusted Thresholds: Test Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.51      0.52      1027\n",
            "           1       0.77      0.82      0.80      5819\n",
            "           2       0.67      0.68      0.67      1284\n",
            "           3       0.51      0.52      0.52       960\n",
            "           4       0.77      0.68      0.72      5458\n",
            "           5       0.78      0.73      0.75      5468\n",
            "\n",
            "   micro avg       0.74      0.72      0.73     20016\n",
            "   macro avg       0.67      0.66      0.66     20016\n",
            "weighted avg       0.74      0.72      0.73     20016\n",
            " samples avg       0.77      0.77      0.75     20016\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "y_proba_train_rf = model_rf.predict_proba(X_train_lsa)\n",
        "y_proba_val_rf   = model_rf.predict_proba(X_val_lsa)\n",
        "y_proba_test_rf  = model_rf.predict_proba(X_test_lsa)\n",
        "\n",
        "# Step 1: Set Per-Class Thresholds and Adjust Predictions\n",
        "# Get number of classes from the probability matrix shape\n",
        "n_classes = y_proba_train_rf.shape[1]\n",
        "\n",
        "# Create an array of default thresholds (0.5 for all classes)\n",
        "default_threshold = 0.5\n",
        "thresholds = np.full(n_classes, default_threshold)\n",
        "\n",
        "# Adjust thresholds for classes 0, 3, and 2\n",
        "thresholds[0] = 0.6\n",
        "thresholds[3] = 0.63\n",
        "thresholds[2] = 0.6\n",
        "\n",
        "print(\"Per-Class Thresholds:\", thresholds)\n",
        "\n",
        "def apply_thresholds(y_proba, thresholds):\n",
        "    \"\"\"\n",
        "    Convert probability predictions to binary predictions using per-class thresholds.\n",
        "    \"\"\"\n",
        "    n_samples, n_classes = y_proba.shape\n",
        "    y_pred = np.zeros_like(y_proba, dtype=int)\n",
        "    for i in range(n_classes):\n",
        "        y_pred[:, i] = (y_proba[:, i] >= thresholds[i]).astype(int)\n",
        "    return y_pred\n",
        "\n",
        "# Apply thresholds for each dataset:\n",
        "y_pred_train_rf_adj = apply_thresholds(y_proba_train_rf, thresholds)\n",
        "y_pred_val_rf_adj   = apply_thresholds(y_proba_val_rf, thresholds)\n",
        "y_pred_test_rf_adj  = apply_thresholds(y_proba_test_rf, thresholds)\n",
        "\n",
        "# Print Classification Reports for Adjusted Predictions\n",
        "print(\"=== Random Forest with Adjusted Thresholds: Training Data Classification Report ===\")\n",
        "print(classification_report(y_train_bin, y_pred_train_rf_adj, target_names=[str(label) for label in mlb.classes_]))\n",
        "\n",
        "print(\"=== Random Forest with Adjusted Thresholds: Test Data Classification Report ===\")\n",
        "print(classification_report(y_test_bin, y_pred_test_rf_adj, target_names=[str(label) for label in mlb.classes_]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiJxF7UdP1Q9",
        "outputId": "4240ec7e-ad9d-4fae-cac1-24a8d01d7990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Random Forest with Adjusted Thresholds: Validation Data Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.49      0.51      1018\n",
            "           1       0.77      0.83      0.80      5777\n",
            "           2       0.66      0.67      0.67      1241\n",
            "           3       0.50      0.52      0.51       995\n",
            "           4       0.77      0.68      0.72      5553\n",
            "           5       0.78      0.73      0.75      5323\n",
            "\n",
            "   micro avg       0.74      0.72      0.73     19907\n",
            "   macro avg       0.67      0.65      0.66     19907\n",
            "weighted avg       0.74      0.72      0.73     19907\n",
            " samples avg       0.77      0.77      0.74     19907\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Random Forest with Adjusted Thresholds: Validation Data Classification Report ===\")\n",
        "print(classification_report(y_val_bin, y_pred_val_rf_adj, target_names=[str(label) for label in mlb.classes_]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05przORMP1Q9",
        "outputId": "1952218c-0ec1-4775-f6a9-3b51f4229c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Random Forest (Adjusted Thresholds) Metrics ===\n",
            "Training Metrics:\n",
            "  Average Precision (macro): 0.6807101453797265\n",
            "  Average Recall (macro): 0.6703791152714028\n",
            "  Average F1 (macro): 0.6746272567916732\n",
            "  Jaccard Score (samples): 0.6973356584759495\n",
            "  Hamming Loss: 0.11527213602361767\n",
            "\n",
            "Test Metrics:\n",
            "  Average Precision (macro): 0.6723861803752863\n",
            "  Average Recall (macro): 0.656220578686312\n",
            "  Average F1 (macro): 0.6635174810802299\n",
            "  Jaccard Score (samples): 0.690846539707906\n",
            "  Hamming Loss: 0.11804723221023661\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, hamming_loss\n",
        "# Training Metrics:\n",
        "avg_precision_train_rf = precision_score(y_train_bin, y_pred_train_rf_adj, average='macro')\n",
        "avg_recall_train_rf    = recall_score(y_train_bin, y_pred_train_rf_adj, average='macro')\n",
        "avg_f1_train_rf        = f1_score(y_train_bin, y_pred_train_rf_adj, average='macro')\n",
        "jaccard_train_rf       = jaccard_score(y_train_bin, y_pred_train_rf_adj, average='samples')\n",
        "ham_loss_train_rf      = hamming_loss(y_train_bin, y_pred_train_rf_adj)\n",
        "\n",
        "# Test Metrics:\n",
        "avg_precision_test_rf = precision_score(y_test_bin, y_pred_test_rf_adj, average='macro')\n",
        "avg_recall_test_rf    = recall_score(y_test_bin, y_pred_test_rf_adj, average='macro')\n",
        "avg_f1_test_rf        = f1_score(y_test_bin, y_pred_test_rf_adj, average='macro')\n",
        "jaccard_test_rf       = jaccard_score(y_test_bin, y_pred_test_rf_adj, average='samples')\n",
        "ham_loss_test_rf      = hamming_loss(y_test_bin, y_pred_test_rf_adj)\n",
        "\n",
        "print(\"\\n=== Random Forest (Adjusted Thresholds) Metrics ===\")\n",
        "print(\"Training Metrics:\")\n",
        "print(\"  Average Precision (macro):\", avg_precision_train_rf)\n",
        "print(\"  Average Recall (macro):\", avg_recall_train_rf)\n",
        "print(\"  Average F1 (macro):\", avg_f1_train_rf)\n",
        "print(\"  Jaccard Score (samples):\", jaccard_train_rf)\n",
        "print(\"  Hamming Loss:\", ham_loss_train_rf)\n",
        "\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(\"  Average Precision (macro):\", avg_precision_test_rf)\n",
        "print(\"  Average Recall (macro):\", avg_recall_test_rf)\n",
        "print(\"  Average F1 (macro):\", avg_f1_test_rf)\n",
        "print(\"  Jaccard Score (samples):\", jaccard_test_rf)\n",
        "print(\"  Hamming Loss:\", ham_loss_test_rf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}