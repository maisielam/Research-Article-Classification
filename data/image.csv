title,authors,summary,published,updated,link,pdf_url,categories
Snapshot multispectral imaging using a filter array,Kazuma Shinoda,"A multispectral filter array (MSFA) is one solution for capturing a multispectral image (MSI) in a single shot at low cost. We introduce our optimization method of the spectral sensitivity of the MSFAs and demosaicking, and show a new prototype filter array for snapshot imaging based on a photonic crystal.",2018-08-28T04:04:47Z,2018-08-28T04:04:47Z,http://arxiv.org/abs/1808.09106v1,http://arxiv.org/pdf/1808.09106v1,eess.IV
A Self-supervised SAR Image Despeckling Strategy Based on   Parameter-sharing Convolutional Neural Networks,"Liang Chen, Yifei Yin, Hao Shi, Qingqing Sheng, Wei Li","Speckle noise is generated due to the SAR imaging mechanism, which brings difficulties in SAR image interpretation. Hence, despeckling is a helpful step in SAR pre-processing. Nowadays, deep learning has been proved to be a progressive method for SAR image despeckling. Most deep learning methods for despeckling are based on supervised learning, which needs original SAR images and speckle-free SAR images to train the network. However, the speckle-free SAR images are generally not available. So, this issue was tackled by adding multiplicative noise to optical images synthetically for simulating speckled image. Therefore, there are following challenges in SAR image despeckling: (1) lack of speckle-free SAR image; (2) difficulty in keeping details such as edges and textures in heterogeneous areas. To address these issues, we propose a self-supervised SAR despeckling strategy that can be trained without speckle-free images. Firstly, the feasibility of SAR image despeckling without speckle-free images is proved theoretically. Then, the sub-sampler based on the adjacent-syntropy criteria is proposed. The training image pairs are generated by the sub-sampler from real-word SAR image to estimate the noise distribution. Furthermore, to make full use of training pairs, the parameter sharing convolutional neural networks are adopted. Finally, according to the characteristics of SAR images, a multi-feature loss function is proposed. The proposed loss function is composed of despeckling term, regular term and perception term, to constrain the gap between the generated paired images. The ability of edge and texture feature preserving is improved simultaneously. Finally, qualitative and quantitative experiments are validated on real-world SAR images, showing better performances than several advanced SAR image despeckling methods.",2023-08-11T07:19:45Z,2023-08-11T07:19:45Z,http://arxiv.org/abs/2308.05975v1,http://arxiv.org/pdf/2308.05975v1,eess.IV
Introduction to Brain and Medical Images,Moo K. Chung,"This article is based on the first chapter of book Chung (2013), where brain and medical images are introduced. The most widely used brain imaging modalities are magnetic resonance images (MRI), functional-MRI (fMRI) and diffusion tensor images (DTI). A brief introduction to each imaging modality is explained. Further, we explain what kind of curve, volume and surface data that can be extracted from each modality.",2021-03-09T23:08:16Z,2021-03-09T23:08:16Z,http://arxiv.org/abs/2103.05772v1,http://arxiv.org/pdf/2103.05772v1,eess.IV
Studying the Effect of Digital Stain Separation of Histopathology Images   on Image Search Performance,"Alison K. Cheeseman, Hamid R. Tizhoosh, Edward R. Vrscay","Due to recent advances in technology, digitized histopathology images are now widely available for both clinical and research purposes. Accordingly, research into computerized image analysis algorithms for digital histopathology images has been progressing rapidly. In this work, we focus on image retrieval for digital histopathology images. Image retrieval algorithms can be used to find similar images and can assist pathologists in making quick and accurate diagnoses. Histopathology images are typically stained with dyes to highlight features of the tissue, and as such, an image analysis algorithm for histopathology should be able to process colour images and determine relevant information from the stain colours present. In this study, we are interested in the effect that stain separation into their individual stain components has on image search performance. To this end, we implement a basic k-nearest neighbours (kNN) search algorithm on histopathology images from two publicly available data sets (IDC and BreakHis) which are: a) converted to greyscale, b) digitally stain-separated and c) the original RGB colour images. The results of this study show that using H\&E separated images yields search accuracies within one or two percent of those obtained with original RGB images, and that superior performance is observed using the H\&E images in most scenarios we tested.",2020-03-31T15:41:36Z,2020-03-31T15:41:36Z,http://arxiv.org/abs/2003.14303v1,http://arxiv.org/pdf/2003.14303v1,eess.IV
A psychophysical evaluation of techniques for Mooney image generation,"Lars C. Reining, Thomas S. A. Wallis","Mooney images can contribute to our understanding of the processes involved in visual perception, because they allow a dissociation between image content and image understanding. Mooney images are generated by first smoothing and subsequently thresholding an image. In most previous studies this was performed manually, using subjective criteria for generation. This manual process could eventually be avoided by using automatic generation techniques. The field of computer image processing offers numerous techniques for image thresholding, but these are only rarely used to create Mooney images. Furthermore, there is little research on the perceptual effects of smoothing and thresholding. Therefore, in this study we investigated how the choice of different thresholding techniques and amount of smoothing affects the interpretability of Mooney images for human participants. We generated Mooney images using four different thresholding techniques and, in a second experiment, parametrically varied the level of smoothing. Participants identified the concepts shown in Mooney images and rated their interpretability. Although the techniques generate physically-different Mooney images, identification performance and subjective ratings were similar across the different techniques. This indicates that finding the perfect threshold in the process of generating Mooney images is not critical for Mooney image interpretability, at least for globally-applied thresholds. The degree of smoothing applied before thresholding, on the other hand, requires more tuning depending on the noise of the original image and the desired interpretability of the resulting Mooney image. Future work in automatic Mooney image generation should pursue local thresholding techniques, where different thresholds are applied to image regions depending on the local image content.",2024-03-18T15:20:57Z,2024-03-18T15:20:57Z,http://arxiv.org/abs/2403.11867v1,http://arxiv.org/pdf/2403.11867v1,q-bio.NC
XNAT-PIC: Extending XNAT to Preclinical Imaging Centers,"Sara Zullino, Alessandro Paglialonga, Walter Dastrù, Dario Livio Longo, Silvio Aime","Molecular imaging generates large volumes of heterogeneous biomedical imagery with an impelling need of guidelines for handling image data. Although several successful solutions have been implemented for human epidemiologic studies, few and limited approaches have been proposed for animal population studies. Preclinical imaging research deals with a variety of machinery yielding tons of raw data but the current practices to store and distribute image data are inadequate. Therefore, standard tools for the analysis of large image datasets need to be established. In this paper, we present an extension of XNAT for Preclinical Imaging Centers (XNAT-PIC). XNAT is a worldwide used, open-source platform for securely hosting, sharing, and processing of clinical imaging studies. Despite its success, neither tools for importing large, multimodal preclinical image datasets nor pipelines for processing whole imaging studies are yet available in XNAT. In order to overcome these limitations, we have developed several tools to expand the XNAT core functionalities for supporting preclinical imaging facilities. Our aim is to streamline the management and exchange of image data within the preclinical imaging community, thereby enhancing the reproducibility of the results of image processing and promoting open science practices.",2021-02-23T17:15:27Z,2021-02-23T17:15:27Z,http://arxiv.org/abs/2103.02044v1,http://arxiv.org/pdf/2103.02044v1,"q-bio.QM, eess.IV"
An Image Identification Scheme of Encrypted JPEG Images for   Privacy-Preserving Photo Sharing Services,"Kenta Iida, Hitoshi Kiya","We propose an image identification scheme for double-compressed encrypted JPEG images that aims to identify encrypted JPEG images that are generated from an original JPEG image. To store images without any visual sensitive information on photo sharing services, encrypted JPEG images are generated by using a block-scrambling-based encryption method that has been proposed for Encryption-then-Compression systems with JPEG compression. In addition, feature vectors robust against JPEG compression are extracted from encrypted JPEG images. The use of the image encryption and feature vectors allows us to identify encrypted images recompressed multiple times. Moreover, the proposed scheme is designed to identify images re-encrypted with different keys. The results of a simulation show that the identification performance of the scheme is high even when images are recompressed and re-encrypted.",2019-05-08T12:18:07Z,2019-05-19T07:27:45Z,http://arxiv.org/abs/1905.03025v2,http://arxiv.org/pdf/1905.03025v2,eess.IV
Deep Hyperspectral and Multispectral Image Fusion with Inter-image   Variability,"Xiuheng Wang, Ricardo Augusto Borsoi, Cédric Richard, Jie Chen","Hyperspectral and multispectral image fusion allows us to overcome the hardware limitations of hyperspectral imaging systems inherent to their lower spatial resolution. Nevertheless, existing algorithms usually fail to consider realistic image acquisition conditions. This paper presents a general imaging model that considers inter-image variability of data from heterogeneous sources and flexible image priors. The fusion problem is stated as an optimization problem in the maximum a posteriori framework. We introduce an original image fusion method that, on the one hand, solves the optimization problem accounting for inter-image variability with an iteratively reweighted scheme and, on the other hand, that leverages light-weight CNN-based networks to learn realistic image priors from data. In addition, we propose a zero-shot strategy to directly learn the image-specific prior of the latent images in an unsupervised manner. The performance of the algorithm is illustrated with real data subject to inter-image variability.",2022-08-24T08:53:38Z,2023-04-11T09:29:09Z,http://arxiv.org/abs/2208.11376v2,http://arxiv.org/pdf/2208.11376v2,eess.IV
Copy-Paste Image Augmentation with Poisson Image Editing for Ultrasound   Instance Segmentation Learning,"Wei-Hsiang Shen, Meng-Lin Li","Deep learning has shown great success in high-level image analysis problems; yet its efficacy relies on the quality and diversity of the training data. In this work, we introduce a copypaste image augmentation for ultrasound images. The Poisson image editing technique is used to generate realistic and seamless boundary transitions around the pasted image. Results showed that the proposed image augmentation technique improves training performance in terms of higher objective metrics and more stable training results.",2023-08-28T09:38:45Z,2023-08-28T09:38:45Z,http://arxiv.org/abs/2308.14772v1,http://arxiv.org/pdf/2308.14772v1,eess.IV
MarsQE: Semantic-Informed Quality Enhancement for Compressed Martian   Image,"Chengfeng Liu, Mai Xu, Qunliang Xing, Xin Zou","Lossy image compression is essential for Mars exploration missions, due to the limited bandwidth between Earth and Mars. However, the compression may introduce visual artifacts that complicate the geological analysis of the Martian surface. Existing quality enhancement approaches, primarily designed for Earth images, fall short for Martian images due to a lack of consideration for the unique Martian semantics. In response to this challenge, we conduct an in-depth analysis of Martian images, yielding two key insights based on semantics: the presence of texture similarities and the compact nature of texture representations in Martian images. Inspired by these findings, we introduce MarsQE, an innovative, semantic-informed, two-phase quality enhancement approach specifically designed for Martian images. The first phase involves the semantic-based matching of texture-similar reference images, and the second phase enhances image quality by transferring texture patterns from these reference images to the compressed image. We also develop a post-enhancement network to further reduce compression artifacts and achieve superior compression quality. Our extensive experiments demonstrate that MarsQE significantly outperforms existing approaches for Earth images, establishing a new benchmark for the quality enhancement on Martian images.",2024-04-15T03:14:20Z,2024-04-15T03:14:20Z,http://arxiv.org/abs/2404.09433v1,http://arxiv.org/pdf/2404.09433v1,eess.IV
Design an Advance computer-aided tool for Image Authentication and   Classification,"Rozita Teymourzadeh, Amirize Alpha Laadi, Yazan Samir, Masuri Othman","Over the years, advancements in the fields of digital image processing and artificial intelligence have been applied in solving many real-life problems. This could be seen in facial image recognition for security systems, identity registrations. Hence a bottleneck of identity registration is image processing. These are carried out in form of image preprocessing, image region extraction by cropping, feature extraction using Principal Component Analysis (PCA) and image compression using Discrete Cosine Transform (DCT). Other processing includes filtering and histogram equalization using contrast stretching is performed while enhancing the image as part of the analytical tool. Hence, this research work presents a universal integration image forgery detection analysis tool with image facial recognition using Back Propagation Neural Network (BPNN) processor. The proposed designed tool is a multi-function smart tool with the novel architecture of programmable error goal and light intensity. Furthermore, its advance dual database increases the efficiency of a high-performance application. With the fact that, the facial image recognition will always, give a matching output or closest possible output image for every input image irrespective of the authenticity, the universal smart GUI tool is proposed and designed to perform image forgery detection with the high accuracy of 2% error rate. Meanwhile, a novel structure that provides efficient automatic image forgery detection for all input test images for the BPNN recognition is presented. Hence, an input image will be authenticated before being fed into the recognition tool.",2018-06-16T21:56:13Z,2018-06-16T21:56:13Z,http://arxiv.org/abs/1808.02085v1,http://arxiv.org/pdf/1808.02085v1,eess.SP
The First Airborne Experiment of Sparse Microwave Imaging: Prototype   System Design and Result Analysis,"Zhe Zhang, Bingchen Zhang, Chenglong Jiang, Xingdong Liang, Longyong Chen, Wen Hong, Yirong Wu","In this paper we report the first airborne experiments of sparse microwave imaging, conducted in September 2013 and May 2014, using our prototype sparse microwave imaging radar system. This is the first reported imaging radar system and airborne experiment that specially designed for sparse microwave imaging. Sparse microwave imaging is a novel concept of radar imaging, it is mainly the combination of traditional radar imaging technology and newly developed sparse signal processing theory, achieving benefits in both improving the imaging quality of current microwave imaging systems and designing optimized sparse microwave imaging radar system to reduce system sampling rate towards the sparse target scenes. During recent years, many researchers focus on related topics of sparse microwave imaging, but rarely few paid attention to prototype system design and experiment. We introduce our prototype sparse microwave imaging radar system, including its system design, hardware considerations and signal processing methods. Several design principles should be considered during the system designing, including the sampling scheme, antenna, SNR, waveform, resolution, etc. We select jittered sampling in azimuth and uniform sampling in range to balance the system complexity and performance. The imaging algorithm is accelerated $\ell_q$ regularization algorithm. To test the prototype radar system and verify the effectiveness of sparse microwave imaging framework, airborne experiments are carried out using our prototype system and we achieve the first sparse microwave image successfully. We analyze the imaging performance of prototype sparse microwave radar system with different sparsities, sampling rates, SNRs and sampling schemes, using three-dimensional phase transit diagram as the evaluation tool.",2021-10-20T17:32:36Z,2021-10-20T17:32:36Z,http://arxiv.org/abs/2110.10675v1,http://arxiv.org/pdf/2110.10675v1,eess.SP
Revisiting registration-based synthesis: A focus on unsupervised MR   image synthesis,"Savannah P. Hays, Lianrui Zuo, Yihao Liu, Anqi Feng, Jiachen Zhuo, Jerry L. Prince, Aaron Carass","Deep learning (DL) has led to significant improvements in medical image synthesis, enabling advanced image-to-image translation to generate synthetic images. However, DL methods face challenges such as domain shift and high demands for training data, limiting their generalizability and applicability. Historically, image synthesis was also carried out using deformable image registration (DIR), a method that warps moving images of a desired modality to match the anatomy of a fixed image. However, concerns about its speed and accuracy led to its decline in popularity. With the recent advances of DL-based DIR, we now revisit and reinvigorate this line of research. In this paper, we propose a fast and accurate synthesis method based on DIR. We use the task of synthesizing a rare magnetic resonance (MR) sequence, white matter nulled (WMn) T1-weighted (T1-w) images, to demonstrate the potential of our approach. During training, our method learns a DIR model based on the widely available MPRAGE sequence, which is a cerebrospinal fluid nulled (CSFn) T1-w inversion recovery gradient echo pulse sequence. During testing, the trained DIR model is first applied to estimate the deformation between moving and fixed CSFn images. Subsequently, this estimated deformation is applied to align the paired WMn counterpart of the moving CSFn image, yielding a synthetic WMn image for the fixed CSFn image. Our experiments demonstrate promising results for unsupervised image synthesis using DIR. These findings highlight the potential of our technique in contexts where supervised synthesis methods are constrained by limited training data.",2024-02-19T17:00:54Z,2024-02-19T17:00:54Z,http://arxiv.org/abs/2402.12288v1,http://arxiv.org/pdf/2402.12288v1,eess.IV
Image Registration with Averaging Network and Edge-Based Loss for   Low-SNR Cardiac MRI,"Xuan Lei, Philip Schniter, Chong Chen, Rizwan Ahmad","Purpose: To perform image registration and averaging of multiple free-breathing single-shot cardiac images, where the individual images may have a low signal-to-noise ratio (SNR).   Methods: To address low SNR encountered in single-shot imaging, especially at low field strengths, we propose a fast deep learning (DL)-based image registration method, called Averaging Morph with Edge Detection (AiM-ED). AiM-ED jointly registers multiple noisy source images to a noisy target image and utilizes a noise-robust pre-trained edge detector to define the training loss. We validate AiM-ED using synthetic late gadolinium enhanced (LGE) imaging data from the MR extended cardiac-torso (MRXCAT) phantom and retrospectively undersampled single-shot data from healthy subjects (24 slices) and patients (5 slices) under various levels of added noise. Additionally, we demonstrate the clinical feasibility of AiM-ED by applying it to prospectively undersampled data from patients (6 slices) scanned at a 0.55T scanner.   Results: Compared to a traditional energy-minimization-based image registration method and DL-based VoxelMorph, images registered using AiM-ED exhibit higher values of recovery SNR and three perceptual image quality metrics. An ablation study shows the benefit of both jointly processing multiple source images and using an edge map in AiM-ED.   Conclusion: For single-shot LGE imaging, AiM-ED outperforms existing image registration methods in terms of image quality. With fast inference, minimal training data requirements, and robust performance at various noise levels, AiM-ED has the potential to benefit single-shot CMR applications.",2024-09-04T00:28:03Z,2024-09-04T00:28:03Z,http://arxiv.org/abs/2409.02348v1,http://arxiv.org/pdf/2409.02348v1,eess.IV
Quality Prediction on Deep Generative Images,"Hyunsuk Ko, Dae Yeol Lee, Seunghyun Cho, Alan C. Bovik","In recent years, deep neural networks have been utilized in a wide variety of applications including image generation. In particular, generative adversarial networks (GANs) are able to produce highly realistic pictures as part of tasks such as image compression. As with standard compression, it is desirable to be able to automatically assess the perceptual quality of generative images to monitor and control the encode process. However, existing image quality algorithms are ineffective on GAN generated content, especially on textured regions and at high compressions. Here we propose a new naturalness-based image quality predictor for generative images. Our new GAN picture quality predictor is built using a multi-stage parallel boosting system based on structural similarity features and measurements of statistical similarity. To enable model development and testing, we also constructed a subjective GAN image quality database containing (distorted) GAN images and collected human opinions of them. Our experimental results indicate that our proposed GAN IQA model delivers superior quality predictions on the generative image datasets, as well as on traditional image quality datasets.",2020-04-17T13:50:04Z,2020-04-17T13:50:04Z,http://arxiv.org/abs/2004.08245v1,http://arxiv.org/pdf/2004.08245v1,eess.IV
Varifocal Multiview Images: Capturing and Visual Tasks,"Kejun Wu, Qiong Liu, Guoan Li, Gangyi Jiang, You Yang","Multiview images have flexible field of view (FoV) but inflexible depth of field (DoF). To overcome the limitation of multiview images on visual tasks, in this paper, we present varifocal multiview (VFMV) images with flexible DoF. VFMV images are captured by focusing a scene on distinct depths by varying focal planes, and each view only focused on one single plane.Therefore, VFMV images contain more information in focal dimension than multiview images, and can provide a rich representation for 3D scene by considering both FoV and DoF. The characteristics of VFMV images are useful for visual tasks to achieve high quality scene representation. Two experiments are conducted to validate the advantages of VFMV images in 4D light field feature detection and 3D reconstruction. Experiment results show that VFMV images can detect more light field features and achieve higher reconstruction quality due to informative focus cues. This work demonstrates that VFMV images have definite advantages over multiview images in visual tasks.",2021-11-19T08:50:18Z,2021-11-19T08:50:18Z,http://arxiv.org/abs/2111.10099v1,http://arxiv.org/pdf/2111.10099v1,eess.IV
Optimal Physical Preprocessing for Example-Based Super-Resolution,"Alexander Robey, Vidya Ganapati","In example-based super-resolution, the function relating low-resolution images to their high-resolution counterparts is learned from a given dataset. This data-driven approach to solving the inverse problem of increasing image resolution has been implemented with deep learning algorithms. In this work, we explore modifying the imaging hardware in order to collect more informative low-resolution images for better ultimate high-resolution image reconstruction. We show that this ""physical preprocessing"" allows for improved image reconstruction with deep learning in Fourier ptychographic microscopy.   Fourier ptychographic microscopy is a technique allowing for both high resolution and high field-of-view at the cost of temporal resolution. In Fourier ptychographic microscopy, variable illumination patterns are used to collect multiple low-resolution images. These low-resolution images are then computationally combined to create an image with resolution exceeding that of any single image from the microscope. We use deep learning to jointly optimize the illumination pattern with the post-processing reconstruction algorithm for a given sample type, allowing for single-shot imaging with both high resolution and high field-of-view. We demonstrate, with simulated data, that the joint optimization yields improved image reconstruction as compared with sole optimization of the post-processing reconstruction algorithm.",2018-07-12T20:49:23Z,2018-07-12T20:49:23Z,http://arxiv.org/abs/1807.04813v1,http://arxiv.org/pdf/1807.04813v1,eess.IV
Unpaired Image Denoising,"Priyatham Kattakinda, A. N. Rajagopalan","Deep learning approaches in image processing predominantly resort to supervised learning. A majority of methods for image denoising are no exception to this rule and hence demand pairs of noisy and corresponding clean images. Only recently has there been the emergence of methods such as Noise2Void, where a deep neural network learns to denoise solely from noisy images. However, when clean images that do not directly correspond to any of the noisy images are actually available, there is room for improvement as these clean images contain useful information that fully unsupervised methods do not exploit. In this paper, we propose a method for image denoising in this setting. First, we use a flow-based generative model to learn a prior from clean images. We then use it to train a denoising network without the need for any clean targets. We demonstrate the efficacy of our method through extensive experiments and comparisons.",2020-09-24T07:47:17Z,2020-09-24T07:47:17Z,http://arxiv.org/abs/2009.11532v1,http://arxiv.org/pdf/2009.11532v1,eess.IV
Nonlocal Co-occurrence for Image Downscaling,"Sanjay Ghosh, Arpan Garai","Image downscaling is one of the widely used operations in image processing and computer graphics. It was recently demonstrated in the literature that kernel-based convolutional filters could be modified to develop efficient image downscaling algorithms. In this work, we present a new downscaling technique which is based on kernel-based image filtering concept. We propose to use pairwise co-occurrence similarity of the pixelpairs as the range kernel similarity in the filtering operation. The co-occurrence of the pixel-pair is learned directly from the input image. This co-occurrence learning is performed in a neighborhood based fashion all over the image. The proposed method can preserve the high-frequency structures, which were present in the input image, into the downscaled image. The idea is further extended to the case of fractions factor of downscaling. The resulting images retain visually-important details and do not suffer from edge-blurring artifact. We demonstrate the effectiveness of our proposed approach with extensive experiments on a large number of images downscaled with various downscaling factors.",2020-12-22T06:57:55Z,2023-01-14T08:38:12Z,http://arxiv.org/abs/2012.11858v3,http://arxiv.org/pdf/2012.11858v3,eess.IV
Hyperspectral image reconstruction by deep learning with super-Rayleigh   speckles,"Ziyan Chen, Zhentao Liu, Jianrong Wu, Shensheng Han","Ghost imaging via sparsity constraints (GISC) spectral camera modulates the three-dimensional (3D) hyperspectral image into a two-dimensional (2D) compressive image with speckles in a single shot. It obtains a 3D hyperspectral image (HSI) by reconstruction algorithms. The rapid development of deep learning has provided a new method for 3D HSI reconstruction. Moreover, the imaging performance of the GISC spectral camera can be improved by optimizing the speckle modulation. In this paper, we propose an end-to-end GISCnet with super-Rayleigh speckle modulation to improve the imaging quality of the GISC spectral camera. The structure of GISCnet is very simple but effective, and we can easily adjust the network structure parameters to improve the image reconstruction quality. Relative to Rayleigh speckles, our super-Rayleigh speckles modulation exhibits a wealth of detail in reconstructing 3D HSIs. After evaluating 648 3D HSIs, it was found that the average peak signal-to-noise ratio increased from 27 dB to 31 dB. Overall, the proposed GISCnet with super-Rayleigh speckle modulation can effectively improve the imaging quality of the GISC spectral camera by taking advantage of both optimized super-Rayleigh modulation and deep-learning image reconstruction, inspiring joint optimization of light-field modulation and image reconstruction to improve ghost imaging performance.",2025-02-26T03:18:42Z,2025-02-26T03:18:42Z,http://arxiv.org/abs/2502.18777v1,http://arxiv.org/pdf/2502.18777v1,eess.IV
Implementation Of Image Analysis Techniques For Various Textile   Identification,"Andrian Wijayono, Valentinus Galih Vidia Putra","Computer image analysis techniques used to identify textile products are presented in this chapter, together with a brief review of the historical development of the method. Automatic and semi-automatic image correction methods are described, which are often used for identification of textile yarn products, and can also be used to identify various textile indentification.   Keywords: digital image acquirement, image modeling, image quality improvement, image correction methods, median filtration, Laplace filter, threshold function, autocorrelation, Fourier transform, erosion, dilatation, digitalisation algorithm",2018-09-28T18:50:25Z,2018-09-28T18:50:25Z,http://arxiv.org/abs/1810.06423v1,http://arxiv.org/pdf/1810.06423v1,eess.IV
Multi-scale PIIFD for Registration of Multi-source Remote Sensing Images,"Chenzhong Gao, Wei Li","This paper aims at providing multi-source remote sensing images registered in geometric space for image fusion. Focusing on the characteristics and differences of multi-source remote sensing images, a feature-based registration algorithm is implemented. The key technologies include image scale-space for implementing multi-scale properties, Harris corner detection for keypoints extraction, and partial intensity invariant feature descriptor (PIIFD) for keypoints description. Eventually, a multi-scale Harris-PIIFD image registration algorithm framework is proposed. The experimental results of four sets of representative real data show that the algorithm has excellent, stable performance in multi-source remote sensing image registration, and can achieve accurate spatial alignment, which has strong practical application value and certain generalization ability.",2021-04-26T13:44:48Z,2021-04-26T13:44:48Z,http://arxiv.org/abs/2104.12572v1,http://arxiv.org/pdf/2104.12572v1,eess.IV
Artificial Intelligence-Based Image Enhancement in PET Imaging: Noise   Reduction and Resolution Enhancement,"Juan Liu, Masoud Malekzadeh, Niloufar Mirian, Tzu-An Song, Chi Liu, Joyita Dutta","High noise and low spatial resolution are two key confounding factors that limit the qualitative and quantitative accuracy of PET images. AI models for image denoising and deblurring are becoming increasingly popular for post-reconstruction enhancement of PET images. We present here a detailed review of recent efforts for AI-based PET image enhancement with a focus on network architectures, data types, loss functions, and evaluation metrics. We also highlight emerging areas in this field that are quickly gaining popularity, identify barriers to large-scale adoption of AI models for PET image enhancement, and discuss future directions.",2021-07-28T18:53:44Z,2021-07-28T18:53:44Z,http://arxiv.org/abs/2107.13595v1,http://arxiv.org/pdf/2107.13595v1,eess.IV
Hue Correction Scheme for Multi-Exposure Image Fusion Considering Hue   Distortion in Input Images,"Kouki Seo, Chihiro Go, Yuma Kinoshita, Hitoshi Kiya","We propose a novel hue-correction scheme for multi-exposure image fusion (MEF). Various MEF methods have so far been studied to generate higher-quality images. However, there are few MEF methods considering hue distortion unlike other fields of image processing, due to a lack of a reference image that has correct hue. In the proposed scheme, we generate an HDR image as a reference for hue correction, from input multi-exposure images. After that, hue distortion in an image fused by an MEF method is removed by using hue information of the HDR one, on the basis of the constant-hue plane in the RGB color space. In simulations, the proposed scheme is demonstrated to be effective to correct hue-distortion caused by conventional MEF methods. Experimental results also show that the proposed scheme can generate high-quality images, regardless of exposure conditions of input multi-exposure images.",2020-05-05T19:50:01Z,2020-05-05T19:50:01Z,http://arxiv.org/abs/2005.02451v1,http://arxiv.org/pdf/2005.02451v1,eess.IV
Image Denoising Inspired by Quantum Many-Body physics,"Sayantan Dutta, Adrian Basarab, Bertrand Georgeot, Denis Kouamé","Decomposing an image through Fourier, DCT or wavelet transforms is still a common approach in digital image processing, in number of applications such as denoising. In this context, data-driven dictionaries and in particular exploiting the redundancy withing patches extracted from one or several images allowed important improvements. This paper proposes an original idea of constructing such an image-dependent basis inspired by the principles of quantum many-body physics. The similarity between two image patches is introduced in the formalism through a term akin to interaction terms in quantum mechanics. The main contribution of the paper is thus to introduce this original way of exploiting quantum many-body ideas in image processing, which opens interesting perspectives in image denoising. The potential of the proposed adaptive decomposition is illustrated through image denoising in presence of additive white Gaussian noise, but the method can be used for other types of noise such as image-dependent noise as well. Finally, the results show that our method achieves comparable or slightly better results than existing approaches.",2021-08-31T12:04:11Z,2021-08-31T12:04:11Z,http://arxiv.org/abs/2108.13778v1,http://arxiv.org/pdf/2108.13778v1,eess.IV
Frequency domain kurtosis-based no-reference image quality assessment   for bright-field microscopy images,"V. A. A. Catanante, O. M. Bruno, J. E. S. Batista Neto","In the last few years, image processing researchers spent a substantial amount of time and effort developing and perfecting image quality assessment algorithms. Bright-field microscopy, for example, produces images whose quality is a bottleneck for consistent evaluation. For instance, when a stack of images of a specimen is acquired in different focal plane configurations, there will be a set of blurred or partially blurred elements in it, impairing proper evaluation. This work aims to provide an image quality assessment metric, without the presence of a reference image for comparison, to detect the blurred and sharp images among the whole set of the stack, and elect the sharpest ones for a further fusion process. The correlation of the results with subjective labeling of the image sets showed that the proposed metric offers reliable identification of the eligible images for fusion and suggests the application in other real-world problems.",2020-03-25T17:40:39Z,2020-03-25T17:40:39Z,http://arxiv.org/abs/2003.11526v1,http://arxiv.org/pdf/2003.11526v1,eess.IV
An Operator Theory for Analyzing the Resolution of Multi-illumination   Imaging Modalities,"Ping Liu, Habib Ammari","By introducing a new operator theory, we provide a unified mathematical theory for general source resolution in the multi-illumination imaging problem. Our main idea is to transform multi-illumination imaging into single-snapshot imaging with a new imaging kernel that depends on both the illumination patterns and the point spread function of the imaging system. We thus prove that the resolution of multi-illumination imaging is approximately determined by the essential cutoff frequency of the new imaging kernel, which is roughly limited by the sum of the cutoff frequency of the point spread function and the maximum essential frequency in the illumination patterns.   Our theory provides a unified way to estimate the resolution of various existing super-resolution modalities and results in the same estimates as those obtained in experiments. In addition, based on the reformulation of the multi-illumination imaging problem, we also estimate the resolution limits for resolving both complex and positive sources by sparsity-based approaches. We show that the resolution of multi-illumination imaging is approximately determined by the new imaging kernel from our operator theory and better resolution can be realized by sparsity-promoting techniques in practice but only for resolving very sparse sources. This explains experimentally observed phenomena in some sparsity-based super-resolution modalities.",2023-02-02T11:53:34Z,2023-02-02T11:53:34Z,http://arxiv.org/abs/2302.01033v1,http://arxiv.org/pdf/2302.01033v1,eess.IV
Knowledge-driven deep learning for fast MR imaging: undersampled MR   image reconstruction from supervised to un-supervised learning,"Shanshan Wang, Ruoyou Wu, Sen Jia, Alou Diakite, Cheng Li, Qiegen Liu, Leslie Ying","Deep learning (DL) has emerged as a leading approach in accelerating MR imaging. It employs deep neural networks to extract knowledge from available datasets and then applies the trained networks to reconstruct accurate images from limited measurements. Unlike natural image restoration problems, MR imaging involves physics-based imaging processes, unique data properties, and diverse imaging tasks. This domain knowledge needs to be integrated with data-driven approaches. Our review will introduce the significant challenges faced by such knowledge-driven DL approaches in the context of fast MR imaging along with several notable solutions, which include learning neural networks and addressing different imaging application scenarios. The traits and trends of these techniques have also been given which have shifted from supervised learning to semi-supervised learning, and finally, to unsupervised learning methods. In addition, MR vendors' choices of DL reconstruction have been provided along with some discussions on open questions and future directions, which are critical for the reliable imaging systems.",2024-02-05T03:37:05Z,2024-02-05T03:37:05Z,http://arxiv.org/abs/2402.02704v1,http://arxiv.org/pdf/2402.02704v1,eess.IV
A Spectrum-based Image Denoising Method with Edge Feature Enhancement,"Peter Luvton, Alfredo Castillejos, Jim Zhao, Christina Chajo","Image denoising stands as a critical challenge in image processing and computer vision, aiming to restore the original image from noise-affected versions caused by various intrinsic and extrinsic factors. This process is essential for applications that rely on the high quality and clarity of visual information, such as image restoration, visual tracking, and image registration, where the original content is vital for performance. Despite the development of numerous denoising algorithms, effectively suppressing noise, particularly under poor capture conditions with high noise levels, remains a challenge. Image denoising's practical importance spans multiple domains, notably medical imaging for enhanced diagnostic precision, as well as surveillance and satellite imagery where it improves image quality and usability. Techniques like the Fourier transform, which excels in noise reduction and edge preservation, along with phase congruency-based methods, offer promising results for enhancing noisy and low-contrast images common in modern imaging scenarios.",2024-03-16T22:50:16Z,2024-03-16T22:50:16Z,http://arxiv.org/abs/2403.11036v1,http://arxiv.org/pdf/2403.11036v1,eess.IV
An All-in-one Approach for Accelerated Cardiac MRI Reconstruction,"Kian Anvari Hamedani, Narges Razizadeh, Shahabedin Nabavi, Mohsen Ebrahimi Moghaddam","Cardiovascular magnetic resonance (CMR) imaging is the gold standard for diagnosing several heart diseases due to its non-invasive nature and proper contrast. MR imaging is time-consuming because of signal acquisition and image formation issues. Prolonging the imaging process can result in the appearance of artefacts in the final image, which can affect the diagnosis. It is possible to speed up CMR imaging using image reconstruction based on deep learning. For this purpose, the high-quality clinical interpretable images can be reconstructed by acquiring highly undersampled k-space data, that is only partially filled, and using a deep learning model. In this study, we proposed a stepwise reconstruction approach based on the Patch-GAN structure for highly undersampled k-space data compatible with the multi-contrast nature, various anatomical views and trajectories of CMR imaging. The proposed approach was validated using the CMRxRecon2024 challenge dataset and outperformed previous studies. The structural similarity index measure (SSIM) values for the first and second tasks of the challenge are 99.07 and 97.99, respectively. This approach can accelerate CMR imaging to obtain high-quality images, more accurate diagnosis and a pleasant patient experience.",2024-11-16T12:22:29Z,2024-11-16T12:22:29Z,http://arxiv.org/abs/2411.10787v1,http://arxiv.org/pdf/2411.10787v1,eess.IV
A Data-Driven Paradigm-Based Image Denoising and Mosaicking Approach for   High-Resolution Acoustic Camera,"Xiaoteng Zhou, Yilong Zhang, Katsunori Mizuno, Kenichiro Tsutsumi, Hideki Sugimoto","In this work, an approach based on a data-driven paradigm to denoise and mosaic acoustic camera images is proposed. Acoustic cameras, also known as 2D forward-looking sonar, could collect high-resolution acoustic images in dark and turbid water. However, due to the unique sensor imaging mechanism, main vision-based processing methods, like image denoising and mosaicking are still in the early stages. Due to the complex noise interference in acoustic images and the narrow field of view of acoustic cameras, it is difficult to restore the entire detection scene even if enough acoustic images are collected. Relevant research work addressing these issues focuses on the design of handcrafted operators for acoustic image processing based on prior knowledge and sensor models. However, such methods lack robustness due to noise interference and insufficient feature details on acoustic images. This study proposes an acoustic image denoising and mosaicking method based on a data-driven paradigm and conducts experimental testing using collected acoustic camera images. The results demonstrate the effectiveness of the proposal.",2025-02-19T07:56:29Z,2025-02-19T07:56:29Z,http://arxiv.org/abs/2502.14002v1,http://arxiv.org/pdf/2502.14002v1,eess.IV
Analysis and Comparison of Different Wavelet Transform Methods Using   Benchmarks for Image Fusion,T Deepika,"In recent years, many research achievements are made in the medical image fusion field. Medical Image fusion means that several of various modality image information is comprehended together to form one image to express its information. The aim of image fusion is to integrate complementary and redundant information. CT/MRI is one of the most common medical image fusion. These medical modalities give information about different diseases. Complementary information is offered by CT and MRI. CT provides the best information about denser tissue and MRI offers better information on soft tissue. There are two approaches to image fusion, namely Spatial Fusion and Transform fusion. Transform fusion uses transform for representing the source images at multi-scale. This paper presents a Wavelet Transform image fusion methodology based on the intensity magnitudes of the wavelet coefficients and compares five variations of the wavelet transform implemented separately in this fusion model. The image fusion model, using the Discrete Wavelet Transform (DWT), the Stationary Wavelet Transform (SWT), the Integer Lifting Wavelet Transform (ILFT) the dual-tree Complex Wavelet Transform (DT CWT) and dual-tree Q-shift dual-tree CWT, is applied to multi-modal images. The resulting fused images are compared visually and through benchmarks such as Entropy (E), Peak Signal to Noise Ratio, (PSNR), Root Mean Square Error (RMSE), Image Quality Index (IQI) and Standard deviation (SD) computations.",2020-07-22T15:24:54Z,2020-07-22T15:24:54Z,http://arxiv.org/abs/2007.11488v1,http://arxiv.org/pdf/2007.11488v1,eess.IV
Reducing Magnetic Resonance Image Spacing by Learning Without   Ground-Truth,"Kai Xuan, Liping Si, Lichi Zhang, Zhong Xue, Yining Jiao, Weiwu Yao, Dinggang Shen, Dijia Wu, Qian Wang","High-quality magnetic resonance (MR) image, i.e., with near isotropic voxel spacing, is desirable in various scenarios of medical image analysis. However, many MR acquisitions use large inter-slice spacing in clinical practice. In this work, we propose a novel deep-learning-based super-resolution algorithm to generate high-resolution (HR) MR images with small slice spacing from low-resolution (LR) inputs of large slice spacing. Notice that most existing deep-learning-based methods need paired LR and HR images to supervise the training, but in clinical scenarios, usually no HR images will be acquired. Therefore, our unique goal herein is to design and train the super-resolution network with no real HR ground-truth. Specifically, two training stages are used in our method. First, HR images of reduced slice spacing are synthesized from real LR images using variational auto-encoder (VAE). Although these synthesized HR images are as realistic as possible, they may still suffer from unexpected morphing induced by VAE, implying that the synthesized HR images cannot be paired with the real LR images in terms of anatomical structure details. In the second stage, we degrade the synthesized HR images to generate corresponding LR images and train a super-resolution network based on these synthesized HR and degraded LR pairs. The underlying mechanism is that such a super-resolution network is less vulnerable to anatomical variability. Experiments on knee MR images successfully demonstrate the effectiveness of our proposed solution to reduce the slice spacing for better rendering.",2020-03-27T20:30:16Z,2021-08-17T12:47:27Z,http://arxiv.org/abs/2003.12627v2,http://arxiv.org/pdf/2003.12627v2,eess.IV
RAWIW: RAW Image Watermarking Robust to ISP Pipeline,"Kang Fu, Xiaohong Liu, Jun Jia, Zicheng Zhang, Yicong Peng, Jia Wang, Guangtao Zhai","Invisible image watermarking is essential for image copyright protection. Compared to RGB images, RAW format images use a higher dynamic range to capture the radiometric characteristics of the camera sensor, providing greater flexibility in post-processing and retouching. Similar to the master recording in the music industry, RAW images are considered the original format for distribution and image production, thus requiring copyright protection. Existing watermarking methods typically target RGB images, leaving a gap for RAW images. To address this issue, we propose the first deep learning-based RAW Image Watermarking (RAWIW) framework for copyright protection. Unlike RGB image watermarking, our method achieves cross-domain copyright protection. We directly embed copyright information into RAW images, which can be later extracted from the corresponding RGB images generated by different post-processing methods. To achieve end-to-end training of the framework, we integrate a neural network that simulates the ISP pipeline to handle the RAW-to-RGB conversion process. To further validate the generalization of our framework to traditional ISP pipelines and its robustness to transmission distortion, we adopt a distortion network. This network simulates various types of noises introduced during the traditional ISP pipeline and transmission. Furthermore, we employ a three-stage training strategy to strike a balance between robustness and concealment of watermarking. Our extensive experiments demonstrate that RAWIW successfully achieves cross-domain copyright protection for RAW images while maintaining their visual quality and robustness to ISP pipeline distortions.",2023-07-28T09:50:06Z,2023-07-28T09:50:06Z,http://arxiv.org/abs/2307.15443v1,http://arxiv.org/pdf/2307.15443v1,eess.IV
Morphological-consistent Diffusion Network for Ultrasound Coronal Image   Enhancement,"Yihao Zhou, Zixun Huang, Timothy Tin-Yan Lee, Chonglin Wu, Kelly Ka-Lee Lai, De Yang, Alec Lik-hang Hung, Jack Chun-Yiu Cheng, Tsz-Ping Lam, Yong-ping Zheng","Ultrasound curve angle (UCA) measurement provides a radiation-free and reliable evaluation for scoliosis based on ultrasound imaging. However, degraded image quality, especially in difficult-to-image patients, can prevent clinical experts from making confident measurements, even leading to misdiagnosis. In this paper, we propose a multi-stage image enhancement framework that models high-quality image distribution via a diffusion-based model. Specifically, we integrate the underlying morphological information from images taken at different depths of the 3D volume to calibrate the reverse process toward high-quality and high-fidelity image generation. This is achieved through a fusion operation with a learnable tuner module that learns the multi-to-one mapping from multi-depth to high-quality images. Moreover, the separate learning of the high-quality image distribution and the spinal features guarantees the preservation of consistent spinal pose descriptions in the generated images, which is crucial in evaluating spinal deformities. Remarkably, our proposed enhancement algorithm significantly outperforms other enhancement-based methods on ultrasound images in terms of image quality. Ultimately, we conduct the intra-rater and inter-rater measurements of UCA and higher ICC (0.91 and 0.89 for thoracic and lumbar angles) on enhanced images, indicating our method facilitates the measurement of ultrasound curve angles and offers promising prospects for automated scoliosis diagnosis.",2024-09-25T06:44:42Z,2024-09-25T06:44:42Z,http://arxiv.org/abs/2409.16661v1,http://arxiv.org/pdf/2409.16661v1,eess.IV
DeepMB: Deep neural network for real-time optoacoustic image   reconstruction with adjustable speed of sound,"Christoph Dehner, Guillaume Zahnd, Vasilis Ntziachristos, Dominik Jüstel","Multispectral optoacoustic tomography (MSOT) is a high-resolution functional imaging modality that can non-invasively access a broad range of pathophysiological phenomena by quantifying the contrast of endogenous chromophores in tissue. Real-time imaging is imperative to translate MSOT into clinical imaging, visualize dynamic pathophysiological changes associated with disease progression, and enable in situ diagnoses. Model-based reconstruction affords state-of-the-art optoacoustic images; however, the image quality provided by model-based reconstruction remains inaccessible during real-time imaging because the algorithm is iterative and computationally demanding. Deep learning affords faster reconstruction, but the lack of ground truth training data can lead to reduced image quality for in vivo data. We introduce a framework, termed DeepMB, that achieves accurate optoacoustic image reconstruction for arbitrary input data in 31 ms per image by expressing model-based reconstruction with a deep neural network. DeepMB facilitates accurate generalization to experimental test data through training on signals synthesized from real-world images and ground truth images generated by model-based reconstruction. The framework affords in-focus images for a broad range of anatomical locations because it supports dynamic adjustment of the reconstruction speed of sound during imaging. Furthermore, DeepMB is compatible with the data rates and image sizes of modern multispectral optoacoustic tomography scanners. We evaluate DeepMB on a diverse dataset of in vivo images and demonstrate that the framework reconstructs images 1000 times faster than the iterative model-based reference method while affording near-identical image qualities. Accurate and real-time image reconstructions with DeepMB can enable full access to the high-resolution and multispectral contrast of handheld optoacoustic tomography.",2022-06-29T09:20:23Z,2023-04-11T14:56:20Z,http://arxiv.org/abs/2206.14485v4,http://arxiv.org/pdf/2206.14485v4,eess.IV
Development of Focused X-ray Luminescence Compute Tomography Imaging,"Yile Fang, Yibing Zhang, Changqing Li",X-ray luminescence is produced when contrast agents absorb energy from X-ray photons and release a portion of that energy by emitting photons in the visible and near-infrared range. X-ray luminescence computed tomography (XLCT) was introduced in the past decade as a hybrid molecular imaging modality combining the merits of both X-ray imaging (high spatial resolution) and optical imaging (high sensitivity to tracer nanophosphors).,2024-06-11T23:36:00Z,2024-06-11T23:36:00Z,http://arxiv.org/abs/2406.07773v1,http://arxiv.org/pdf/2406.07773v1,eess.IV
Mosaicked multispectral image compression based on inter- and intra-band   correlation,"Kazuma Shinoda, Madoka Hasegawa, Masahiro Yamaguchi, Antonio Ortega","Multispectral imaging has been utilized in many fields, but the cost of capturing and storing image data is still high. Single-sensor cameras with multispectral filter arrays can reduce the cost of capturing images at the expense of slightly lower image quality. When multispectral filter arrays are used, conventional multispectral image compression methods can be applied after interpolation, but the compressed image data after interpolation has some redundancy because the interpolated data are computed from the captured raw data. In this paper, we propose an efficient image compression method for single-sensor multispectral cameras. The proposed method encodes the captured multispectral data before interpolation. We also propose a new spectral transform method for the compression of mosaicked multispectral images. This transform is designed by considering the filter arrangement and the spectral sensitivities of a multispectral filter array. The experimental results show that the proposed method achieves a higher peak signal-to-noise ratio at higher bit rates than a conventional compression method that encodes a multispectral image after interpolation, e.g., 3-dB gain over conventional compression when coding at rates of over 0.1 bit/pixel/bands.",2018-01-10T22:47:02Z,2018-01-10T22:47:02Z,http://arxiv.org/abs/1801.03577v1,http://arxiv.org/pdf/1801.03577v1,eess.IV
Graph Spectral Image Processing,"Gene Cheung, Enrico Magli, Yuichi Tanaka, Michael Ng","Recent advent of graph signal processing (GSP) has spurred intensive studies of signals that live naturally on irregular data kernels described by graphs (e.g., social networks, wireless sensor networks). Though a digital image contains pixels that reside on a regularly sampled 2D grid, if one can design an appropriate underlying graph connecting pixels with weights that reflect the image structure, then one can interpret the image (or image patch) as a signal on a graph, and apply GSP tools for processing and analysis of the signal in graph spectral domain. In this article, we overview recent graph spectral techniques in GSP specifically for image / video processing. The topics covered include image compression, image restoration, image filtering and image segmentation.",2018-01-15T11:45:29Z,2018-01-16T11:00:06Z,http://arxiv.org/abs/1801.04749v2,http://arxiv.org/pdf/1801.04749v2,"eess.IV, eess.SP"
A new focal-plane 3D imaging method based on temporal ghost imaging,"Zunwang Bo, Wenlin Gong, Shensheng Han","A new focal-plane three-dimensional (3D) imaging method based on temporal ghost imaging is proposed and demonstrated. By exploiting the advantages of temporal ghost imaging, this method enables slow integrating cameras have an ability of 3D surface imaging in the framework of sequential flood-illumination and focal-plane detection. The depth information of 3D objects is easily lost when imaging with traditional cameras, but it can be reconstructed with high-resolution by temporal correlation between received signals and reference signals. Combining with a two-dimensional (2D) projection image obtained by one single shot, a 3D image of the object can be achieved. The feasibility and performance of this focal-plane 3D imaging method have been verified through theoretical analysis and numerical experiments in this paper.",2018-05-04T09:36:44Z,2018-05-04T09:36:44Z,http://arxiv.org/abs/1805.06481v1,http://arxiv.org/pdf/1805.06481v1,eess.IV
Robust Image Identification for Double-Compressed and Resized JPEG   Images,"Kenta Iida, Hitoshi Kiya","In the case that images are shared via social networking services (SNS) and cloud photo sharing services (CPSS), it is known that the JPEG images uploaded to the services are often re-compressed and resized by the providers. Because of such a situation, a new image identification scheme for double-compressed JPEG images having different sizes from that of a singled-compressed one is proposed in this paper. The aim is to detect a single-compressed image that has the same original image as the double-compressed ones, even when the sizes of those compressed images are different. In the proposed scheme, a feature extracted from only DC coefficients in DCT coefficients is used for the identification. The use of the feature allows us not only to robustly avoid errors caused by double-compression but also to perform the identification for different size images. The simulation results demonstrate the effectiveness of the proposed one in terms of the querying performance.",2018-09-02T07:33:42Z,2018-09-02T07:33:42Z,http://arxiv.org/abs/1809.00305v1,http://arxiv.org/pdf/1809.00305v1,eess.IV
Saliency Prediction for Omnidirectional Images Considering Optimization   on Sphere Domain,"Bhishma Dedhia, Jui-Chiu Chiang, Yi-Fan Char","There are several formats to describe the omnidirectional images. Among them, equirectangular projection (ERP), represented as 2D image, is the most widely used format. There exist many outstanding methods capable of well predicting the saliency maps for the conventional 2D images. But these works cannot be directly extended to predict the saliency map of the ERP image, since the content on ERP is not for direct display. Instead, the viewport image on demand is generated after converting the ERP image to the sphere domain, followed by rectilinear projection. In this paper, we propose a model to predict the saliency maps of the ERP images using existing saliency predictors for the 2D image. Some pre-processing and post-processing are used to manage the problem mentioned above. In particular, a smoothing based optimization is realized on the sphere domain. A public dataset of omnidirectional images is used to perform all the experiments and competitive results are achieved.",2019-03-04T17:22:11Z,2019-03-04T17:22:11Z,http://arxiv.org/abs/1903.01380v1,http://arxiv.org/pdf/1903.01380v1,eess.IV
Total Variation and Tight Frame Image Segmentation with Intensity   Inhomogeneity,"Raymond Chan, Hongfei Yang, Tieyong Zeng","Image segmentation is an important task in the domain of computer vision and medical imaging. In natural and medical images, intensity inhomogeneity, i.e. the varying image intensity, occurs often and it poses considerable challenges for image segmentation. In this paper, we propose an efficient variational method for segmenting images with intensity inhomogeneity. The method is inspired by previous works on two-stage segmentation and variational Retinex. Our method consists of two stages. In the first stage, we decouple the image into reflection and illumination parts by solving a convex energy minimization model with either total variation or tight-frame regularisation. In the second stage, we segment the original image by thresholding on the reflection part, and the inhomogeneous intensity is estimated by the smoothly varying illumination part. We adopt a primal dual algorithm to solve the convex model in the first stage, and the convergence is guaranteed. Numerical experiments clearly show that our method is robust and efficient to segment both natural and medical images.",2019-04-03T04:25:04Z,2019-04-03T04:25:04Z,http://arxiv.org/abs/1904.01760v1,http://arxiv.org/pdf/1904.01760v1,eess.IV
Hue-Correction Scheme Considering Non-Linear Camera Response for   Multi-Exposure Image Fusion,"Kouki Seo, Chihiro Go, Yuma Kinoshita, Hitoshi Kiya","We propose a novel hue-correction scheme for multi-exposure image fusion (MEF). Various MEF methods have so far been studied to generate higher-quality images. However, there are few MEF methods considering hue distortion unlike other fields of image processing, due to a lack of a reference image that has correct hue. In the proposed scheme, we generate an HDR image as a reference for hue correction, from input multi-exposure images. After that, hue distortion in images fused by an MEF method is removed by using hue information of the HDR one, on the basis of the constant-hue plane in the RGB color space. In simulations, the proposed scheme is demonstrated to be effective to correct hue-distortion caused by conventional MEF methods. Experimental results also show that the proposed scheme can generate high-quality images, regardless of exposure conditions of input multi-exposure images.",2020-07-18T14:40:49Z,2020-07-18T14:40:49Z,http://arxiv.org/abs/2007.10802v1,http://arxiv.org/pdf/2007.10802v1,eess.IV
Reducing Randomness of Non-Regular Sampling Masks for Image   Reconstruction,"Markus Jonscher, Jürgen Seiler, Thomas Richter, André Kaup","Increasing spatial image resolution is an often required, yet challenging task in image acquisition. Recently, it has been shown that it is possible to obtain a high resolution image by covering a low resolution sensor with a non-regular sampling mask. Due to the masking, however, some pixel information in the resulting high resolution image is not available and has to be reconstructed by an efficient image reconstruction algorithm in order to get a fully reconstructed high resolution image. In this paper, the influence of different sampling masks with a reduced randomness of the non-regularity on the image reconstruction process is evaluated. Simulation results show that it is sufficient to use sampling masks that are non-regular only on a smaller scale. These sampling masks lead to a visually noticeable gain in PSNR compared to arbitrary chosen sampling masks which are non-regular over the whole image sensor size. At the same time, they simplify the manufacturing process and allow for efficient storage.",2022-04-07T15:51:33Z,2022-04-07T15:51:33Z,http://arxiv.org/abs/2204.04065v1,http://arxiv.org/pdf/2204.04065v1,eess.IV
Model-Based Photoacoustic Image Reconstruction using Compressed Sensing   and Smoothed L0 Norm,"Moein Mozaffarzadeh, Ali Mahloojifar, Mohammadreza Nasiriavanaki, Mahdi Orooji","Photoacoustic imaging (PAI) is a novel medical imaging modality that uses the advantages of the spatial resolution of ultrasound imaging and the high contrast of pure optical imaging. Analytical algorithms are usually employed to reconstruct the photoacoustic (PA) images as a result of their simple implementation. However, they provide a low accurate image. Model-based (MB) algorithms are used to improve the image quality and accuracy while a large number of transducers and data acquisition are needed. In this paper, we have combined the theory of compressed sensing (CS) with MB algorithms to reduce the number of transducer. Smoothed version of L0-norm (SL0) was proposed as the reconstruction method, and it was compared with simple iterative reconstruction (IR) and basis pursuit. The results show that S$\ell_0$ provides a higher image quality in comparison with other methods while a low number of transducers were. Quantitative comparison demonstrates that, at the same condition, the SL0 leads to a peak-signal-to-noise ratio for about two times of the basis pursuit.",2018-02-26T14:22:19Z,2018-02-26T14:22:19Z,http://arxiv.org/abs/1802.09313v1,http://arxiv.org/pdf/1802.09313v1,eess.SP
Low-Cost Implementation of Bilinear and Bicubic Image Interpolation for   Real-Time Image Super-Resolution,"Donya Khaledyan, Abdolah Amirany, Kian Jafari, Mohammad Hossein Moaiyeri, Abolfazl Zargari Khuzani, Najmeh Mashhadi","Super-resolution imaging (S.R.) is a series of techniques that enhance the resolution of an imaging system, especially in surveillance cameras where simplicity and low cost are of great importance. S.R. image reconstruction can be viewed as a three-stage process: image interpolation, image registration, and fusion. Image interpolation is one of the most critical steps in the S.R. algorithms and has a significant influence on the quality of the output image. In this paper, two hardware-efficient interpolation methods are proposed for these platforms, mainly for the mobile application. Experiments and results on the synthetic and real image sequences clearly validate the performance of the proposed scheme. They indicate that the proposed approach is practically applicable to real-world applications. The algorithms are implemented in a Field Programmable Gate Array (FPGA) device using a pipelined architecture. The implementation results show the advantages of the proposed methods regarding area, performance, and output quality.",2020-09-21T05:45:58Z,2020-09-21T05:45:58Z,http://arxiv.org/abs/2009.09622v1,http://arxiv.org/pdf/2009.09622v1,eess.IV
Manipulation Detection in Satellite Images Using Vision Transformer,"János Horváth, Sriram Baireddy, Hanxiang Hao, Daniel Mas Montserrat, Edward J. Delp","A growing number of commercial satellite companies provide easily accessible satellite imagery. Overhead imagery is used by numerous industries including agriculture, forestry, natural disaster analysis, and meteorology. Satellite images, just as any other images, can be tampered with image manipulation tools. Manipulation detection methods created for images captured by ""consumer cameras"" tend to fail when used on satellite images due to the differences in image sensors, image acquisition, and processing. In this paper we propose an unsupervised technique that uses a Vision Transformer to detect spliced areas within satellite images. We introduce a new dataset which includes manipulated satellite images that contain spliced objects. We show that our proposed approach performs better than existing unsupervised splicing detection techniques.",2021-05-13T16:04:16Z,2021-05-13T16:04:16Z,http://arxiv.org/abs/2105.06373v1,http://arxiv.org/pdf/2105.06373v1,eess.IV
An Unsupervised Optical Flow Estimation For LiDAR Image Sequences,"Xuezhou Guo, Xuhu Lin, Lili Zhao, Zezhi Zhu, Jianwen Chen","In recent years, the LiDAR images, as a 2D compact representation of 3D LiDAR point clouds, are widely applied in various tasks, e.g., 3D semantic segmentation, LiDAR point cloud compression (PCC). Among these works, the optical flow estimation for LiDAR image sequences has become a key issue, especially for the motion estimation of the inter prediction in PCC. However, the existing optical flow estimation models are likely to be unreliable for LiDAR images. In this work, we first propose a light-weight flow estimation model for LiDAR image sequences. The key novelty of our method lies in two aspects. One is that for the different characteristics (with the spatial-variation feature distribution) of the LiDAR images w.r.t. the normal color images, we introduce the attention mechanism into our model to improve the quality of the estimated flow. The other one is that to tackle the lack of large-scale LiDAR-image annotations, we present an unsupervised method, which directly minimizes the inconsistency between the reference image and the reconstructed image based on the estimated optical flow. Extensive experimental results have shown that our proposed model outperforms other mainstream models on the KITTI dataset, with much fewer parameters.",2021-05-28T14:42:20Z,2021-05-28T14:42:20Z,http://arxiv.org/abs/2105.13879v1,http://arxiv.org/pdf/2105.13879v1,eess.IV
Self-supervised Enhanced Radar Imaging Based on Deep-Learning-Assisted   Compressed Sensing,Shaoyin Huang,"Traditional radar imaging methods suffer from the problems of low resolution and poor noise suppression. We propose a new radar imaging method based on Self-supervised deep-learning-assisted compressed sensing (SS-DL-CS-Net). The original radar image as the input of net. The net is trained to learn the mapping function between the original radar image and the high quality radar image. However, the high quality radar image cant be obtained. We solve this problem by used the sparsity of radar image. The original radar image and image with the zeros value as the reference of net. Ours net dont need a lot of data to train. Real radar data are used to evaluate the performance of the proposed method. The experimental results demonstrate the superiority of the proposed method",2022-08-08T04:19:44Z,2022-08-08T04:19:44Z,http://arxiv.org/abs/2208.03911v1,http://arxiv.org/pdf/2208.03911v1,eess.IV
Modulating human brain responses via optimal natural image selection and   synthetic image generation,"Zijin Gu, Keith Jamison, Mert R. Sabuncu, Amy Kuceyeski","Understanding how human brains interpret and process information is important. Here, we investigated the selectivity and inter-individual differences in human brain responses to images via functional MRI. In our first experiment, we found that images predicted to achieve maximal activations using a group level encoding model evoke higher responses than images predicted to achieve average activations, and the activation gain is positively associated with the encoding model accuracy. Furthermore, aTLfaces and FBA1 had higher activation in response to maximal synthetic images compared to maximal natural images. In our second experiment, we found that synthetic images derived using a personalized encoding model elicited higher responses compared to synthetic images from group-level or other subjects' encoding models. The finding of aTLfaces favoring synthetic images than natural images was also replicated. Our results indicate the possibility of using data-driven and generative approaches to modulate macro-scale brain region responses and probe inter-individual differences in and functional specialization of the human visual system.",2023-04-18T18:25:26Z,2023-04-18T18:25:26Z,http://arxiv.org/abs/2304.09225v1,http://arxiv.org/pdf/2304.09225v1,q-bio.QM
High-precision terahertz frequency modulated continuous wave imaging   method using continuous wavelet transform,Yu Zhou,"Inspired by the extensive application of terahertz imaging technologies in the field of aerospace, we exploit a terahertz frequency modulated continuous wave imaging method with continuous wavelet transform algorithm to detect a multilayer heat shield made of special materials. This method uses the frequency modulation continuous wave system to catch the reflected terahertz signal and then processing the image data by the continuous wavelet transform with different basis functions. By calculating the sizes of the defects area in the final images and then comparing the results with real samples, a novel and practical high-precision terahertz imaging method are demonstrated. Our method can be an effective tool for the terahertz nondestructive testing of composites, drugs and some cultural heritages.",2019-05-28T06:34:34Z,2019-05-28T06:34:34Z,http://arxiv.org/abs/1905.12437v1,http://arxiv.org/pdf/1905.12437v1,"eess.SP, eess.IV"
EDIZ: An Error Diffusion Image Zooming Scheme,"Soroush Saryazdi, Saman Saryazdi, Hossein Nezamabadi-pour","Interpolation based image zooming methods provide a high execution speed and low computational complexity. However, the quality of the zoomed images is unsatisfactory in many cases. The main challenge of super- resolution methods is to create new details to the image. This paper proposes a new algorithm to create new details using a zoom-out-zoom-in strategy. This strategy permits reducing blurring effects by adding the estimated error to the final image. Experimental results for natural images confirm the algorithm's ability to create visually pleasing results.",2017-12-03T23:42:10Z,2017-12-03T23:42:10Z,http://arxiv.org/abs/1712.00855v1,http://arxiv.org/pdf/1712.00855v1,eess.IV
"Optics-free imaging of complex, non-sparse QR-codes with Deep Neural   Networks","Evan Scullion, Soren Nelson, Rajesh Menon","We demonstrate optics-free imaging of complex QR-codes using a bare image sensor and a trained artificial neural network (ANN). The ANN is trained to interpret the raw sensor data for human visualization. The image sensor is placed at a specified gap from the QR code. We studied the robustness of our approach by experimentally testing the output of the ANNs with system perturbations of this gap, and the translational and rotational alignments of the QR code to the image sensor. Our demonstration opens us the possibility of using completely optics-free cameras for application-specific imaging of complex, non-sparse objects.",2020-02-25T19:03:52Z,2020-02-25T19:03:52Z,http://arxiv.org/abs/2002.11141v1,http://arxiv.org/pdf/2002.11141v1,eess.IV
Determining JPEG Image Standard Quality Factor from the Quantization   Tables,Rémi Cogranne,"Identifying the quality factor of JPEG images is very useful for applications in digital image forensics. Though several command-line tools exist and are used in widely used software such as \emph{GIMP} (GNU Image Manipulation Program), the well-known image editing software, or the \emph{ImageMagick} suite, we have found that those may provide inaccurate or even wrong results. This paper presents a simple method for determining the exact quality factor of a JPEG image from its quantization tables. The method is presented briefly and a sample program, written in Unix/Linux Shell bash language is provided.",2018-02-03T15:48:43Z,2018-02-03T15:48:43Z,http://arxiv.org/abs/1802.00992v1,http://arxiv.org/pdf/1802.00992v1,eess.IV
"Sensitivity of BPA SAR Image Formation to Initial Position, Velocity,   and Attitude Navigation Errors","Colton Lindstrom, Randall Christensen, Jacob Gunther","The Back-Projection Algorithm (BPA) is a time domain matched filtering technique to form synthetic aperture radar (SAR) images. To produce high quality BPA images, precise navigation data for the radar platform must be known. Any error in position, velocity, or attitude results in improperly formed images corrupted by shifting, blurring, and distortion. This paper develops analytical expressions that characterize the relationship between navigation errors and image formation errors. These analytical expressions are verified via simulated image formation and real data image formation.",2020-09-21T23:00:09Z,2020-09-21T23:00:09Z,http://arxiv.org/abs/2009.10210v1,http://arxiv.org/pdf/2009.10210v1,eess.SP
Non-Semantic Evaluation of Image Forensics Tools: Methodology and   Database,"Quentin Bammey, Tina Nikoukhah, Marina Gardella, Rafael Grompone, Miguel Colom, Jean-Michel Morel","With the aim of evaluating image forensics tools, we propose a methodology to create forgeries traces, leaving intact the semantics of the image. Thus, the only forgery cues left are the specific alterations of one or several aspects of the image formation pipeline. This methodology creates automatically forged images that are challenging to detect for forensic tools and overcomes the problem of creating convincing semantic forgeries. Based on this methodology, we create the Trace database and conduct an evaluation of the main state-of-the-art image forensics tools.",2021-05-04T07:28:53Z,2021-05-04T07:28:53Z,http://arxiv.org/abs/2105.02700v1,http://arxiv.org/pdf/2105.02700v1,"eess.IV, eess.SP"
Opening the Black Box of Learned Image Coders,"Zhihao Duan, Ming Lu, Zhan Ma, Fengqing Zhu","End-to-end learned lossy image coders (LICs), as opposed to hand-crafted image codecs, have shown increasing superiority in terms of the rate-distortion performance. However, they are mainly treated as black-box systems and their interpretability is not well studied. In this paper, we show that LICs learn a set of basis functions to transform input image for its compact representation in the latent space, as analogous to the orthogonal transforms used in image coding standards. Our analysis provides insights to help understand how learned image coders work and could benefit future design and development.",2022-02-26T18:29:56Z,2022-10-14T20:43:08Z,http://arxiv.org/abs/2202.13209v2,http://arxiv.org/pdf/2202.13209v2,eess.IV
Adapting CSI-Guided Imaging Across Diverse Environments: An Experimental   Study Leveraging Continuous Learning,"Cheng Chen, Shoki Ohta, Takayuki Nishio, Mohamed Wahib","This study explores the feasibility of adapting CSI-guided imaging across varied environments. Focusing on continuous model learning through continuous updates, we investigate CSI-Imager's adaptability in dynamically changing settings, specifically transitioning from an office to an industrial environment. Unlike traditional approaches that may require retraining for new environments, our experimental study aims to validate the potential of CSI-guided imaging to maintain accurate imaging performance through Continuous Learning (CL). By conducting experiments across different scenarios and settings, this work contributes to understanding the limitations and capabilities of existing CSI-guided imaging systems in adapting to new environmental contexts.",2024-04-01T06:26:48Z,2024-04-01T06:26:48Z,http://arxiv.org/abs/2404.00951v1,http://arxiv.org/pdf/2404.00951v1,eess.IV
Intensity-Sensitive Similarity Indexes for Image Quality Assessment,"X. Li, W. Armour","The importance of Image quality assessment (IQA) is ever increasing due to the fast paced advances in imaging technology and computer vision. Among the numerous IQA methods, Structural SIMilarity (SSIM) index and its variants are better matched to the perceived quality of the human visual system. However, SSIM methods are insufficiently sensitive, when images contain low information, where the important information only occupies a low proportion of the image while most of the image is noise-like, which is common in scientific data. Therefore, we propose two new IQA methods, InTensity Weighted SSIM index and Low-Information Similarity Index, for such low information images. In addition, auxiliary indexes are proposed to assist with the assessment. The application of these new IQA methods to natural images and field-specific images, such as radio astronomical images, medical images, and remote sensing images, are also demonstrated. The results show that our IQA methods perform better than state-of-the-art SSIM methods for differences in high-intensity parts of the input images and have similar performance to that of the original and gradient-based SSIM for differences in low-intensity parts. Different similarity indexes are suitable for different applications, which we demonstrate in our results.",2022-06-22T16:51:22Z,2022-12-03T22:37:20Z,http://arxiv.org/abs/2206.11207v2,http://arxiv.org/pdf/2206.11207v2,eess.IV
Grating lobe reduction in plane wave imaging with angular compounding   using subtraction of coherent signals,"Zhengchang Kou, Rita J. Miller, Michael L. Oelze","Plane wave imaging (PWI) with angular compounding has gained in popularity over recent years because it provides high frame rates and good image properties. However, most linear arrays used in clinical practice have a pitch that is equal to than the wavelength of ultrasound. Hence, the presence of grating lobes is a concern for PWI using multiple transmit angles. The presence of grating lobes produces clutter in images and reduces the ability to observe tissue contrast. Techniques to reduce or eliminate the presence of grating lobes for PWI using multiple angles will result in improved image quality. Null subtraction imaging (NSI) is a nonlinear beamforming technique that has been explored for improving the lateral resolution of ultrasonic imaging. However, the apodization scheme used in NSI also eliminates or greatly reduces the presence of grating lobes. Imaging tasks using NSI were evaluated in simulations and physical experiments involving tissue-mimicking phantoms and rat tumors in vivo. Images created with NSI were compared with images created using traditional delay and sum (DAS) with Hann apodization and images created using a generalized coherence factor (GCF). NSI was observed to greatly reduce the presence of grating lobes in ultrasonic images, compared to DAS with Hann and GCF, while maintaining spatial resolution and contrast in the images. Therefore, NSI can provide a novel means of creating images using PWI with multiple steering angles on clinically available linear arrays while reducing the adverse effects associated with grating lobes.",2022-10-24T18:56:04Z,2022-10-24T18:56:04Z,http://arxiv.org/abs/2210.13546v1,http://arxiv.org/pdf/2210.13546v1,eess.SP
DELTA-MRI: Direct deformation Estimation from LongiTudinally Acquired   k-space data,"Jens Renders, Banafshe Shafieizargar, Marleen Verhoye, Jan De Beenhouwer, Arnold J. den Dekker, Jan Sijbers","Longitudinal MRI is an important diagnostic imaging tool for evaluating the effects of treatment and monitoring disease progression. However, MRI, and particularly longitudinal MRI, is known to be time consuming. To accelerate imaging, compressed sensing (CS) theory has been applied to exploit sparsity, both on single image as on image sequence level. State-of-the-art CS methods however, are generally focused on image reconstruction, and consider analysis (e.g., alignment, change detection) as a post-processing step.   In this study, we propose DELTA-MRI, a novel framework to estimate longitudinal image changes {\it directly} from a reference image and subsequently acquired, strongly sub-sampled MRI k-space data. In contrast to state-of-the-art longitudinal CS based imaging, our method avoids the conventional multi-step process of image reconstruction of subsequent images, image alignment, and deformation vector field computation. Instead, the set of follow-up images, along with motion and deformation vector fields that describe their relation to the reference image, are estimated in one go. Experiments show that DELTA-MRI performs significantly better than the state-of-the-art in terms of the normalized reconstruction error.",2023-01-23T14:25:16Z,2023-01-23T14:25:16Z,http://arxiv.org/abs/2301.09455v1,http://arxiv.org/pdf/2301.09455v1,eess.IV
SAR Target Image Generation Method Using Azimuth-Controllable Generative   Adversarial Network,"Chenwei Wang, Jifang Pei, Xiaoyu Liu, Yulin Huang, Deqing Mao, Yin Zhang, Jianyu Yang","Sufficient synthetic aperture radar (SAR) target images are very important for the development of researches. However, available SAR target images are often limited in practice, which hinders the progress of SAR application. In this paper, we propose an azimuth-controllable generative adversarial network to generate precise SAR target images with an intermediate azimuth between two given SAR images' azimuths. This network mainly contains three parts: generator, discriminator, and predictor. Through the proposed specific network structure, the generator can extract and fuse the optimal target features from two input SAR target images to generate SAR target image. Then a similarity discriminator and an azimuth predictor are designed. The similarity discriminator can differentiate the generated SAR target images from the real SAR images to ensure the accuracy of the generated, while the azimuth predictor measures the difference of azimuth between the generated and the desired to ensure the azimuth controllability of the generated. Therefore, the proposed network can generate precise SAR images, and their azimuths can be controlled well by the inputs of the deep network, which can generate the target images in different azimuths to solve the small sample problem to some degree and benefit the researches of SAR images. Extensive experimental results show the superiority of the proposed method in azimuth controllability and accuracy of SAR target image generation.",2023-08-10T10:34:51Z,2023-08-10T10:34:51Z,http://arxiv.org/abs/2308.05489v1,http://arxiv.org/pdf/2308.05489v1,eess.IV
Active millimeter wave three-dimensional scan real-time imaging   mechanism with a line antenna array,"Yang Yu, Lingbo Qiao, Yingxin Wang, Ziran Zhao","Active Millimeter wave (AMMW) imaging is of interest as it has played important roles in wide variety of applications, from nondestructive test to medical diagnosis. Current AMMW imaging systems have a high spatial resolution and can realize three-dimensional (3D) imaging. However, conventional AMMW imaging systems based on the synthetic aperture require either time-consume acquisition or reconstruction. The AMMW imaging systems based on real-aperture are able to real-time imaging but they need a large aperture and a complex two-dimensional (2D) scan structure to get 3D images. Besides, most AMMW imaging systems need the targets keep still and hold a special posture while screening, limiting the throughput. Here, by using beam control techniques and fast post-processing algorithms, we demonstrate the AMMW 3D scan real-time imaging mechanism with a line antenna array, which can realize 3D real-time imaging by a simple one-dimensional (1D) linear moving, simultaneously, with a satisfactory throughput (over 2000 people per-hour, 10 times than the commercial AMMW imaging systems) and a low system cost. First, the original spherical beam lines generated by the linear antenna array are modulated to fan beam lines via a bi-convex cylindrical lens. Then the holographic imaging algorithm is used to primarily focus the echo data of the imaged object. Finally, the defocus blur is corrected rapidly to get high resolution images by deconvolution. Since our method does not need targets to keep still, has a low system cost, can achieve 3D real-time imaging with a satisfactory throughput simultaneously, this work has the potential to serve as a foundation for future short-range AMMW imaging systems, which can be used in a variety of fields such as security inspection, medical diagnosis, etc.",2021-02-08T15:06:45Z,2021-02-08T15:06:45Z,http://arxiv.org/abs/2102.04878v1,http://arxiv.org/pdf/2102.04878v1,eess.IV
Predicting Encoded Picture Quality in Two Steps is a Better Way,"Xiangxu Yu, Christos G. Bampis, Praful Gupta, Alan C. Bovik","Full-reference (FR) image quality assessment (IQA) models assume a high quality ""pristine"" image as a reference against which to measure perceptual image quality. In many applications, however, the assumption that the reference image is of high quality may be untrue, leading to incorrect perceptual quality predictions. To address this, we propose a new two-step image quality prediction approach which integrates both no-reference (NR) and full-reference perceptual quality measurements into the quality prediction process. The no-reference module accounts for the possibly imperfect quality of the source (reference) image, while the full-reference component measures the quality differences between the source image and its possibly further distorted version. A simple, yet very efficient, multiplication step fuses the two sources of information into a reliable objective prediction score. We evaluated our two-step approach on a recently designed subjective image database and achieved standout performance compared to full-reference approaches, especially when the reference images were of low quality. The proposed approach is made publicly available at https://github.com/xiangxuyu/2stepQA",2018-01-06T14:01:05Z,2018-02-09T18:44:11Z,http://arxiv.org/abs/1801.02016v2,http://arxiv.org/pdf/1801.02016v2,eess.IV
Error-Control-Coding Assisted Imaging,"Xiaopeng Wang, Zunwang Bo, Zihuai Lin, Wenlin Gong, Branka Vucetic, Shensheng Han","Error-control-coding (ECC) techniques are widely used in modern digital communication systems to minimize the effect of noisy channels on the quality of received signals. Motivated by the fact that both communication and imaging can be considered as an information transfer process, in this paper we demonstrate that ECC could yield significant improvements in the image quality by reducing the effect of noise in the physical process of image acquisition. In the demonstrated approach, the object is encoded by ECC structured light fields generated by a digital-micromirror-device (DMD) while its image is obtained by decoding the received signal collected by a bucket-detector (BD). By applying a Luby Transform (LT) code as an example, our proof-of-concept experiment validates that the object image can be effectively reconstructed while errors induced by noisy reception can be significantly reduced. The demonstrated approach informs a new imaging technique: ECC assisted imaging, which can be scaled into applications such as remote sensing, spectroscopy and biomedical imaging.",2018-09-18T09:33:09Z,2018-09-18T09:33:09Z,http://arxiv.org/abs/1809.06853v1,http://arxiv.org/pdf/1809.06853v1,eess.IV
Analog Beamforming for Active Imaging using Sparse Arrays,"Robin Rajamäki, Sundeep Prabhakar Chepuri, Visa Koivunen","This paper studies analog beamforming in active sensing applications, such as millimeter-wave radar or ultrasound imaging. Analog beamforming architectures employ a single RF-IF chain connected to all array elements via inexpensive phase shifters. This can drastically lower costs compared to fully-digital beamformers having a dedicated RF-IF chain for each sensor. However, controlling only the element phases may lead to elevated side-lobe levels and degraded image quality. We address this issue by image addition, which synthesizes a high resolution image by adding together several lower resolution component images. Image addition also facilitates the use of sparse arrays, which can further reduce array costs. To limit the image acquisition time, we formulate an optimization problem for minimizing the number of component images, subject to achieving a desired point spread function. We propose a gradient descent algorithm for finding a locally optimal solution to this problem. We also derive an upper bound on the number of component images needed for achieving the traditional fully-digital beamformer solution.",2019-06-21T06:23:50Z,2019-06-21T06:23:50Z,http://arxiv.org/abs/1906.08970v1,http://arxiv.org/pdf/1906.08970v1,eess.SP
Bone marrow sparing for cervical cancer radiotherapy on multimodality   medical images,"Yuening Wang, Ying Sun, Jie Yuan, Kexin Gan, Hanzi Xu, Han Gao, Xiuming Zhang","Cervical cancer threatens the health of women seriously. Radiotherapy is one of the main therapy methods but with high risk of acute hematologic toxicity. Delineating the bone marrow (BM) for sparing using computer tomography (CT) images to plan before radiotherapy can effectively avoid this risk. Comparing with magnetic resonance (MR) images, CT lacks the ability to express the activity of BM. Thus, in current clinical practice, medical practitioners manually delineate the BM on CT images by corresponding to MR images. However, the time?consuming delineating BM by hand cannot guarantee the accuracy due to the inconsistency of the CT-MR multimodal images. In this study, we propose a multimodal image oriented automatic registration method for pelvic BM sparing, which consists of three-dimensional bone point cloud reconstruction, a local spherical system iteration closest point registration for marking BM on CT images. Experiments on patient dataset reveal that our proposed method can enhance the multimodal image registration accuracy and efficiency for medical practitioners in sparing BM of cervical cancer radiotherapy. The method proposed in this contribution might also provide references for similar studies in other clinical application.",2022-04-20T07:40:01Z,2022-04-20T07:40:01Z,http://arxiv.org/abs/2204.09278v1,http://arxiv.org/pdf/2204.09278v1,eess.IV
"On Random-Matrix Bases, Ghost Imaging and X-ray Phase Contrast   Computational Ghost Imaging","David Ceddia, David M. Paganin","A theory of random-matrix bases is presented, including expressions for orthogonality, completeness and the random-matrix synthesis of arbitrary matrices. This is applied to ghost imaging as the realization of a random-basis reconstruction, including an expression for the resulting signal-to-noise ratio. Analysis of conventional direct imaging and ghost imaging leads to a criterion which, when satisfied, implies reduced dose for computational ghost imaging. We also propose an experiment for x-ray phase contrast computational ghost imaging, which enables differential phase contrast to be achieved in an x-ray ghost imaging context. We give a numerically robust solution to the associated inverse problem of decoding differential phase contrast x-ray ghost images, to yield a quantitative map of the projected thickness of the sample.",2018-02-12T02:56:30Z,2018-04-27T04:55:10Z,http://arxiv.org/abs/1802.04258v2,http://arxiv.org/pdf/1802.04258v2,eess.IV
Real-time Image Enhancement for Vision-based Autonomous Underwater   Vehicle Navigation in Murky Waters,"Wenjie Chen, Mehdi Rahmati, Vidyasagar Sadhu, Dario Pompili","Classic vision-based navigation solutions, which are utilized in algorithms such as Simultaneous Localization and Mapping (SLAM), usually fail to work underwater when the water is murky and the quality of the recorded images is low. That is because most SLAM algorithms are feature-based techniques and often it is impossible to extract the matched features from blurry underwater images. To get more useful features, image processing techniques can be used to dehaze the images before they are used in a navigation/localization algorithm. There are many well-developed methods for image restoration, but the degree of enhancement and the resource cost of the methods are different. In this paper, we propose a new visual SLAM, specifically-designed for the underwater environment, using Generative Adversarial Networks (GANs) to enhance the quality of underwater images with underwater image quality evaluation metrics. This procedure increases the efficiency of SLAM and gets a better navigation and localization accuracy. We evaluate the proposed GANs-SLAM combination by using different images with various levels of turbidity in the water. Experiments were conducted and the data was extracted from the Carnegie Lake in Princeton, and the Raritan river both in New Jersey, USA.",2019-11-11T05:13:01Z,2019-11-11T05:13:01Z,http://arxiv.org/abs/1911.04080v1,http://arxiv.org/pdf/1911.04080v1,eess.IV
Fish Detection Using Morphological Approach Based-on K-Means   Segmentation,"Shoffan Saifullah, Andiko Putro Suryotomo, Bambang Yuwono","Image segmentation is a concept that is often used for object detection. This detection has difficulty detecting objects with backgrounds that have many colors and even have a color similar to the object being detected. This study aims to detect fish using segmentation, namely segmenting fish images using k-means clustering. The segmentation process is processed by improving the image first. The initial process is preprocessing to improve the image. Preprocessing is done twice, before segmentation using k-means and after. Preprocessing stage 1 using resize and reshape. Whereas after k-means is the contrast-limited adaptive histogram equalization. Preprocessing results are segmented using k-means clustering. The K-means concept classifies images using segments between the object and the background (using k = 8). The final step is the morphological process with open and close operations to obtain fish contours using black and white images based on grayscale images from color images. Based on the experimental results, the process can run well, with the ssim value close to 1, which means that image information does not change. Processed objects provide a clear picture of fish objects so that this k-means segmentation can help detect fish objects.",2021-01-16T02:37:16Z,2021-01-16T02:37:16Z,http://arxiv.org/abs/2101.06352v1,http://arxiv.org/pdf/2101.06352v1,eess.IV
Multi-Feature Fusion-based Scene Classification Framework for HSR Images,Zhengrui Huang,"To realize high-accuracy classification of high spatial resolution (HSR) images, this letter proposes a new multi-feature fusion-based scene classification framework (MF2SCF) by fusing local, global, and color features of HSR images. Specifically, we first extract the local features with the help of image slicing and densely connected convolutional networks (DenseNet), where the outputs of dense blocks in the fine-tuned DenseNet-121 model are jointly averaged and concatenated to describe local features. Second, from the perspective of complex networks (CN), we model a HSR image as an undirected graph based on pixel distance, intensity, and gradient, and obtain a gray-scale image (GSI), a gradient of image (GoI), and three CN-based feature images to delineate global features. To make the global feature descriptor resist to the impact of rotation and illumination, we apply uniform local binary patterns (LBP) on GSI, GoI, and feature images, respectively, and generate the final global feature representation by concatenating spatial histograms. Third, the color features are determined based on the normalized HSV histogram, where HSV stands for hue, saturation, and value, respectively. Finally, three feature vectors are jointly concatenated for scene classification. Experiment results show that MF2SCF significantly improves the classification accuracy compared with state-of-the-art LBP-based methods and deep learning-based methods.",2021-05-22T16:28:18Z,2021-05-22T16:28:18Z,http://arxiv.org/abs/2105.10758v1,http://arxiv.org/pdf/2105.10758v1,eess.IV
A Multi-scale Video Denoising Algorithm for Raw Image,"Bin Ma, Yueli Hu, Xianxian Lv, Kai Li","Video denoising for raw image has always been the difficulty of camera image processing. On the one hand, image denoising performance largely determines the image quality, moreover denoising effect in raw image will affect the accuracy of the following operations of ISP processing flow. On the other hand, compared with image, video have motion information in time sequence, thus motion estimation which is complex and computationally expensive is needed in video denoising. In view of the above problems, this paper proposes a video denoising algorithm for raw image, performing multiple cascading processing stages on raw-RGB image based on convolutional neural network, and carries out implicit motion estimation in the network. The denoising performance is far superior to that of traditional algorithms with minimal computation and bandwidth, and has computational advantages compared with most deep learning algorithms.",2022-09-05T03:19:58Z,2022-09-05T03:19:58Z,http://arxiv.org/abs/2209.01740v1,http://arxiv.org/pdf/2209.01740v1,eess.IV
Adaptive CSI Feedback for Deep Learning-Enabled Image Transmission,"Guangyi Zhang, Qiyu Hu, Yunlong Cai, Guanding Yu","Recently, deep learning-enabled joint-source channel coding (JSCC) has received increasing attention due to its great success in image transmission. However, most existing JSCC studies only focus on single-input single-output (SISO) channels. In this paper, we first propose a JSCC system for wireless image transmission over multiple-input multiple-output (MIMO) channels. As the complexity of an image determines its reconstruction difficulty, the JSCC achieves quite different reconstruction performances on different images. Moreover, we observe that the images with higher reconstruction qualities are generally more robust to the noise, and can be allocated with less communication resources than the images with lower reconstruction qualities. Based on this observation, we propose an adaptive channel state information (CSI) feedback scheme for precoding, which improves the effectiveness by adjusting the feedback overhead. In particular, we develop a performance evaluator to predict the reconstruction quality of each image, so that the proposed scheme can adaptively decrease the CSI feedback overhead for the transmitted images with high predicted reconstruction qualities in the JSCC system. We perform experiments to demonstrate that the proposed scheme can significantly improve the image transmission performance with much-reduced feedback overhead.",2023-02-27T02:24:25Z,2023-02-27T02:24:25Z,http://arxiv.org/abs/2302.13477v1,http://arxiv.org/pdf/2302.13477v1,eess.SP
Image Blending with Osmosis,"Paul Bungert, Pascal Peter, Joachim Weickert","Image blending is an integral part of many multi-image applications such as panorama stitching or remote image acquisition processes. In such scenarios, multiple images are connected at predefined boundaries to form a larger image. A convincing transition between these boundaries may be challenging, since each image might have been acquired under different conditions or even by different devices.   We propose the first blending approach based on osmosis filters. These drift-diffusion processes define an image evolution with a non-trivial steady state. For our blending purposes, we explore several ways to compose drift vector fields based on the derivatives of our input images. These vector fields guide the evolution such that the steady state yields a convincing blended result. Our method benefits from the well-founded theoretical results for osmosis, which include useful invariances under multiplicative changes of the colour values. Experiments on real-world data show that this yields better quality than traditional gradient domain blending, especially under challenging illumination conditions.",2023-03-14T10:08:16Z,2023-05-10T15:26:48Z,http://arxiv.org/abs/2303.07762v3,http://arxiv.org/pdf/2303.07762v3,eess.IV
Semantic-Aware Image Compressed Sensing,"Bowen Zhang, Zhijin Qin, Geoffrey Ye Li","Deep learning based image compressed sensing (CS) has achieved great success. However, existing CS systems mainly adopt a fixed measurement matrix to images, ignoring the fact the optimal measurement numbers and bases are different for different images. To further improve the sensing efficiency, we propose a novel semantic-aware image CS system. In our system, the encoder first uses a fixed number of base CS measurements to sense different images. According to the base CS results, the encoder then employs a policy network to analyze the semantic information in images and determines the measurement matrix for different image areas. At the decoder side, a semantic-aware initial reconstruction network is developed to deal with the changes of measurement matrices used at the encoder. A rate-distortion training loss is further introduced to dynamically adjust the average compression ratio for the semantic-aware CS system and the policy network is trained jointly with the encoder and the decoder in an en-to-end manner by using some proxy functions. Numerical results show that the proposed semantic-aware image CS system is superior to the traditional ones with fixed measurement matrices.",2023-07-06T18:32:50Z,2023-07-11T02:09:12Z,http://arxiv.org/abs/2307.03246v2,http://arxiv.org/pdf/2307.03246v2,eess.IV
Secure Control of Networked Inverted Pendulum Visual Servo System with   Adverse Effects of Image Computation (Extended Version),"Dajun Du, Changda Zhang, Qianjiang Lu, Minrui Fei, Huiyu Zhou","When visual image information is transmitted via communication networks, it easily suffers from image attacks, leading to system performance degradation or even crash. This paper investigates secure control of networked inverted pendulum visual servo system (NIPVSS) with adverse effects of image computation. Firstly, the image security limitation of the traditional NIPVSS is revealed, where its stability will be destroyed by eavesdropping-based image attacks. Then, a new NIPVSS with the fast scaled-selective image encryption (F2SIE) algorithm is proposed, which not only meets the real-time requirement by reducing the computational complexity, but also improve the security by reducing the probability of valuable information being compromised by eavesdropping-based image attacks. Secondly, adverse effects of the F2SIE algorithm and image attacks are analysed, which will produce extra computational delay and errors. Then, a closed-loop uncertain time-delay model of the new NIPVSS is established, and a robust controller is designed to guarantee system asymptotic stability. Finally, experimental results of the new NIPVSS demonstrate the feasibility and effectiveness of the proposed method.",2023-09-07T08:37:50Z,2023-09-07T08:37:50Z,http://arxiv.org/abs/2309.03556v1,http://arxiv.org/pdf/2309.03556v1,eess.IV
Joint Sparse Representations and Coupled Dictionary Learning in   Multi-Source Heterogeneous Image Pseudo-color Fusion,"Long Bai, Shilong Yao, Kun Gao, Yanjun Huang, Ruijie Tang, Hong Yan, Max Q. -H. Meng, Hongliang Ren","Considering that Coupled Dictionary Learning (CDL) method can obtain a reasonable linear mathematical relationship between resource images, we propose a novel CDL-based Synthetic Aperture Radar (SAR) and multispectral pseudo-color fusion method. Firstly, the traditional Brovey transform is employed as a pre-processing method on the paired SAR and multispectral images. Then, CDL is used to capture the correlation between the pre-processed image pairs based on the dictionaries generated from the source images via enforced joint sparse coding. Afterward, the joint sparse representation in the pair of dictionaries is utilized to construct an image mask via calculating the reconstruction errors, and therefore generate the final fusion image. The experimental verification results of the SAR images from the Sentinel-1 satellite and the multispectral images from the Landsat-8 satellite show that the proposed method can achieve superior visual effects, and excellent quantitative performance in terms of spectral distortion, correlation coefficient, MSE, NIQE, BRISQUE, and PIQE.",2023-10-15T20:04:57Z,2023-10-15T20:04:57Z,http://arxiv.org/abs/2310.09937v1,http://arxiv.org/pdf/2310.09937v1,"eess.IV, eess.SP"
Using Diffusion Models to Generate Synthetic Labelled Data for Medical   Image Segmentation,"Daniel Saragih, Atsuhiro Hibi, Pascal Tyrrell","Medical image analysis has become a prominent area where machine learning has been applied. However, high quality, publicly available data is limited either due to patient privacy laws or the time and cost required for experts to annotate images. In this retrospective study, we designed and evaluated a pipeline to generate synthetic labeled polyp images for augmenting medical image segmentation models with the aim of reducing this data scarcity. In particular, we trained diffusion models on the HyperKvasir dataset, comprising 1000 images of polyps in the human GI tract from 2008 to 2016. Qualitative expert review, Fr\'echet Inception Distance (FID), and Multi-Scale Structural Similarity (MS-SSIM) were tested for evaluation. Additionally, various segmentation models were trained with the generated data and evaluated using Dice score and Intersection over Union. We found that our pipeline produced images more akin to real polyp images based on FID scores, and segmentation performance also showed improvements over GAN methods when trained entirely, or partially, with synthetic data, despite requiring less compute for training. Moreover, the improvement persists when tested on different datasets, showcasing the transferability of the generated images.",2023-10-25T17:24:38Z,2024-05-09T22:53:10Z,http://arxiv.org/abs/2310.16794v2,http://arxiv.org/pdf/2310.16794v2,eess.IV
Wireless Regional Imaging through Reconfigurable Intelligent Surfaces:   Passive Mode,"Fuhai Wang, Chun Wang, Rujing Xiong, Zhengyu Wang, Tiebin Mi, Robert Caiming Qiu","In this paper, we propose a multi-RIS-aided wireless imaging framework in 3D facing the distributed placement of multi-sensor networks. The system creates a randomized reflection pattern by adjusting the RIS phase shift, enabling the receiver to capture signals within the designated space of interest (SoI). Firstly, a multi-RIS-aided linear imaging channel modeling is proposed. We introduce a theoretical framework of computational imaging to recover the signal strength distribution of the SOI. For the RIS-aided imaging system, the impact of multiple parameters on the performance of the imaging system is analyzed. The simulation results verify the correctness of the proposal. Furthermore, we propose an amplitude-only imaging algorithm for the RIS-aided imaging system to mitigate the problem of phase unpredictability. Finally, the performance verification of the imaging algorithm is carried out by proof of concept experiments under reasonable parameter settings.",2023-11-19T04:30:40Z,2023-11-19T04:30:40Z,http://arxiv.org/abs/2311.11222v1,http://arxiv.org/pdf/2311.11222v1,eess.IV
Deep convolutional demosaicking network for multispectral polarization   filter array,"Tomoharu Ishiuchi, Kazuma Shinoda","To address the demosaicking problem in multispectral polarization filter array (MSPFA) imaging, we propose a multispectral polarization demosaicking network (MSPDNet) that improves image reconstruction accuracy. Imaging with a multispectral polarization filter array acquires multispectral polarization information in a snapshot. The full-resolution multispectral polarization image must be reconstructed from a mosaic image. In the proposed method, a sparse image in which pixel values of the same channel are extracted from a mosaic image is used as input to MSPDNet. Missing pixels are interpolated by learning spatial and wavelength correlations from the observed pixels in the mosaic image. Moreover, by using 3D convolution, features are extracted at each convolution layer, and by deepening the network, even detailed features of the multispectral polarization image can be learned. Experimental results show that MSPDNet can reconstruct multi-wavelength and multi-polarization angle information with high accuracy in terms of peak signal-to-noise ratio (PSNR) evaluation and visual quality, indicating the effectiveness of the proposed method compared to other methods.",2024-06-08T01:08:41Z,2024-10-16T04:14:09Z,http://arxiv.org/abs/2406.05312v2,http://arxiv.org/pdf/2406.05312v2,eess.IV
DD_RoTIR: Dual-Domain Image Registration via Image Translation and   Hierarchical Feature-matching,"Ruixiong Wang, Stephen Cross, Alin Achim","Microscopy images obtained from multiple camera lenses or sensors in biological experiments provide a comprehensive understanding of objects from diverse perspectives. However, using multiple microscope setups increases the risk of misalignment of identical target features across different modalities, making multimodal image registration crucial. In this work, we build upon previous successes in biological image translation (XAcGAN) and mono-modal image registration (RoTIR) to develop a deep learning model, Dual-Domain RoTIR (DD_RoTIR), specifically designed to address these challenges. While GAN-based translation models are often considered inadequate for multimodal image registration, we enhance registration accuracy by employing a feature-matching algorithm based on Transformers and rotation equivariant networks. Additionally, hierarchical feature matching is utilized to tackle the complexities of multimodal image registration. Our results demonstrate that the DD_RoTIR model exhibits strong applicability and robustness across multiple microscopy image datasets.",2024-07-15T20:19:44Z,2024-07-17T10:15:12Z,http://arxiv.org/abs/2407.11223v2,http://arxiv.org/pdf/2407.11223v2,eess.IV
Enhancing digital core image resolution using optimal upscaling   algorithm: with application to paired SEM images,"Shaohua You, Shuqi Sun, Zhengting Yan, Qinzhuo Liao, Huiying Tang, Lianhe Sun, Gensheng Li","The porous media community extensively utilizes digital rock images for core analysis. High-resolution digital rock images that possess sufficient quality are essential but often challenging to acquire. Super-resolution (SR) approaches enhance the resolution of digital rock images and provide improved visualization of fine features and structures, aiding in the analysis and interpretation of rock properties, such as pore connectivity and mineral distribution. However, there is a current shortage of real paired microscopic images for super-resolution training. In this study, we used two types of Scanning Electron Microscopes (SEM) to obtain the images of shale samples in five regions, with 1X, 2X, 4X, 8X and 16X magnifications. We used these real scanned paired images as a reference to select the optimal method of image generation and validated it using Enhanced Deep Super Resolution (EDSR) and Very Deep Super Resolution (VDSR) methods. Our experiments show that the bilinear algorithm is more suitable than the commonly used bicubic method, for establishing low-resolution datasets in the SR approaches, which is partially attributed to the mechanism of Scanning Electron Microscopes (SEM).",2024-09-05T06:19:14Z,2024-09-05T06:19:14Z,http://arxiv.org/abs/2409.03265v1,http://arxiv.org/pdf/2409.03265v1,eess.IV
Liver Segmentation from Multimodal Images using HED-Mask R-CNN,"Supriti Mulay, Deepika G, Jeevakala S, Keerthi Ram, Mohanasankar Sivaprakasam","Precise segmentation of the liver is critical for computer-aided diagnosis such as pre-evaluation of the liver for living donor-based transplantation surgery. This task is challenging due to the weak boundaries of organs, countless anatomical variations, and the complexity of the background. Computed tomography (CT) scanning and magnetic resonance imaging (MRI) images have different parameters and settings. Thus, images acquired from different modalities differ from one another making liver segmentation challenging task. We propose an efficient liver segmentation with the combination of holistically-nested edge detection (HED) and the Mask-region-convolutional neural network (R-CNN) to address these challenges. The proposed HED-Mask R-CNN approach is based on effective identification of edge maps from multimodal images. The proposed system firstly applies a preprocessing step of image enhancement to get the 'primal sketches' of the abdomen. Then the HED network is applied to enhanced CT and MRI modality images to get a better edge map. Finally, the Mask R-CNN is used to segment the liver from edge map images. We used a dataset of 20 CT patients and 9 MR patients from the CHAOS challenge. The system is trained on CT and MRI images separately and then converted to 2D slices. We significantly improved the segmentation accuracy of CT and MRI images on a database with a Dice value of 0.94 for CT, 0.89 for T2-weighted MRI and 0.91 for T1-weighted MRI.",2019-10-23T12:04:45Z,2019-10-23T12:04:45Z,http://arxiv.org/abs/1910.10504v1,http://arxiv.org/pdf/1910.10504v1,eess.IV
Image Denoising by Random Interpolation Average with Low-Rank Matrix   Approximation,"Qi Liu, Wing-Shan Tam, Chi-Wah Kok, Hing Cheung So","With the wide deployment of digital image capturing equipment, the need of denoising to produce a crystal clear image from noisy capture environment has become indispensable. This work presents a novel image denoising method that can tackle both impulsive noise, such as salt and pepper noise (SAPN), and additive white Gaussian noise (AWGN), such as hot carrier noise from CMOS sensor, at the same time. We propose to use low-rank matrix approximation to form the basic denoising framework, as it has the advantage of preserving the spatial integrity of the image. To mitigate the SAPN, the original noise corrupted image is randomly sampled to produce sampled image sets. Low-rank matrix factorization method (LRMF) via alternating minimization denoising method is applied to all sampled images, and the resultant images are fused together via a wavelet fusion with hard threshold denoising. Since the sampled image sets have independent but identical noise property, the wavelet fusion serves as the effective mean to remove the AWGN, while the LRMF method suppress the SAPN. Simulation results are presented which vividly show the denoised images obtained by the proposed method can achieve crystal clear image with strong structural integrity and showing good performance in both subjective and objective metrics.",2019-12-23T08:06:20Z,2019-12-23T08:06:20Z,http://arxiv.org/abs/1912.10669v1,http://arxiv.org/pdf/1912.10669v1,eess.IV
Effective Super-Resolution Method for Paired Electron Microscopic Images,"Yanjun Qian, Jiaxi Xu, Lawrence F. Drummy, Yu Ding","This paper is concerned with investigating super-resolution algorithms and solutions for handling electron microscopic images. We note two main aspects differentiating the problem discussed here from those considered in the literature. The first difference is that in the electron imaging setting. We have a pair of physical high-resolution and low-resolution images, rather than a physical image with its downsampled counterpart. The high-resolution image covers about 25% of the view field of the low-resolution image, and the objective is to enhance the area of the low-resolution image where there is no high-resolution counterpart. The second difference is that the physics behind electron imaging is different from that of optical (visible light) photos. The implication is that super-resolution models trained by optical photos are not effective when applied to electron images. Focusing on the unique properties, we devise a global and local registration method to match the high- and low-resolution image patches and explore training strategies for applying deep learning super-resolution methods to the paired electron images. We also present a simple, non-local-mean approach as an alternative. This alternative performs as a close runner-up to the deep learning approaches, but it takes less time to train and entertains a simpler model structure.",2019-07-23T19:21:21Z,2020-06-29T14:58:34Z,http://arxiv.org/abs/1907.10105v4,http://arxiv.org/pdf/1907.10105v4,eess.IV
Low dose SPECT image denoising using a generative adversarial network,"Qi Zhang, Jingzhang Sun, Greta S. P. Mok","The image noise level and resolution of SPECT images are relatively poor attributed to the limited number of detected counts and various physical degradation factors during acquisitions. This study aims to apply and evaluate the use of generative adversarial network (GAN) method in static SPECT image denoising. A population of 4D extended cardiac-torso (XCAT) phantoms were used to simulate 10 male and female patients with different organ sizes and activity uptakes. An analytical projector was applied to simulate 120 projections from right anterior oblique to left posterior oblique positions with two noise levels. The first noise level was based on a standard clinical count rate of 987 MBq injection and 16 min acquisition (low noise) while the other was 1/8 of the previous count rate (high noise). The high noise and low noise SPECT reconstructed images of 9 patients, i.e., 1026 images (9*114 axial slices) respectively, were paired for training. High noise SPECT images of 1 patient were tested using the trained GAN. The noise level is substantially reduced in high noise SPECT reconstructed images after using the GAN. Our method has the potential to decrease the noise level of SPECT images, which could be traded for a reduced injection dose or acquisition time while still maintaining the similar image quality as compared to the original low noise images for clinical diagnosis.",2019-07-27T16:18:52Z,2019-07-27T16:18:52Z,http://arxiv.org/abs/1907.11944v1,http://arxiv.org/pdf/1907.11944v1,eess.IV
Time of arrival imaging: The proof of concept for a novel medical   imaging modality,Tao Feng,"It has been shown that with the use of ultra-wideband (UWB) electromagnetic signal and time of arrival (ToA) principle, it is possible to locate medical implants given the permittivity distribution of the body. We propose a new imaging modality using the reverse process to acquire permittivity distributions as a surrogate of human anatomy. In the proposed systems, the locations of the signal source, receiver, and signal shapes are assumed to be known exactly. The measured data is recorded as the time it takes for the signal to travel from the signal source to the signal receiver. The finite-difference-time-domain (FDTD) method is used for the modeling of signal propagation within the phantom, which is used for both simulation and image reconstruction. Image reconstruction is achieved using linear regression on the training pairs, which includes randomly generated images and its corresponding arrival times generated using the FDTD approach. The linear weights of the training images are generated to minimize the difference between the arrival time of the reconstruction image and the measured arrival time. A simulation study using UWB signal with the central frequency of 300 MHz and the Shepp-Logan phantom was carried out. Ten-picosecond timing resolution is used for the simulation and image reconstruction. The quantitative difference between the arrival times of the phantom and the reconstructed image reduced with an increased iteration number. The quantitative error of the reconstructed image reached below 10% after 900 iterations, and 8.4% after 1200 iterations. With additional post-smoothing to suppress the introduced noise pattern through reconstruction, 6.5% error was achieved. In this paper, an approach that utilizes the ToA principle to achieve transmission imaging with radio waves is proposed and validated using a simulation study.",2020-02-28T23:52:13Z,2020-02-28T23:52:13Z,http://arxiv.org/abs/2003.00127v1,http://arxiv.org/pdf/2003.00127v1,eess.IV
Early Detection of Retinopathy of Prematurity stage using Deep Learning   approach,"Supriti Mulay, Keerthi Ram, Mohanasankar Sivaprakasam, Anand Vinekar","Retinopathy of Prematurity (ROP) is a fibrovascular proliferative disorder, which affects the developing peripheral retinal vasculature of premature infants. Early detection of ROP is possible in stage 1 and stage 2 characterized by demarcation line and ridge with width, which separates vascularised retina and the peripheral retina. To detect demarcation line/ ridge from neonatal retinal images is a complex task because of low contrast images. In this paper we focus on detection of ridge, the important landmark in ROP diagnosis, using Convolutional Neural Network(CNN). Our contribution is to use a CNN-based model Mask R-CNN for demarcation line/ridge detection allowing clinicians to detect ROP stage 2 better. The proposed system applies a pre-processing step of image enhancement to overcome poor image quality. In this study we use labelled neonatal images and we explore the use of CNN to localize ridge in these images. We used a dataset of 220 images of 45 babies from the KIDROP project. The system was trained on 175 retinal images with ground truth segmentation of ridge region. The system was tested on 45 images and reached detection accuracy of 0.88, showing that deep learning detection with pre-processing by image normalization allows robust detection of ROP in early stages.",2021-09-03T11:09:07Z,2021-09-03T11:09:07Z,http://arxiv.org/abs/2109.01442v1,http://arxiv.org/pdf/2109.01442v1,eess.IV
Actuated Reflector-Based Three-dimensional Ultrasound Imaging with   Adaptive-Delay Synthetic Aperture Focusing,"Yichuan Tang, Ryosuke Tsumura, Jakub T. Kaminski, Haichong K. Zhang","Three-dimensional (3D) ultrasound (US) imaging addresses the limitation in field-of-view (FOV) in conventional two-dimensional (2D) US imaging by providing 3D viewing of the anatomy. 3D US imaging has been extensively adapted for diagnosis and image-guided surgical intervention. However, conventional approaches to implement 3D US imaging require either expensive and sophisticated 2D array transducers, or external actuation mechanisms to move a one-dimensional array mechanically. Here, we propose a 3D US imaging mechanism using actuated acoustic reflector instead of the sensor elements for volume acquisition with significantly extended 3D FOV, which can be implemented with simple hardware and compact size. To improve image quality on the elevation plane, we introduce an adaptive-delay synthetic aperture focusing (AD-SAF) method for elevation beamforming. We first evaluated the proposed imaging mechanism and AD-SAF with simulated point targets and cysts targets. Results of point targets suggested improved image quality on the elevation plane, and results of cysts targets demonstrated a potential to improve 3D visualization of human anatomy. We built a prototype imaging system that has a 3D FOV of 38 mm (lateral) by 38 mm (elevation) by 50 mm (axial) and collected data in imaging experiments with phantoms. Experimental data showed consistency with simulation results. The AD-SAF method enhanced quantifying the cyst volume size in the breast mimicking phantom compared to without elevation beamforming. These results suggested that the proposed 3D US imaging mechanism could potentially be applied in clinical scenarios.",2021-12-13T18:27:17Z,2021-12-13T18:27:17Z,http://arxiv.org/abs/2112.06866v1,http://arxiv.org/pdf/2112.06866v1,eess.SP
De-speckling of Optical Coherence Tomography Images Using Anscombe   Transform and a Noisier2noise Model,"Arka Saha, Sourya Sengupta","Optical Coherence Tomography (OCT) image denoising is a fundamental problem as OCT images suffer from multiplicative speckle noise, resulting in poor visibility of retinal layers. The traditional denoising methods consider specific statistical properties of the noise, which are not always known. Furthermore, recent deep learning-based denoising methods require paired noisy and clean images, which are often difficult to obtain, especially medical images. Noise2Noise family architectures are generally proposed to overcome this issue by learning without noisy-clean image pairs. However, for that, multiple noisy observations from a single image are typically needed. Also, sometimes the experiments are demonstrated by simulating noises on clean synthetic images, which is not a realistic scenario. This work shows how a single real-world noisy observation of each image can be used to train a denoising network. Along with a theoretical understanding, our algorithm is experimentally validated using a publicly available OCT image dataset. Our approach incorporates Anscombe transform to convert the multiplicative noise model to additive Gaussian noise to make it suitable for OCT images. The quantitative results show that this method can outperform several other methods where a single noisy observation of an image is needed for denoising. The code and implementation of this paper will be available publicly upon acceptance of this paper.",2022-09-20T16:14:31Z,2022-09-20T16:14:31Z,http://arxiv.org/abs/2209.09825v1,http://arxiv.org/pdf/2209.09825v1,eess.IV
From Nano to Macro: Overview of the IEEE Bio Image and Signal Processing   Technical Committee,"Selin Aviyente, Alejandro Frangi, Erik Meijering, Arrate Muñoz-Barrutia, Michael Liebling, Dimitri Van De Ville, Jean-Christophe Olivo-Marin, Jelena Kovačević, Michael Unser","The Bio Image and Signal Processing (BISP) Technical Committee (TC) of the IEEE Signal Processing Society (SPS) promotes activities within the broad technical field of biomedical image and signal processing. Areas of interest include medical and biological imaging, digital pathology, molecular imaging, microscopy, and associated computational imaging, image analysis, and image-guided treatment, alongside physiological signal processing, computational biology, and bioinformatics. BISP has 40 members and covers a wide range of EDICS, including CIS-MI: Medical Imaging, BIO-MIA: Medical Image Analysis, BIO-BI: Biological Imaging, BIO: Biomedical Signal Processing, BIO-BCI: Brain/Human-Computer Interfaces, and BIO-INFR: Bioinformatics. BISP plays a central role in the organization of the IEEE International Symposium on Biomedical Imaging (ISBI) and contributes to the technical sessions at the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), and the IEEE International Conference on Image Processing (ICIP). In this paper, we provide a brief history of the TC, review the technological and methodological contributions its community delivered, and highlight promising new directions we anticipate.",2022-10-31T14:12:11Z,2023-01-23T11:14:26Z,http://arxiv.org/abs/2210.17346v2,http://arxiv.org/pdf/2210.17346v2,"eess.SP, q-bio.QM"
Color Image steganography using Deep convolutional Autoencoders based on   ResNet architecture,"Seyed Hesam Odin Hashemi, Mohammad-Hassan Majidi, Saeed Khorashadizadeh","In this paper, a deep learning color image steganography scheme combining convolutional autoencoders and ResNet architecture is proposed. Traditional steganography methods suffer from some critical defects such as low capacity, security, and robustness. In recent decades, image hiding and image extraction were realized by autoencoder convolutional neural networks to solve the aforementioned challenges. The contribution of this paper is introducing a new scheme for color image steganography inspired by ResNet architecture. The reverse ResNet architecture is utilized to extract the secret image from the stego image. In the proposed method, all images are passed through the prepossess model which is a convolutional deep neural network with the aim of feature extraction. Then, the operational model generates stego and extracted images. In fact, the operational model is an autoencoder based on ResNet structure that produces an image from feature maps. The advantage of proposed structure is identity of models in embedding and extraction phases. The performance of the proposed method is studied using COCO and CelebA datasets. For quantitative comparisons with previous related works, peak signal-to-noise ratio (PSNR), the structural similarity index (SSIM) and hiding capacity are evaluated. The experimental results verify that the proposed scheme performs better than traditional and pervious deep steganography methods. The PSNR and SSIM are more than 40 dB and 0.98, respectively that implies high imperceptibility of the proposed method. Also, this method can hide a color image of the same size in another color image, which can be inferred that the relative capacity of the proposed method is 8 bits per pixel.",2022-11-17T08:39:47Z,2022-11-17T08:39:47Z,http://arxiv.org/abs/2211.09409v1,http://arxiv.org/pdf/2211.09409v1,"eess.IV, eess.SP"
VEDA: Uneven light image enhancement via a vision-based exploratory data   analysis model,"Tian Pu, Shuhang Wang, Zhenming Peng, Qingsong Zhu","Uneven light image enhancement is a highly demanded task in many industrial image processing applications. Many existing enhancement methods using physical lighting models or deep-learning techniques often lead to unnatural results. This is mainly because: 1) the assumptions and priors made by the physical lighting model (PLM) based approaches are often violated in most natural scenes, and 2) the training datasets or loss functions used by deep-learning technique based methods cannot handle the various lighting scenarios in the real world well. In this paper, we propose a novel vision-based exploratory data analysis model (VEDA) for uneven light image enhancement. Our method is conceptually simple yet effective. A given image is first decomposed into a contrast image that preserves most of the perceptually important scene details, and a residual image that preserves the lighting variations. After achieving this decomposition at multiple scales using a retinal model that simulates the neuron response to light, the enhanced result at each scale can be obtained by manipulating the two images and recombining them. Then, a weighted averaging strategy based on the residual image is designed to obtain the output image by combining enhanced results at multiple scales. A similar weighting strategy can also be leveraged to reconcile noise suppression and detail preservation. Extensive experiments on different image datasets demonstrate that the proposed method can achieve competitive results in its simplicity and effectiveness compared with state-of-the-art methods. It does not require any explicit assumptions and priors about the scene imaging process, nor iteratively solving any optimization functions or any learning procedures.",2023-05-25T14:01:48Z,2023-05-25T14:01:48Z,http://arxiv.org/abs/2305.16072v1,http://arxiv.org/pdf/2305.16072v1,eess.IV
A Plug-and-Play Untrained Neural Network for Full Waveform Inversion in   Reconstructing Sound Speed Images of Ultrasound Computed Tomography,"Weicheng Yan, Qiude Zhang, Yun Wu, Zhaohui Liu, Liang Zhou, Mingyue Ding, Ming Yuchi, Wu Qiu","Ultrasound computed tomography (USCT), as an emerging technology, can provide multiple quantitative parametric images of human tissue, such as sound speed and attenuation images, distinguishing it from conventional B-mode (reflection) ultrasound imaging. Full waveform inversion (FWI) is acknowledged as a technique with the greatest potential for reconstructing high-resolution sound speed images in USCT. However, traditional FWI for sound speed image reconstruction suffers from high sensitivity to the initial model caused by its strong non-convex nonlinearity, resulting in poor performance when ultrasound signals are at high frequencies. This limitation significantly restricts the application of FWI in the USCT imaging field. In this paper, we propose an untrained neural network (UNN) that can be integrated into the traditional iteration-based FWI framework as an implicit regularization prior. This integration allows for seamless deployment as a plug-and-play module within existing FWI algorithms or their variants. Notably, the proposed UNN method can be trained in an unsupervised fashion, a vital aspect in medical imaging where ground truth data is often unavailable. Evaluations of the numerical simulation and phantom experiment of the breast demonstrate that the proposed UNN improves the robustness of image reconstruction, reduces image artifacts, and achieves great image contrast. To the best of our knowledge, this study represents the first attempt to propose an implicit UNN for FWI in reconstructing sound speed images for USCT.",2024-06-12T06:29:28Z,2024-06-14T02:29:53Z,http://arxiv.org/abs/2406.08523v2,http://arxiv.org/pdf/2406.08523v2,eess.IV
A Diffuse Light Field Imaging Model for Forward-Scattering Photon-Coded   Signal Retrieval,"Hongkun Cao, Xin Jin, Junjie Wei, Yihui Fan, Dongyu Du","Scattering imaging is often hindered by extremely low signal-to-noise ratios (SNRs) due to the prevalence of scattering noise. Light field imaging has been shown to be effective in suppressing noise and collect more ballistic photons as signals. However, to overcome the SNR limit in super-strong scattering environments, even with light field framework, only rare ballistic signals are insufficient. Inspired by radiative transfer theory, we propose a diffuse light field imaging model (DLIM) that leverages light field imaging to retrieve forward-scattered photons as signals to overcome the challenges of low-SNR imaging caused by super-strong scattering environments. This model aims to recover the ballistic photon signal as a source term from forward-scattered photons based on diffusion equations. The DLIM consists of two main processes: radiance modeling and diffusion light-field approximation. Radiate modeling analyzes the radiance distribution in scattering light field images using a proposed three-plane parameterization, which solves a 4-D radiate kernel describing the impulse function of scattering light field. Then, the scattering light field images synthesize a diffuse source satisfying the diffusion equation governing forward scattering photons, solved under Neumann boundary conditions in imaging space. This is the first physically-aware scattering light field imaging model, extending the conventional light field imaging framework from free space into diffuse space. The extensive experiments confirm that the DLIM can reconstruct the target objects even when scattering light field images are reduced as random noise at extremely low SNRs.",2024-11-10T04:24:39Z,2024-11-10T04:24:39Z,http://arxiv.org/abs/2411.06357v1,http://arxiv.org/pdf/2411.06357v1,eess.IV
Learned Correction Methods for Ultrasound Computed Tomography Imaging   Using Simplified Physics Models,"Luke Lozenski, Hanchen Wang, Fu Li, Mark A. Anastasio, Brendt Wohlberg, Youzuo Lin, Umberto Villa","Ultrasound computed tomography (USCT) is an emerging modality for breast imaging. Image reconstruction methods that incorporate accurate wave physics produce high resolution quantitative images of acoustic properties but are computationally expensive. The use of a simplified linear model in reconstruction reduces computational expense at the cost of reduced accuracy. This work aims to systematically compare different learning approaches for USCT reconstruction utilizing simplified linear models. This work considered various learning approaches to compensate for errors stemming from a linearized wave propagation model: correction in the data and image domains. The resulting image reconstruction methods are systematically assessed, alongside data-driven and model-based methods, in four virtual imaging studies utilizing anatomically realistic numerical phantoms. Image quality was assessed utilizing relative root mean square error (RRMSE), structural similarity index measure (SSIM), and a task-based assessment for tumor detection. Correction in the measurement domain resulted in images with minor visual artifacts and highly accurate task performance. Correction in the image domain demonstrated a heavy bias on training data, resulting in hallucinations, but greater robustness to measurement noise. Combining both forms of correction performed best in terms of RRMSE and SSIM, at the cost of task performance. This work systematically assessed learned reconstruction methods incorporating an approximated physical model for USCT imaging. Results demonstrated the importance of incorporating physics, compared to data-driven methods. Learning a correction in the data domain led to better task performance and robust out-of-distribution generalization compared to correction in the image domain.",2025-02-13T17:59:04Z,2025-02-13T17:59:04Z,http://arxiv.org/abs/2502.09546v1,http://arxiv.org/pdf/2502.09546v1,eess.IV
Image Inpainting by Hyperbolic Selection of Pixels for Two Dimensional   Bicubic Interpolations,"Mehran Motmaen, Majid Mohrekesh, Mojtaba Akbari, Nader Karimi, Shadrokh Samavi","Image inpainting is a restoration process which has numerous applications. Restoring of scanned old images with scratches, or removing objects in images are some of inpainting applications. Different approaches have been used for implementation of inpainting algorithms. Interpolation approaches only consider one direction for this purpose. In this paper we present a new perspective to image inpainting. We consider multiple directions and apply both one-dimensional and two-dimensional bicubic interpolations. Neighboring pixels are selected in a hyperbolic formation to better preserve corner pixels. We compare our work with recent inpainting approaches to show our superior results.",2017-12-30T16:29:38Z,2017-12-30T16:29:38Z,http://arxiv.org/abs/1801.00148v1,http://arxiv.org/pdf/1801.00148v1,eess.IV
Snapshot light-field laryngoscope,"Shuaishuai Zhu, Peng Jin, Rongguang Liang, Liang Gao","The convergence of recent advances in optical fabrication and digital processing yields a new generation of imaging technology: light-field cameras, which bridge the realms of applied mathematics, optics, and high-performance computing. Herein for the first time, we introduce the paradigm of light-field imaging into laryngoscopy. The resultant probe can image the three-dimensional (3D) shape of vocal folds within a single camera exposure. Furthermore, to improve the spatial resolution, we developed an image fusion algorithm, providing a simple solution to a long-standing problem in light-field imaging.",2018-01-24T06:23:25Z,2018-01-24T06:23:25Z,http://arxiv.org/abs/1801.07871v1,http://arxiv.org/pdf/1801.07871v1,eess.IV
Improvements of computational ghost imaging by using Special-Hadamard   patterns,"Jie Hou, Yuan Sun, Wanqing Yang, Ting Lv, Xiaoqian Wang","We introduced a new kind of patterns named Special-Hadamard patterns, which could be used as structured illuminations of computational ghost imaging. Special-Hadamard patterns can get a better image quality than Hadamard patterns in a noisy environment. We can completely reconstruct the original object in a noiseless environment by using Special-Hadamard patterns, and the size of object also can be adjusted arbitrarily, these advantages cannot be achieved by other common patterns. We also performed simulations to compare the results of Special Hadamard patterns with the results of Hadamard patterns. We found Special Hadamard patterns can greatly improve the image quality of computational ghost imaging.",2019-02-12T09:44:48Z,2019-02-12T09:44:48Z,http://arxiv.org/abs/1902.04892v1,http://arxiv.org/pdf/1902.04892v1,eess.IV
Compressive Imaging with Stochastic Spatial Light Modulator,"J. C. Schaake, R. C. Pooser, S. Jesse",We present a stochastic analog spatial light modulator designed for compressive imaging applications. We rely on the unpredictable nature of multi-particle collisions to provide randomization for the particle location. We demonstrate this concept in an optical imaging system using a single-pixel camera. This design can be applied to imaging or spectroscopic systems in which no analog to optical spatial light modulators currently exist or in non-optical lensless imaging systems.,2018-10-19T21:42:20Z,2018-10-19T21:42:20Z,http://arxiv.org/abs/1810.08694v1,http://arxiv.org/pdf/1810.08694v1,eess.IV
Geometry of the EOS(R) Radiographic Scanner,Benjamin Groisser,"The EOS(R) scanner is a radiographic system that captures PA and lateral images in standing posture. The system is widely used in diagnosis and assessment of scoliosis, as it provides a low-dose alternative to traditional X-ray and can capture full-body images. Furthermore, spacial calibration between the two imaging views is implemented in hardware, facilitating 3D reconstruction of imaging targets. In this paper, a brief description of the system is followed by an explanation of the geometric relationship between 3D space and radiographic image space.",2019-04-14T15:39:26Z,2019-04-14T15:39:26Z,http://arxiv.org/abs/1904.06711v1,http://arxiv.org/pdf/1904.06711v1,eess.IV
High-speed Millimeter-wave 5G/6G Image Transmission via Artificial   Intelligence,"Shaolin Liao, Lu Ou","Artificial Intelligence (AI) has been used to jointly optimize a mmWave Compressed Sensing (CS) for high-speed 5G/6G image transmission. Specifically, we have developed a Dictionary Learning Compressed Sensing neural Network (DL-CSNet) to realize three key functionalities: 1) to learn the dictionary basis of the images for transmission; 2) to optimize the Hadamard measurement matrix; and 3) to reconstruct the lossless images with the learned dictionary basis. A 94-GHz prototype has been built and up to one order of image transmission speed increase has been realized for letters ``A"" to ``Z"".",2020-07-07T01:16:20Z,2020-07-07T01:16:20Z,http://arxiv.org/abs/2007.03153v1,http://arxiv.org/pdf/2007.03153v1,eess.IV
Capacitive imaging using fused amplitude and phase information for   improved defect detection,"Silvio Amato, David Hutchins, Xiaokang Yin, Marco Ricci, Stefano Laureti","This paper introduces an improved image processing method usable in capacitive imaging applications. Standard capacitive imaging tends to prefer amplitude-based images over the use of phase due to better signal-to-noise ratios. The new approach exploits the best features of both types of information by combining them to form clearer images, hence improving both defect detection and characterization in non-destructive evaluation. The methodology is demonstrated and optimized using a benchmark sample. Additional experiments on glass fibre composite sample illustrate the advantages of the technique.",2021-03-25T23:04:58Z,2021-03-25T23:04:58Z,http://arxiv.org/abs/2103.14170v1,http://arxiv.org/pdf/2103.14170v1,eess.SP
4Dia: A tool for automated 4D microscope image alignment,"Nimmy S. John, Michelle A. Urman, ChangHwan Lee","Recent advances in microscopy enable three-dimensional live imaging at a high resolution. Long-term live imaging of a multicellular organism requires immobilization of the organism under stable physiological conditions. Despite proper immobilization, challenges remain within live imaging data analysis due to other intrinsic and extrinsic dynamics, which can result in misalignments of an image series over time. 4Dia, an ImageJ/Fiji macro script, aligns 3D timelapse images through Z-stacks as well as over time using any user selected channel. 4Dia can be used for essentially any tissue sample with no limit on the size of Z-stack or the number of timepoints.",2021-11-07T02:39:48Z,2021-11-07T02:39:48Z,http://arxiv.org/abs/2111.03988v1,http://arxiv.org/pdf/2111.03988v1,q-bio.QM
Multimodal Medical Image registration using Discrete Wavelet Transform   and Gaussian Pyramids,"Hina Shakir, S. Talha Ahsan, Nabiha Faisal","In this research paper, authors propose multimodal brain image registration using discrete wavelet transform(DWT) followed by Gaussian pyramids. The reference and target images are decomposed into their LL, LH, HL and LL DWT coefficients and then are processed for image registration using Gaussian pyramids. The image registration is also done using Gaussian pyramids only and wavelets transforms only for comparison. The quality of registration is measured by comparing the maximum MI values used by the three methods and also by comparing their correlation coefficients. Our proposed technique proves to show better results when compared with the other two methods.",2020-09-13T11:05:26Z,2020-09-13T11:05:26Z,http://arxiv.org/abs/2009.05978v1,http://arxiv.org/pdf/2009.05978v1,eess.IV
Estimation of Motion Parameters for Ultrasound Images Using Motion Blur   Invariants,"Barmak Honarvar Shakibaei, Yifan Zhao, John Ahmet Erkoyuncu","The quality of fetal ultrasound images is significantly affected by motion blur while the imaging system requires low motion quality in order to capture accurate data. This can be achieved with a mathematical model of motion blur in time or frequency domain. We propose a new model of linear motion blur in both frequency and moment domain to analyse the invariant features of blur convolution for ultrasound images. Moreover, the model also helps to provide an estimation of motion parameters for blur length and angle. These outcomes might imply great potential of this invariant method in ultrasound imaging application.",2020-09-23T12:53:38Z,2020-09-23T12:53:38Z,http://arxiv.org/abs/2009.11117v1,http://arxiv.org/pdf/2009.11117v1,eess.IV
SAR Image Autofocusing using Wirtinger calculus and Cauchy   regularization,"Zi-Yao Zhang, Odysseas Pappas, Alin Achim","In this paper, an optimization model using Cauchy regularization is proposed for simultaneous SAR image reconstruction and autofocusing. A coordinate descent framework in which the desired image and the phase errors are optimized alternatively is designed to solve the model. For the subproblem of estimating the image, we utilize the techniques of Wirtinger calculus to directly minimize the cost function which involves complex variables. We also utilise a state-of-the-art, sparsity-enforcing Cauchy regularizer. The proposed method is demonstrated to give impressive autofocusing results by conducting experiments on both simulated scene and real SAR image.",2020-12-17T17:29:47Z,2020-12-17T17:29:47Z,http://arxiv.org/abs/2012.09772v1,http://arxiv.org/pdf/2012.09772v1,eess.IV
Generative adversarial network based single pixel imaging,"Ming Zhao, Fengqiang Li, Fengyue Huo, Zhiming Tian","Single pixel imaging can reconstruct two-dimensional images of a scene with only a single-pixel detector. It has been widely used for imaging in non-visible bandwidth (e.g., near-infrared and X-ray) where focal-plane array sensors are challenging to be manufactured. In this paper, we propose a generative adversarial network based reconstruction algorithm for single pixel imaging, which demonstrates efficient reconstruction in 10ms and higher quality. We verify the proposed method with both synthetic and real-world experiments, and demonstrate a good quality of reconstruction of a real-world plaster using a 0.05 sampling rate.",2021-07-11T21:48:35Z,2021-07-11T21:48:35Z,http://arxiv.org/abs/2107.05135v1,http://arxiv.org/pdf/2107.05135v1,eess.IV
Strategies in JPEG compression using Convolutional Neural Network (CNN),Suman Kunwar,"Interests in digital image processing are growing enormously in recent decades. As a result, different data compression techniques have been proposed which are concerned mostly with the minimization of information used for the representation of images. With the advances of deep neural networks, image compression can be achieved to a higher degree. This paper describes an overview of JPEG Compression, Discrete Fourier Transform (DFT), Convolutional Neural Network (CNN), quality metrics to measure the performance of image compression and discuss the advancement of deep learning for image compression mostly focused on JPEG, and suggests that adaptation of model improve the compression.",2021-12-06T03:41:51Z,2021-12-06T03:41:51Z,http://arxiv.org/abs/2112.04500v1,http://arxiv.org/pdf/2112.04500v1,eess.IV
End-to-End Optimization of JPEG-Based Deep Learning Process for Image   Classification,"Siyu Qi, Lahiru D. Chamain, Zhi Ding","Among major deep learning (DL) applications, distributed learning involving image classification require effective image compression codecs deployed on low-cost sensing devices for efficient transmission and storage. Traditional codecs such as JPEG designed for perceptual quality are not configured for DL tasks. This work introduces an integrative end-to-end trainable model for image compression and classification consisting of a JPEG image codec and a DL-based classifier. We demonstrate how this model can optimize the widely deployed JPEG codec settings to improve classification accuracy in consideration of bandwidth constraint. Our tests on CIFAR-100 and ImageNet also demonstrate improved validation accuracy over preset JPEG configuration.",2023-08-10T19:38:41Z,2023-08-10T19:38:41Z,http://arxiv.org/abs/2308.05840v1,http://arxiv.org/pdf/2308.05840v1,eess.IV
Noise2Fast: Fast Self-Supervised Single Image Blind Denoising,"Jason Lequyer, Reuben Philip, Amit Sharma, Laurence Pelletier","In the last several years deep learning based approaches have come to dominate many areas of computer vision, and image denoising is no exception. Neural networks can learn by example to map noisy images to clean images. However, access to noisy/clean or even noisy/noisy image pairs isn't always readily available in the desired domain. Recent approaches have allowed for the denoising of single noisy images without access to any training data aside from that very image. But since they require both training and inference to be carried out on each individual input image, these methods require significant computation time. As such, they are difficult to integrate into automated microscopy pipelines where denoising large datasets is essential but needs to be carried out in a timely manner. Here we present Noise2Fast, a fast single image blind denoiser. Our method is tailored for speed by training on a four-image dataset produced using a unique form of downsampling we refer to as ""checkerboard downsampling"". Noise2Fast is faster than all tested approaches and is more accurate than all except Self2Self, which takes well over 100 times longer to denoise an image. This allows for a combination of speed and flexibility that was not previously attainable using any other method.",2021-08-23T14:47:50Z,2021-08-23T14:47:50Z,http://arxiv.org/abs/2108.10209v1,http://arxiv.org/pdf/2108.10209v1,eess.IV
Reconstruction for Diverging-Wave Imaging Using Deep Convolutional   Neural Networks,"Jingfeng Lu, Fabien Millioz, Damien Garcia, Sebastien Salles, Wanyu Liu, Denis Friboulet","In recent years, diverging-wave (DW) ultrasound imaging has become a very promising methodology for cardiovascular imaging due to its high temporal resolution. However, if they are limited in number, DW transmits provide lower image quality compared with classical focused schemes. A conventional reconstruction approach consists in summing series of ultrasound signals coherently, at the expense of the frame rate. To deal with this limitation, we propose a convolutional neural networks (CNN) architecture for high-quality reconstruction of DW ultrasound images using a small number of transmissions. Given the spatially varying properties of DW images along depth, we adopted the inception model composed of the concatenation of multi-scale convolutional kernels. Incorporating inception modules aims at capturing different image features with multi-scale receptive fields. A mapping between low-quality images and corresponding high-quality compounded reconstruction was learned by training the network using in vitro and in vivo samples. The performance of the proposed approach was evaluated in terms of contrast-to-noise ratio and lateral resolution, and compared with standard compounding method and conventional CNN methods. The results demonstrate that our method could produce high-quality images using only three DWs, yielding an image quality equivalent to the one obtained with standard compounding of 31 DWs and outperforming more conventional CNN architectures in terms of complexity, inference time and image quality.",2019-11-08T18:07:05Z,2020-03-24T14:14:22Z,http://arxiv.org/abs/1911.03416v3,http://arxiv.org/pdf/1911.03416v3,"eess.IV, eess.SP"
AutoBCS: Block-based Image Compressive Sensing with Data-driven   Acquisition and Non-iterative Reconstruction,"Yang Gao, Hongping Gan, Haiwei CHen, Chunyi Liu, Feng Liu","Block compressive sensing is a well-known signal acquisition and reconstruction paradigm with widespread application prospects in science, engineering and cybernetic systems. However, state-of-the-art block-based image compressive sensing (BCS) methods generally suffer from two issues. The sparsifying domain and the sensing matrices widely used for image acquisition are not data-driven, and thus both the features of the image and the relationships among subblock images are ignored. Moreover, doing so requires addressing high-dimensional optimization problems with extensive computational complexity for image reconstruction. In this paper, we provide a deep learning strategy for BCS, called AutoBCS, which takes the prior knowledge of images into account in the acquisition step and establishes a subsequent reconstruction model for performing fast image reconstruction with a low computational cost. More precisely, we present a learning-based sensing matrix (LSM) derived from training data to accomplish image acquisition, thereby capturing and preserving more image characteristics than those captured by existing methods. In particular, the generated LSM is proven to satisfy the theoretical requirements of compressive sensing, such as the so-called restricted isometry property. Additionally, we build a noniterative reconstruction network, which provides an end-to-end BCS reconstruction framework to eliminate blocking artifacts and maximize image reconstruction accuracy, in our AutoBCS architecture. Furthermore, we investigate comprehensive comparison studies with both traditional BCS approaches and newly developed deep learning methods. Compared with these approaches, our AutoBCS framework can not only provide superior performance in terms of image quality metrics (SSIM and PSNR) and visual perception, but also automatically benefit reconstruction speed.",2020-09-30T14:41:04Z,2021-01-28T12:38:32Z,http://arxiv.org/abs/2009.14706v2,http://arxiv.org/pdf/2009.14706v2,eess.SP
Bilateral Spectrum Weighted Total Variation for Noisy-Image   Super-Resolution and Image Denoising,"Kaicong Sun, Sven Simon","In this paper, we propose a regularization technique for noisy-image super-resolution and image denoising. Total variation (TV) regularization is adopted in many image processing applications to preserve the local smoothness. However, TV prior is prone to oversmoothness, staircasing effect, and contrast losses. Nonlocal TV (NLTV) mitigates the contrast losses by adaptively weighting the smoothness based on the similarity measure of image patches. Although it suppresses the noise effectively in the flat regions, it might leave residual noise surrounding the edges especially when the image is not oversmoothed. To address this problem, we propose the bilateral spectrum weighted total variation (BSWTV). Specially, we apply a locally adaptive shrink coefficient to the image gradients and employ the eigenvalues of the covariance matrix of the weighted image gradients to effectively refine the weighting map and suppress the residual noise. In conjunction with the data fidelity term derived from a mixed Poisson-Gaussian noise model, the objective function is decomposed and solved by the alternating direction method of multipliers (ADMM) algorithm. In order to remove outliers and facilitate the convergence stability, the weighting map is smoothed by a Gaussian filter with an iteratively decreased kernel width and updated in a momentum-based manner in each ADMM iteration. We benchmark our method with the state-of-the-art approaches on the public real-world datasets for super-resolution and image denoising. Experiments show that the proposed method obtains outstanding performance for super-resolution and achieves promising results for denoising on real-world images.",2021-06-01T20:04:15Z,2021-06-05T19:00:28Z,http://arxiv.org/abs/2106.00768v3,http://arxiv.org/pdf/2106.00768v3,eess.IV
A New Approach to Image Compression in Industrial Internet of Things,"Nahid Hajizadeh, Pirooz Shamsinejad, Reza Javidan","Applying image sensors in automation of Industrial Internet of Things (IIoT) technology is on the rise, day by day. In such companies, a large number of high volume images are transmitted at any moment; therefore, a significant challenge is reducing the amount of transmitted information and consequently bandwidth without reducing the quality of images. Image compression in sensors, in this regard, will save bandwidth and speed up data transmitting. There are several pieces of research in image compression for sensor networks, but, according to the nature of image transfer in IIoT, there is no study in this particular field. In this paper, it is for the first time that a new reusable technique to improve productivity in image compression is introduced and applied. To do this, a new adaptive lossy compression technique to compact sensor-generated images in IIoT by using K- Means++ and Intelligent Embedded Coding (IEC) as our novel approach, is presented. The new method is based on the colour of pixels so that pixels with the same or nearly the same colours are clustered around a centroid and finally, the colour of the pixels will be encoded. The experiments are based on a reputable image dataset from a real smart greenhouse; i.e. KOMATSUNA. The evaluation results reveal that, with the same compression rate, our approach compresses images with higher quality in comparison with other methods such as K-means, fuzzy C-means and fuzzy C-means++ clustering.",2021-12-10T07:01:58Z,2021-12-10T07:01:58Z,http://arxiv.org/abs/2112.05361v1,http://arxiv.org/pdf/2112.05361v1,eess.IV
Learning Nonlocal Sparse and Low-Rank Models for Image Compressive   Sensing,"Zhiyuan Zha, Bihan Wen, Xin Yuan, Saiprasad Ravishankar, Jiantao Zhou, Ce Zhu","The compressive sensing (CS) scheme exploits much fewer measurements than suggested by the Nyquist-Shannon sampling theorem to accurately reconstruct images, which has attracted considerable attention in the computational imaging community. While classic image CS schemes employed sparsity using analytical transforms or bases, the learning-based approaches have become increasingly popular in recent years. Such methods can effectively model the structures of image patches by optimizing their sparse representations or learning deep neural networks, while preserving the known or modeled sensing process. Beyond exploiting local image properties, advanced CS schemes adopt nonlocal image modeling, by extracting similar or highly correlated patches at different locations of an image to form a group to process jointly. More recent learning-based CS schemes apply nonlocal structured sparsity prior using group sparse representation (GSR) and/or low-rank (LR) modeling, which have demonstrated promising performance in various computational imaging and image processing applications. This article reviews some recent works in image CS tasks with a focus on the advanced GSR and LR based methods. Furthermore, we present a unified framework for incorporating various GSR and LR models and discuss the relationship between GSR and LR models. Finally, we discuss the open problems and future directions in the field.",2022-03-17T23:32:58Z,2022-10-25T09:11:59Z,http://arxiv.org/abs/2203.09656v6,http://arxiv.org/pdf/2203.09656v6,eess.IV
Image Processing via Multilayer Graph Spectra,"Songyang Zhang, Qinwen Deng, Zhi Ding","Graph signal processing (GSP) has become an important tool in image processing because of its ability to reveal underlying data structures. Many real-life multimedia datasets, however, exhibit heterogeneous structures across frames. Multilayer graphs (MLG), instead of traditional single-layer graphs, provide better representation of these datasets such as videos and hyperspectral images. To generalize GSP to multilayer graph models and develop multilayer analysis for image processing, this work introduces a tensor-based framework of multilayer graph signal processing (M-GSP) and present useful M-GSP tools for image processing. We then present guidelines for applying M-GSP in image processing and introduce several applications, including RGB image compression, edge detection and hyperspectral image segmentation. Successful experimental results demonstrate the efficacy and promising futures of M-GSP in image processing.",2021-08-31T06:41:56Z,2022-04-19T01:44:46Z,http://arxiv.org/abs/2108.13639v3,http://arxiv.org/pdf/2108.13639v3,eess.SP
Biologically-inspired characterization of sparseness in natural images,Laurent U Perrinet,"Natural images follow statistics inherited by the structure of our physical (visual) environment. In particular, a prominent facet of this structure is that images can be described by a relatively sparse number of features. We designed a sparse coding algorithm biologically-inspired by the architecture of the primary visual cortex. We show here that coefficients of this representation exhibit a heavy-tailed distribution. For each image, the parameters of this distribution characterize sparseness and vary from image to image. To investigate the role of this sparseness, we designed a new class of random textured stimuli with a controlled sparseness value inspired by our measurements on natural images. Then, we provide with a method to synthesize random textures images with a given statistics for sparseness that matches that of some given class of natural images and provide perspectives for their use in neurophysiology.",2017-02-08T15:57:57Z,2017-02-08T15:57:57Z,http://arxiv.org/abs/1702.02485v1,http://arxiv.org/pdf/1702.02485v1,q-bio.NC
A Practical Guide to Multi-image Alignment,"Cecilia Aguerrebere, Mauricio Delbracio, Alberto Bartesaghi, Guillermo Sapiro","Multi-image alignment, bringing a group of images into common register, is an ubiquitous problem and the first step of many applications in a wide variety of domains. As a result, a great amount of effort is being invested in developing efficient multi-image alignment algorithms. Little has been done, however, to answer fundamental practical questions such as: what is the comparative performance of existing methods? is there still room for improvement? under which conditions should one technique be preferred over another? does adding more images or prior image information improve the registration results? In this work, we present a thorough analysis and evaluation of the main multi-image alignment methods which, combined with theoretical limits in multi-image alignment performance, allows us to organize them under a common framework and provide practical answers to these essential questions.",2018-02-09T14:41:27Z,2018-02-09T14:41:27Z,http://arxiv.org/abs/1802.03280v1,http://arxiv.org/pdf/1802.03280v1,eess.IV
Three-Dimensional Photoacoustic Tomography using Delay Multiply and Sum   Beamforming Algorithm,"Roya Paridar, Moein Mozaffarzadeh, Ali Mahloojifar, Mohammadreza Nasiriavanaki, Mahdi Orooji","Photoacoustic imaging (PAI), is a promising medical imaging technique that provides the high contrast of the optical imaging and the resolution of ultrasound (US) imaging. Among all the methods, Three-dimensional (3D) PAI provides a high resolution and accuracy. One of the most common algorithms for 3D PA image reconstruction is delay-and-sum (DAS). However, the quality of the reconstructed image obtained from this algorithm is not satisfying, having high level of sidelobes and a wide mainlobe. In this paper, delay-multiply-and-sum (DMAS) algorithm is suggested to overcome these limitations in 3D PAI. It is shown that DMAS algorithm is an appropriate reconstruction technique for 3D PAI and the reconstructed images using this algorithm are improved in the terms of the width of mainlobe and sidelobes, compared to DAS. Also, the quantitative results show that DMAS improves signal-to-noise ratio (SNR) and full-width-half-maximum (FWHM) for about 25 dB and 0.2 mm, respectively, compared to DAS.",2018-02-26T14:13:54Z,2018-02-26T14:13:54Z,http://arxiv.org/abs/1802.09310v1,http://arxiv.org/pdf/1802.09310v1,eess.SP
Learning an Inverse Tone Mapping Network with a Generative Adversarial   Regularizer,"Shiyu Ning, Hongteng Xu, Li Song, Rong Xie, Wenjun Zhang","Transferring a low-dynamic-range (LDR) image to a high-dynamic-range (HDR) image, which is the so-called inverse tone mapping (iTM), is an important imaging technique to improve visual effects of imaging devices. In this paper, we propose a novel deep learning-based iTM method, which learns an inverse tone mapping network with a generative adversarial regularizer. In the framework of alternating optimization, we learn a U-Net-based HDR image generator to transfer input LDR images to HDR ones, and a simple CNN-based discriminator to classify the real HDR images and the generated ones. Specifically, when learning the generator we consider the content-related loss and the generative adversarial regularizer jointly to improve the stability and the robustness of the generated HDR images. Using the learned generator as the proposed inverse tone mapping network, we achieve superior iTM results to the state-of-the-art methods consistently.",2018-04-20T15:30:26Z,2018-04-20T15:30:26Z,http://arxiv.org/abs/1804.07677v1,http://arxiv.org/pdf/1804.07677v1,eess.IV
Joint optimization of multispectral filter arrays and demosaicking for   pathological images,"Kazuma Shinoda, Maru Kawase, Madoka Hasegawa, Masahiro Ishikawa, Hideki Komagata, Naoki Kobayashi","A capturing system with multispectral filter array (MSFA) technology is proposed for shortening the capture time and reducing costs. Therein, a mosaicked image captured using an MSFA is demosaicked to reconstruct multispectral images (MSIs). Joint optimization of the spectral sensitivity of the MSFAs and demosaicking is considered, and pathology-specific multispectral imaging is proposed. This optimizes the MSFA and the demosaicking matrix by minimizing the reconstruction error between the training data of a hematoxylin and eosin-stained pathological tissue and a demosaicked MSI using a cost function. Initially, the spectral sensitivity of the filter array is set randomly and the mosaicked image is obtained from the training data. Subsequently, a reconstructed image is obtained using Wiener estimation. To minimize the reconstruction error, the spectral sensitivity of the filter array and the Wiener estimation matrix are optimized iteratively through an interior-point approach. The effectiveness of the proposed MSFA and demosaicking is demonstrated by comparing the recovered spectrum and RGB image with those obtained using a conventional method.",2018-07-03T22:34:42Z,2018-07-03T22:34:42Z,http://arxiv.org/abs/1807.01385v1,http://arxiv.org/pdf/1807.01385v1,eess.IV
Physics-assisted Deep Learning for FMCW Radar Quantitative Imaging of   Two-dimension Target,"Zhuoyang Liu, Huilin Xu, Feng Xu","Radar imaging is crucial in remote sensing and has many applications in detection and autonomous driving. However, the received radar signal for imaging is enormous and redundant, which degrades the speed of real-time radar quantitative imaging and leads to obstacles in the downlink applications. In this paper, we propose a physics-assisted deep learning method for radar quantitative imaging with the advantage of compressed sensing (CS). Specifically, the signal model for frequency-modulated continuous-wave (FMCW) radar imaging which only uses four antennas and parts of frequency components is formulated in terms of matrices multiplication. The learned fast iterative shrinkage-thresholding algorithm with residual neural network (L-FISTA-ResNet) is proposed for solving the quantitative imaging problem. The L-FISTA is developed to ensure the basic solution and ResNet is attached to enhance the image quality. Simulation results show that our proposed method has higher reconstruction accuracy than the traditional optimization method and pure neural networks. The effectiveness and generalization performance of the proposed strategy is verified in unseen target imaging, denoising, and frequency migration tasks.",2023-07-05T08:47:45Z,2023-07-05T08:47:45Z,http://arxiv.org/abs/2307.02119v1,http://arxiv.org/pdf/2307.02119v1,eess.SP
RGB-Guided Resolution Enhancement of IR Images,"Marcel Trammer, Nils Genser, Jürgen Seiler","This paper introduces a novel method for RGB-Guided Resolution Enhancement of infrared (IR) images called Guided IR Resolution Enhancement (GIRRE). In the area of single image super resolution (SISR) there exists a wide variety of algorithms like interpolation methods or neural networks to improve the spatial resolution of images. In contrast to SISR, even more information can be gathered on the recorded scene when using multiple cameras. In our setup, we are dealing with multi image super resolution, especially with stereo super resolution. We consider a color camera and an IR camera. Current IR sensors have a very low resolution compared to color sensors so that recent color sensors take up 100 times more pixels than IR sensors. To this end, GIRRE increases the spatial resolution of the low-resolution IR image. After that, the upscaled image is filtered with the aid of the high-resolution color image. We show that our method achieves an average PSNR gain of 1.2 dB and at best up to 1.8 dB compared to state-of-the-art methods, which is visually noticeable.",2023-09-12T06:50:45Z,2023-09-12T06:50:45Z,http://arxiv.org/abs/2309.05996v1,http://arxiv.org/pdf/2309.05996v1,eess.IV
MBIR Training for a 2.5D DL network in X-ray CT,"Obaidullah Rahman, Madhuri Nagare, Ken D. Sauer, Charles A. Bouman, Roman Melnyk, Brian Nett, Jie Tang","In computed tomographic imaging, model based iterative reconstruction methods have generally shown better image quality than the more traditional, faster filtered backprojection technique. The cost we have to pay is that MBIR is computationally expensive. In this work we train a 2.5D deep learning (DL) network to mimic MBIR quality image. The network is realized by a modified Unet, and trained using clinical FBP and MBIR image pairs. We achieve the quality of MBIR images faster and with a much smaller computation cost. Visually and in terms of noise power spectrum (NPS), DL-MBIR images have texture similar to that of MBIR, with reduced noise power. Image profile plots, NPS plots, standard deviation, etc. suggest that the DL-MBIR images result from a successful emulation of an MBIR operator.",2023-09-23T15:21:28Z,2023-09-23T15:21:28Z,http://arxiv.org/abs/2309.13399v1,http://arxiv.org/pdf/2309.13399v1,eess.IV
SDDPM: Speckle Denoising Diffusion Probabilistic Models,"Soumee Guha, Scott T. Acton","Coherent imaging systems, such as medical ultrasound and synthetic aperture radar (SAR), are subject to corruption from speckle due to sub-resolution scatterers. Since speckle is multiplicative in nature, the constituent image regions become corrupted to different extents. The task of denoising such images requires algorithms specifically designed for removing signal-dependent noise. This paper proposes a novel image denoising algorithm for removing signal-dependent multiplicative noise with diffusion models, called Speckle Denoising Diffusion Probabilistic Models (SDDPM). We derive the mathematical formulations for the forward process, the reverse process, and the training objective. In the forward process, we apply multiplicative noise to a given image and prove that the forward process is Gaussian. We show that the reverse process is also Gaussian and the final training objective can be expressed as the Kullback Leibler (KL) divergence between the forward and reverse processes. As derived in the paper, the final denoising task is a single step process, thereby reducing the denoising time significantly. We have trained our model with natural land-use images and ultrasound images for different noise levels. Extensive experiments centered around two different applications show that SDDPM is robust and performs significantly better than the comparative models even when the images are severely corrupted.",2023-11-17T20:59:04Z,2023-11-17T20:59:04Z,http://arxiv.org/abs/2311.10868v1,http://arxiv.org/pdf/2311.10868v1,eess.IV
Quantifying the Resolution of a Template after Image Registration,"Matthias Glock, Thomas Hotz","In many image processing applications (e.g. computational anatomy) a groupwise registration is performed on a sample of images and a template image is simultaneously generated. From the template alone it is in general unclear to which extent the registered images are still misaligned, which means that some regions of the template represent the structural features in the sample images less reliably than others. In a sense, the template exhibits a lower resolution there. Guided by characteristic examples of misaligned image features in one dimension, we develop a visual measure to quantify the resolution at each location of a template which is based on the observation that misalignments between the registered sample images are reduced by smoothing with the strength of the smoothing being related to the magnitude of the misalignment. Finally the resulting resolution measure is applied to example datasets in two and three dimensions. The corresponding code is publicly available on GitHub.",2024-02-27T15:45:15Z,2024-02-27T15:45:15Z,http://arxiv.org/abs/2402.17617v1,http://arxiv.org/pdf/2402.17617v1,eess.IV
A Microwave Imaging System for Soil Moisture Estimation in Subsurface   Drip Irrigation,"Mohammad Ramezaninia, Mohammad Zoofaghari","The microwave imaging system(MIS) stands out among prominent imaging tools for capturing images of concealed obstacles. Leveraging its capability to penetrate through heterogeneous environments MIS has been widely used for subsurface imaging. Monitoring subsurface drip irrigation(SDI) as an efficient procedure in agricultural irrigation is essential to maintain the required moisture percentage for plant growth which is a novel MIS application. In this research, we implement a laboratory-scale MIS for SDI reflecting real-world conditions to evaluate leakage localization and quantification in a heterogeneous area. We extract a model to quantify the moisture content by exploiting an imaging approach that could be used in a scheduled SDI. We employ the subspace information of images formed by back projection and Born approximation algorithms for model parametrization and estimate the model parameters using a statistical curve fitting technique. We then compare the performance of these imaging techniques in the presence of environmental clutter such as plant roots and pebbles. The proposed approach can well contribute to efficient mechanistic subsurface irrigation for which the local moisture around the root is obtained noninvasively and remotely with less than 20% estimation error.",2024-03-08T21:38:17Z,2024-03-08T21:38:17Z,http://arxiv.org/abs/2403.05685v1,http://arxiv.org/pdf/2403.05685v1,"eess.IV, eess.SP"
A CT Image Denoising Method with Residual Encoder-Decoder Network,"Helena Shawn, Thompson Chyrikov, Jacob Lanet, Lam-chi Chen, Jim Zhao, Christina Chajo","Utilizing a low-dose CT approach significantly reduces the radiation exposure for patients, yet it introduces challenges, such as increased noise and artifacts in the resultant images, which can hinder accurate medical diagnostics. Traditional methods for noise reduction struggle with preserving image textures due to the complexity of modeling statistical properties directly within the image domain. To address these limitations, this study introduces an enhanced noise-reduction technique centered around an advanced residual encoder-decoder network. By incorporating recursive processing into the foundational network, this method reduces computational complexity and enhances the effectiveness of noise reduction. Furthermore, the introduction of a root-mean-square error and perceptual loss functions aims to retain the integrity of the images' textural details. The enhanced technique also includes optimized tissue segmentation, improving artifact management post-improvement. Validation using the TCGA-COAD clinical dataset demonstrates superior performance in both noise reduction and image quality, as measured by post-denoising PSNR and SSIM, compared to the existing WGAN approach. This advancement in CT image processing offers a practical solution for clinical applications, achieving lower computational demands and faster processing times without compromising image quality.",2024-04-02T01:38:19Z,2024-04-02T01:38:19Z,http://arxiv.org/abs/2404.01553v1,http://arxiv.org/pdf/2404.01553v1,eess.IV
Remote Sensing Image Enhancement through Spatiotemporal Filtering,Hessah Albanwan,"The analysis of time-sequence satellite images is a powerful tool in remote sensing; it is used to explore the statics and dynamics of the surface of the earth. Usually, the quality of multitemporal images is influenced by metrological conditions, high reflectance of surfaces, illumination, and satellite sensor conditions. These negative influences may produce noises and different radiances and appearances between the images, which can affect the applications that process them. Thus, a spatiotemporal bilateral filter has been adopted in this research to enhance the quality of an image before using it in any application. The filter takes advantage of the temporal information provided by multi temporal images and attempts to reduce the differences between them to improve transfer learning used in classification. The classification method used here is support vector machine (SVM). Three experiments were conducted in this research, two were on Landsat 8 images with low-medium resolution, and the third on high-resolution images of Planet satellite. The newly developed filter proved that it can enhance the accuracy of classification using transfer learning by about 5%,15%, and 2% for the three experiments respectively.",2024-04-27T08:33:48Z,2024-04-27T08:33:48Z,http://arxiv.org/abs/2404.18950v1,http://arxiv.org/pdf/2404.18950v1,eess.IV
Pre-capture Privacy via Adaptive Single-Pixel Imaging,"Yoko Sogabe, Shiori Sugimoto, Ayumi Matsumoto, Masaki Kitahara","As cameras become ubiquitous in our living environment, invasion of privacy is becoming a growing concern. A common approach to privacy preservation is to remove personally identifiable information from a captured image, but there is a risk of the original image being leaked. In this paper, we propose a pre-capture privacy-aware imaging method that captures images from which the details of a pre-specified anonymized target have been eliminated. The proposed method applies a single-pixel imaging framework in which we introduce a feedback mechanism called an aperture pattern generator. The introduced aperture pattern generator adaptively outputs the next aperture pattern to avoid sampling the anonymized target by exploiting the data already acquired as a clue. Furthermore, the anonymized target can be set to any object without changing hardware. Except for detailed features which have been removed from the anonymized target, the captured images are of comparable quality to those captured by a general camera and can be used for various computer vision applications. In our work, we target faces and license plates and experimentally show that the proposed method can capture clear images in which detailed features of the anonymized target are eliminated to achieve both privacy and utility.",2024-07-01T06:05:12Z,2024-07-01T06:05:12Z,http://arxiv.org/abs/2407.00991v1,http://arxiv.org/pdf/2407.00991v1,eess.IV
Generative Diffusion Model Bootstraps Zero-shot Classification of Fetal   Ultrasound Images In Underrepresented African Populations,"Fangyijie Wang, Kevin Whelan, Guénolé Silvestre, Kathleen M. Curran","Developing robust deep learning models for fetal ultrasound image analysis requires comprehensive, high-quality datasets to effectively learn informative data representations within the domain. However, the scarcity of labelled ultrasound images poses substantial challenges, especially in low-resource settings. To tackle this challenge, we leverage synthetic data to enhance the generalizability of deep learning models. This study proposes a diffusion-based method, Fetal Ultrasound LoRA (FU-LoRA), which involves fine-tuning latent diffusion models using the LoRA technique to generate synthetic fetal ultrasound images. These synthetic images are integrated into a hybrid dataset that combines real-world and synthetic images to improve the performance of zero-shot classifiers in low-resource settings. Our experimental results on fetal ultrasound images from African cohorts demonstrate that FU-LoRA outperforms the baseline method by a 13.73% increase in zero-shot classification accuracy. Furthermore, FU-LoRA achieves the highest accuracy of 82.40%, the highest F-score of 86.54%, and the highest AUC of 89.78%. It demonstrates that the FU-LoRA method is effective in the zero-shot classification of fetal ultrasound images in low-resource settings. Our code and data are publicly accessible on https://github.com/13204942/FU-LoRA.",2024-07-29T14:57:29Z,2024-07-29T14:57:29Z,http://arxiv.org/abs/2407.20072v1,http://arxiv.org/pdf/2407.20072v1,eess.IV
Inter-Camera Color Correction for Multispectral Imaging with Camera   Arrays Using a Consensus Image,"Katja Kossira, Jürgen Seiler, André Kaup","This paper introduces a novel method for inter-camera color calibration for multispectral imaging with camera arrays using a consensus image. Capturing images using multispectral camera arrays has gained importance in medical, agricultural, and environmental processes. Due to fabrication differences, noise, or device altering, varying pixel sensitivities occur, influencing classification processes. Therefore, color calibration between the cameras is necessary. In existing methods, one of the camera images is chosen and considered as a reference, ignoring the color information of all other recordings. Our new approach does not just take one image as reference, but uses statistical information such as the location parameter to generate a consensus image as basis for calibration. This way, we managed to improve the PSNR values for the linear regression color correction algorithm by 1.15 dB and the improved color difference (iCID) values by 2.81.",2024-10-30T14:09:38Z,2024-11-13T09:55:30Z,http://arxiv.org/abs/2410.23043v2,http://arxiv.org/pdf/2410.23043v2,eess.IV
Performance Boundaries and Tradeoffs in Super-Resolution Imaging   Technologies for Space Targets,"XiaoLe He, Ping Liu, JunLing Wang","Inverse synthetic aperture radar (ISAR) super-resolution imaging technology is widely applied in space target imaging. However, the performance limits of super-resolution imaging algorithms remain a rarely explored issue. This paper investigates these limits by analyzing the boundaries of super-resolution algorithms for space targets and examines the relationships between key contributing factors. In particular, drawing on the established mathematical theory of computational resolution limits (CRL) for line spectrum reconstruction, we derive mathematical expressions for the upper and lower bounds of cross-range super-resolution imaging, based on ISAR imaging model transformations. Leveraging the explicit expressions, we first explore influencing factors of these bounds, such as the traditional Rayleigh limit, the number of scatterers, and the peak signal-to-noise ratio (PSNR) of scatterers. Then we elucidate the minimum resource requirements in ISAR imaging imposed by the CRL theory to meet the desired cross-range resolution, without which studying super-resolution algorithms becomes unnecessary in practice. Furthermore, the tradeoffs between the cumulative rotation angle, the radar transmit energy, and other contributing factors in optimizing the resolution are analyzed. Simulations are conducted to demonstrate these tradeoffs across various ISAR imaging scenarios, revealing their high dependence on specific imaging targets.",2024-11-14T03:14:09Z,2024-11-14T03:14:09Z,http://arxiv.org/abs/2411.09155v1,http://arxiv.org/pdf/2411.09155v1,eess.SP
Semantic Communications for Digital Signals via Carrier Images,"Zhigang Yan, Dong Li","Most of current semantic communication (SemCom) frameworks focus on the image transmission, which, however, do not address the problem on how to deliver digital signals without any semantic features. This paper proposes a novel SemCom approach to transmit digital signals by using the image as the carrier signal. Specifically, the proposed approach encodes the digital signal as a binary stream and maps it to mask locations on an image. This allows binary data to be visually represented, enabling the use of existing model, pre-trained Masked Autoencoders (MAE), which are optimized for masked image reconstruction, as the SemCom encoder and decoder. Since MAE can both process and recover masked images, this approach allows for the joint transmission of digital signals and images without additional overhead. In addition, considering the mask tokens transmission encoded by the MAE still faces extra costs, we design a sparse encoding module at the transmitter to encode the mask tokens into a sparse matrix, and it can be recovered at the receiver. Thus, this approach simply needs to transmit the latent representations of the unmasked patches and a sparse matrix, which further reduce the transmission overhead compared with the original MAE encoder. Simulation results show that the approach maintains reliable transmission of digital signals and images even in a high mask ratio of transmitted images.",2024-12-10T04:13:54Z,2024-12-10T04:13:54Z,http://arxiv.org/abs/2412.07173v1,http://arxiv.org/pdf/2412.07173v1,eess.SP
Encoding Visual Sensitivity by MaxPol Convolution Filters for Image   Sharpness Assessment,"Mahdi S. Hosseini, Yueyang Zhang, Konstantinos N. Plataniotis","In this paper, we propose a novel design of Human Visual System (HVS) response in a convolution filter form to decompose meaningful features that are closely tied with image sharpness level. No-reference (NR) Image sharpness assessment (ISA) techniques have emerged as the standard of image quality assessment in diverse imaging applications. Despite their high correlation with subjective scoring, they are challenging for practical considerations due to high computational cost and lack of scalability across different image blurs. We bridge this gap by synthesizing the HVS response as a linear combination of Finite Impulse Response (FIR) derivative filters to boost the falloff of high band frequency magnitudes in natural imaging paradigm. The numerical implementation of the HVS filter is carried out with MaxPol filter library that can be arbitrarily set for any differential orders and cutoff frequencies to balance out the estimation of informative features and noise sensitivities. We then design an innovative NR-ISA metric called `HVS-MaxPol' that (a) requires minimal computational cost, (b) produce high correlation accuracy with image blurriness, and (c) scales to assess synthetic and natural image blur. Specifically, the synthetic blur images are constructed by blurring the raw images using Gaussian filter, while natural blur is observed from real-life application such as motion, out-of-focus, etc. Furthermore, we create a natural benchmark database in digital pathology for validation of image focus quality in whole slide imaging systems called `FocusPath' consisting of 864 blurred images. Thorough experiments are designed to test and validate the efficiency of HVS-MaxPol across different blur databases and state-of-the-art NR-ISA metrics. The experiment result indicates that our metric has the best overall performance with respect to speed, accuracy and scalability.",2018-08-02T01:10:14Z,2019-03-19T02:50:58Z,http://arxiv.org/abs/1808.00617v2,http://arxiv.org/pdf/1808.00617v2,eess.IV
Identification of images of COVID-19 from Chest Computed Tomography (CT)   images using Deep learning: Comparing COGNEX VisionPro Deep Learning 1.0   Software with Open Source Convolutional Neural Networks,"Arjun Sarkar, Joerg Vandenhirtz, Jozsef Nagy, David Bacsa, Mitchell Riley","For testing patients infected with COVID-19, along with RT-PCR testing, chest radiology images are being used. For the detection of COVID-19 from radiology images, many organizations are proposing the use of Deep Learning. University of Waterloo and DarwinAI, have designed their own Deep Learning model COVIDNet-CT to detect COVID-19 from infected chest CT images. Additionally, they have introduced a CT image dataset COVIDx-CT, from CT images collected by the China National Center for Bioinformation. COVIDx-CT contains 104,009 CT image slices across 1,489 patient cases. After obtaining remarkable results on the identification of COVID-19 from chest X-ray images by using the COGNEX VisionPro Deep Learning Software 1.0 this time we test the performance of the software on the identification of COVID-19 from CT images. COGNEX Deep Learning Software: VisionPro Deep Learning, is a Deep Learning software that is used across various domains ranging from factory automation to life sciences. In this study, we train the classification model on 82,818 chest CT training and validation images from the COVIDx-CT dataset in 3 classes - normal, pneumonia, and COVID-19 and then test the results of the classification on the 21,191 test images are compared with the results of COVIDNet-CT and various other state of the art Deep Learning models from the open-source community. Also, we test how reducing the number of images in the training set effects the results of the software. Overall, VisionPro Deep Learning gives the best results with F-scores over 99%, even as the number of images in the training set is reduced significantly. This software is by no means a stand-alone solution in the detection of COVID-19 but can aid radiologists and clinicians in achieving faster and understandable diagnosis using the full potential of Deep Learning, without the prerequisite of having to code in any programming language.",2020-10-01T09:27:09Z,2020-10-09T10:11:15Z,http://arxiv.org/abs/2010.00958v2,http://arxiv.org/pdf/2010.00958v2,eess.IV
Methods for Joint Imaging and RNA-seq Data Analysis,"Junhai Jiang, Nan Lin, Shicheng Guo, Jinyun Chen, Momiao Xiong","Emerging integrative analysis of genomic and anatomical imaging data which has not been well developed, provides invaluable information for the holistic discovery of the genomic structure of disease and has the potential to open a new avenue for discovering novel disease susceptibility genes which cannot be identified if they are analyzed separately. A key issue to the success of imaging and genomic data analysis is how to reduce their dimensions. Most previous methods for imaging information extraction and RNA-seq data reduction do not explore imaging spatial information and often ignore gene expression variation at genomic positional level. To overcome these limitations, we extend functional principle component analysis from one dimension to two dimension (2DFPCA) for representing imaging data and develop a multiple functional linear model (MFLM) in which functional principal scores of images are taken as multiple quantitative traits and RNA-seq profile across a gene is taken as a function predictor for assessing the association of gene expression with images. The developed method has been applied to image and RNA-seq data of ovarian cancer and KIRC studies. We identified 24 and 84 genes whose expressions were associated with imaging variations in ovarian cancer and KIRC studies, respectively. Our results showed that many significantly associated genes with images were not differentially expressed, but revealed their morphological and metabolic functions. The results also demonstrated that the peaks of the estimated regression coefficient function in the MFLM often allowed the discovery of splicing sites and multiple isoform of gene expressions.",2014-09-13T02:05:29Z,2014-09-13T02:05:29Z,http://arxiv.org/abs/1409.3899v1,http://arxiv.org/pdf/1409.3899v1,q-bio.GN
Iterative Algorithms for Joint Scatter and Attenuation Estimation From   Broken Ray Transform Data,"Michael R. Walker II, Joseph A. O'Sullivan","The single-scatter approximation is fundamental in many tomographic imaging problems including x-ray scatter imaging and optical scatter imaging for certain media. In all cases, noisy measurements are affected by both local scatter events and nonlocal attenuation. Prior works focus on reconstructing one of two images: scatter density or total attenuation. However, both images are media specific and useful for object identification.   Nonlocal effects of the attenuation image on the data are summarized by the broken ray transform (BRT). While analytic inversion formulas exist, poor conditioning of the inverse problem is only exacerbated by noisy measurements and sampling errors. This has motivated interest in the related star transforms incorporating BRT measurements from multiple source-detector pairs. However, all analytic methods operate on the log of the data. For media comprising regions with no scatter a new approach is required.   We are the first to present a joint estimation algorithm based on Poisson data models for a single-scatter measurement geometry. Monotonic reduction of the log-likelihood function is guaranteed for our iterative algorithm while alternating image updates. We also present a fast algorithm for computing the discrete BRT forward operator. Our generalized approach can incorporate both transmission and scatter measurements from multiple source-detector pairs. Transmission measurements resolve low-frequency ambiguity in the joint image estimation problem, while multiple scatter measurements resolve the attenuation image. The benefits of joint estimation, over single-image estimation, vary with problem scaling. Our results quantify these benefits and should inform design of future acquisition systems.",2020-06-25T22:20:18Z,2021-04-20T02:19:54Z,http://arxiv.org/abs/2006.14719v2,http://arxiv.org/pdf/2006.14719v2,"eess.IV, eess.SP"
Coupled Tensor Decomposition for Hyperspectral and Multispectral Image   Fusion with Inter-Image Variability,"Ricardo Augusto Borsoi, Clémence Prévost, Konstantin Usevich, David Brie, José Carlos Moreira Bermudez, Cédric Richard","Coupled tensor approximation has recently emerged as a promising approach for the fusion of hyperspectral and multispectral images, reconciling state of the art performance with strong theoretical guarantees. However, tensor-based approaches previously proposed assume that the different observed images are acquired under exactly the same conditions. A recent work proposed to accommodate inter-image spectral variability in the image fusion problem using a matrix factorization-based formulation, but did not account for spatially-localized variations. Moreover, it lacks theoretical guarantees and has a high associated computational complexity. In this paper, we consider the image fusion problem while accounting for both spatially and spectrally localized changes in an additive model. We first study how the general identifiability of the model is impacted by the presence of such changes. Then, assuming that the high-resolution image and the variation factors admit a Tucker decomposition, two new algorithms are proposed -- one purely algebraic, and another based on an optimization procedure. Theoretical guarantees for the exact recovery of the high-resolution image are provided for both algorithms. Experimental results show that the proposed method outperforms state-of-the-art methods in the presence of spectral and spatial variations between the images, at a smaller computational cost.",2020-06-30T17:00:20Z,2020-12-06T03:06:07Z,http://arxiv.org/abs/2006.16968v2,http://arxiv.org/pdf/2006.16968v2,"eess.SP, eess.IV"
Resampling Images to a Regular Grid from a Non-Regular Subset of Pixel   Positions Using Frequency Selective Reconstruction,"Jürgen Seiler, Markus Jonscher, Michael Schöberl, André Kaup","Even though image signals are typically defined on a regular two-dimensional grid, there also exist many scenarios where this is not the case and the amplitude of the image signal only is available for a non-regular subset of pixel positions. In such a case, a resampling of the image to a regular grid has to be carried out. This is necessary since almost all algorithms and technologies for processing, transmitting or displaying image signals rely on the samples being available on a regular grid. Thus, it is of great importance to reconstruct the image on this regular grid so that the reconstruction comes closest to the case that the signal has been originally acquired on the regular grid. In this paper, Frequency Selective Reconstruction is introduced for solving this challenging task. This algorithm reconstructs image signals by exploiting the property that small areas of images can be represented sparsely in the Fourier domain. By further taking into account the basic properties of the Optical Transfer Function of imaging systems, a sparse model of the signal is iteratively generated. In doing so, the proposed algorithm is able to achieve a very high reconstruction quality, in terms of PSNR and SSIM as well as in terms of visual quality. Simulation results show that the proposed algorithm is able to outperform state-of-the-art reconstruction algorithms and gains of more than 1 dB PSNR are possible.",2022-04-27T12:11:52Z,2022-04-27T12:11:52Z,http://arxiv.org/abs/2204.12873v1,http://arxiv.org/pdf/2204.12873v1,eess.IV
High-resolution Multi-spectral Imaging with Diffractive Lenses and   Learned Reconstruction,"Figen S. Oktem, Oğuzhan Fatih Kar, Can Deniz Bezek, Farzad Kamalabadi","Spectral imaging is a fundamental diagnostic technique with widespread application. Conventional spectral imaging approaches have intrinsic limitations on spatial and spectral resolutions due to the physical components they rely on. To overcome these physical limitations, in this paper, we develop a novel multi-spectral imaging modality that enables higher spatial and spectral resolutions. In the developed computational imaging modality, we exploit a diffractive lens, such as a photon sieve, for both dispersing and focusing the optical field, and achieve measurement diversity by changing the focusing behavior of this lens. Because the focal length of a diffractive lens is wavelength-dependent, each measurement is a superposition of differently blurred spectral components. To reconstruct the individual spectral images from these superimposed and blurred measurements, model-based fast reconstruction algorithms are developed with deep and analytical priors using alternating minimization and unrolling. Finally, the effectiveness and performance of the developed technique is illustrated for an application in astrophysical imaging under various observation scenarios in the extreme ultraviolet (EUV) regime. The results demonstrate that the technique provides not only diffraction-limited high spatial resolution, as enabled by diffractive lenses, but also the capability of resolving close-by spectral sources that would not otherwise be possible with the existing techniques. This work enables high resolution multi-spectral imaging with low cost designs for a variety of applications and spectral regimes.",2020-08-26T15:33:00Z,2021-06-04T14:33:01Z,http://arxiv.org/abs/2008.11625v3,http://arxiv.org/pdf/2008.11625v3,eess.IV
Compressed Fourier-Domain Convolutional Beamforming for Wireless   Ultrasound imaging,"Alon Mamistvalov, Yonina C. Eldar","Wireless ultrasound (US) systems that produce high-quality images can improve current clinical diagnosis capabilities by making the imaging process much more efficient, affordable, and accessible to users. The most common technique for generating B-mode US images is delay and sum (DAS) beamforming, where an appropriate delay is introduced to signals sampled and processed at each transducer element. However, sampling rates that are much higher than the Nyquist rate of the signal are required for high resolution DAS beamforming, leading to large amounts of data, making transmission of channel data over WIFI impractical. Moreover, the production of US images that exhibit high resolution and good image contrast requires a large set of transducers which further increases the data size. Previous works suggest methods for reduction in sampling rate and in array size. In this work, we introduce compressed Fourier domain convolutional beamforming, combining Fourier domain beamforming, sparse convolutional beamforming, and compressed sensing methods. This allows reducing both the number of array elements and the sampling rate in each element, while achieving high resolution images. Using in vivo data we demonstrate that the proposed method can generate B-mode images using 142 times less data than DAS. Our results pave the way towards wireless US and demonstrate that high resolution US images can be produced using sub-Nyquist sampling and a small number of receiving channels.",2020-10-25T17:41:30Z,2020-10-25T17:41:30Z,http://arxiv.org/abs/2010.13171v1,http://arxiv.org/pdf/2010.13171v1,"eess.SP, eess.IV"
Structurally Adaptive Multi-Derivative Regularization for Image Recovery   from Sparse Fourier Samples,"Sanjay Viswanath, Manu Ghulyani, Muthuvel Arigovindan","The importance of regularization has been well established in image reconstruction -- which is the computational inversion of imaging forward model -- with applications including deconvolution for microscopy, tomographic reconstruction, magnetic resonance imaging, and so on. Originally, the primary role of the regularization was to stabilize the computational inversion of the imaging forward model against noise. However, a recent framework pioneered by Donoho and others, known as compressive sensing, brought the role of regularization beyond the stabilization of inversion. It established a possibility that regularization can recover full images from highly undersampled measurements. However, it was observed that the quality of reconstruction yielded by compressive sensing methods falls abruptly when the under-sampling and/or measurement noise goes beyond a certain threshold. Recently developed learning-based methods are believed to outperform the compressive sensing methods without a steep drop in the reconstruction quality under such imaging conditions. However, the need for training data limits their applicability. In this paper, we develop a regularization method that outperforms compressive sensing methods as well as selected learning-based methods, without any need for training data. The regularization is constructed as a spatially varying weighted sum of first- and canonical second-order derivatives, with the weights determined to be adaptive to the image structure; the weights are determined such that the attenuation of sharp image features -- which is inevitable with the use of any regularization -- is significantly reduced. We demonstrate the effectiveness of the proposed method by performing reconstruction on sparse Fourier samples simulated from a variety of MRI images.",2021-05-26T18:20:18Z,2021-06-27T06:15:35Z,http://arxiv.org/abs/2105.12775v3,http://arxiv.org/pdf/2105.12775v3,eess.IV
Image Restoration for Remote Sensing: Overview and Toolbox,"Benhood Rasti, Yi Chang, Emanuele Dalsasso, Loïc Denis, Pedram Ghamisi","Remote sensing provides valuable information about objects or areas from a distance in either active (e.g., RADAR and LiDAR) or passive (e.g., multispectral and hyperspectral) modes. The quality of data acquired by remotely sensed imaging sensors (both active and passive) is often degraded by a variety of noise types and artifacts. Image restoration, which is a vibrant field of research in the remote sensing community, is the task of recovering the true unknown image from the degraded observed image. Each imaging sensor induces unique noise types and artifacts into the observed image. This fact has led to the expansion of restoration techniques in different paths according to each sensor type. This review paper brings together the advances of image restoration techniques with particular focuses on synthetic aperture radar and hyperspectral images as the most active sub-fields of image restoration in the remote sensing community. We, therefore, provide a comprehensive, discipline-specific starting point for researchers at different levels (i.e., students, researchers, and senior researchers) willing to investigate the vibrant topic of data restoration by supplying sufficient detail and references. Additionally, this review paper accompanies a toolbox to provide a platform to encourage interested students and researchers in the field to further explore the restoration techniques and fast-forward the community. The toolboxes are provided in https://github.com/ImageRestorationToolbox.",2021-07-01T15:54:49Z,2022-11-21T15:28:37Z,http://arxiv.org/abs/2107.00557v3,http://arxiv.org/pdf/2107.00557v3,eess.IV
Automatic Multi-Class Cardiovascular Magnetic Resonance Image Quality   Assessment using Unsupervised Domain Adaptation in Spatial and Frequency   Domains,"Shahabedin Nabavi, Hossein Simchi, Mohsen Ebrahimi Moghaddam, Alejandro F. Frangi, Ahmad Ali Abin","Population imaging studies rely upon good quality medical imagery before downstream image quantification. This study provides an automated approach to assess image quality from cardiovascular magnetic resonance (CMR) imaging at scale. We identify four common CMR imaging artefacts, including respiratory motion, cardiac motion, Gibbs ringing, and aliasing. The model can deal with images acquired in different views, including two, three, and four-chamber long-axis and short-axis cine CMR images. Two deep learning-based models in spatial and frequency domains are proposed. Besides recognising these artefacts, the proposed models are suitable to the common challenges of not having access to data labels. An unsupervised domain adaptation method and a Fourier-based convolutional neural network are proposed to overcome these challenges. We show that the proposed models reliably allow for CMR image quality assessment. The accuracies obtained for the spatial model in supervised and weakly supervised learning are 99.41+0.24 and 96.37+0.66 for the UK Biobank dataset, respectively. Using unsupervised domain adaptation can somewhat overcome the challenge of not having access to the data labels. The maximum achieved domain gap coverage in unsupervised domain adaptation is 16.86%. Domain adaptation can significantly improve a 5-class classification task and deal with considerable domain shift without data labels. Increasing the speed of training and testing can be achieved with the proposed model in the frequency domain. The frequency-domain model can achieve the same accuracy yet 1.548 times faster than the spatial model. This model can also be used directly on k-space data, and there is no need for image reconstruction.",2021-12-13T17:06:15Z,2021-12-13T17:06:15Z,http://arxiv.org/abs/2112.06806v1,http://arxiv.org/pdf/2112.06806v1,eess.IV
Online Fusion of Multi-resolution Multispectral Images with Weakly   Supervised Temporal Dynamics,"Haoqing Li, Bhavya Duvvuri, Ricardo Borsoi, Tales Imbiriba, Edward Beighley, Deniz Erdogmus, Pau Closas","Real-time satellite imaging has a central role in monitoring, detecting and estimating the intensity of key natural phenomena such as floods, earthquakes, etc. One important constraint of satellite imaging is the trade-off between spatial/spectral resolution and their revisiting time, a consequence of design and physical constraints imposed by satellite orbit among other technical limitations. In this paper, we focus on fusing multi-temporal, multi-spectral images where data acquired from different instruments with different spatial resolutions is used. We leverage the spatial relationship between images at multiple modalities to generate high-resolution image sequences at higher revisiting rates. To achieve this goal, we formulate the fusion method as a recursive state estimation problem and study its performance in filtering and smoothing contexts. Furthermore, a calibration strategy is proposed to estimate the time-varying temporal dynamics of the image sequence using only a small amount of historical image data. Differently from the training process in traditional machine learning algorithms, which usually require large datasets and computation times, the parameters of the temporal dynamical model are calibrated based on an analytical expression that uses only two of the images in the historical dataset. A distributed version of the Bayesian filtering and smoothing strategies is also proposed to reduce its computational complexity. To evaluate the proposed methodology we consider a water mapping task where real data acquired by the Landsat and MODIS instruments are fused generating high spatial-temporal resolution image estimates. Our experiments show that the proposed methodology outperforms the competing methods in both estimation accuracy and water mapping tasks.",2023-01-06T16:48:33Z,2023-01-06T16:48:33Z,http://arxiv.org/abs/2301.02598v1,http://arxiv.org/pdf/2301.02598v1,eess.IV
Interferometric single-pixel imaging with a multicore fiber,"Olivier Leblanc, Matthias Hofer, Siddharth Sivankutty, Hervé Rigneault, Laurent Jacques","Lensless illumination single-pixel imaging with a multicore fiber (MCF) is a computational imaging technique that enables potential endoscopic observations of biological samples at cellular scale. In this work, we show that this technique is tantamount to collecting multiple symmetric rank-one projections (SROP) of a Hermitian \emph{interferometric} matrix -- a matrix encoding the spectral content of the sample image. In this model, each SROP is induced by the complex \emph{sketching} vector shaping the incident light wavefront with a spatial light modulator (SLM), while the projected interferometric matrix collects up to $O(Q^2)$ image frequencies for a $Q$-core MCF. While this scheme subsumes previous sensing modalities, such as raster scanning (RS) imaging with beamformed illumination, we demonstrate that collecting the measurements of $M$ random SLM configurations -- and thus acquiring $M$ SROPs -- allows us to estimate an image of interest if $M$ and $Q$ scale linearly (up to log factors) with the image sparsity level, hence requiring much fewer observations than RS imaging or a complete Nyquist sampling of the $Q \times Q$ interferometric matrix. This demonstration is achieved both theoretically, with a specific restricted isometry analysis of the sensing scheme, and with extensive Monte Carlo experiments. Experimental results made on an actual MCF system finally demonstrate the effectiveness of this imaging procedure on a benchmark image.",2023-07-17T15:28:03Z,2023-07-17T15:28:03Z,http://arxiv.org/abs/2307.08562v1,http://arxiv.org/pdf/2307.08562v1,eess.SP
A Visual Quality Assessment Method for Raster Images in Scanned Document,"Justin Yang, Peter Bauer, Todd Harris, Changhyung Lee, Hyeon Seok Seo, Jan P Allebach, Fengqing Zhu","Image quality assessment (IQA) is an active research area in the field of image processing. Most prior works focus on visual quality of natural images captured by cameras. In this paper, we explore visual quality of scanned documents, focusing on raster image areas. Different from many existing works which aim to estimate a visual quality score, we propose a machine learning based classification method to determine whether the visual quality of a scanned raster image at a given resolution setting is acceptable. We conduct a psychophysical study to determine the acceptability at different image resolutions based on human subject ratings and use them as the ground truth to train our machine learning model. However, this dataset is unbalanced as most images were rated as visually acceptable. To address the data imbalance problem, we introduce several noise models to simulate the degradation of image quality during the scanning process. Our results show that by including augmented data in training, we can significantly improve the performance of the classifier to determine whether the visual quality of raster images in a scanned document is acceptable or not for a given resolution setting.",2023-07-25T04:11:16Z,2023-07-25T04:11:16Z,http://arxiv.org/abs/2307.13241v1,http://arxiv.org/pdf/2307.13241v1,eess.IV
Research on Image Stitching Based on Invariant Features of Reconstructed   Plane,"Qi Liu, Xiyu Tang, Ju Huo","Generating high-quality stitched images is a challenging task in computer vision. The existing feature-based image stitching methods commonly only focus on point and line features, neglecting the crucial role of higher-level planar features in image stitching. This paper proposes an image stitching method based on invariant planar features, which uses planar features as constraints to improve the overall effect of natural image stitching. Initially, our approach expands the quantity of matched feature points and lines through straight-line procedures, advancing alignment quality and reducing artifacts in overlapping areas. Then, uncertain planes are described by known matching points and matching lines, and plane features are introduced to preserve energy items, which improves the overall appearance of stitched images while reducing distortion and guarantees a more natural stitched image. Furthermore, to demonstrate the superiority of our approach, we also propose several evaluation indexes related to planar features to quantify the detailed changes of planar features. An extensive set of experiments validates the effectiveness of our approach in stitching natural images with a larger field of view. Compared with the most advanced methods, our method retains the texture and structure of the image better, and produces less unnatural distortion. Multiple quantitative evaluations illustrate that our approach outperforms existing methods with significant improvements, further validating the effectiveness and superiority of our proposed method.",2023-08-30T08:50:49Z,2023-08-30T08:50:49Z,http://arxiv.org/abs/2308.15860v1,http://arxiv.org/pdf/2308.15860v1,eess.IV
See SIFT in a Rain,"Wei Wu, Hao Chang, Zhu Li","Rain streaks bring complicated pixel intensity changes and additional gradients, greatly obstructing the extraction of image features from background. This causes serious performance degradation in feature-based applications. Thus, it is critical to remove rain streaks from a single rainy image to recover image features. Recently, many excellent image deraining methods have made remarkable progress. However, these human visual system-driven approaches mainly focus on improving image quality with pixel recovery as loss function, and neglect how to enhance image feature recovery ability. To address this issue, we propose a task-driven image deraining algorithm to strengthen image feature supply for subsequent feature-based applications. Due to the extensive use and strong practicability of Scale-Invariant Feature Transform (SIFT), we first propose two separate networks using distinct losses and modules to achieve two goals, respectively. One is difference of Gaussian (DoG) pyramid recovery network (DPRNet) for SIFT detection, and the other gradients of Gaussian images recovery network (GGIRNet) for SIFT description. Second, in the DPRNet we propose an alternative interest point loss that directly penalizes scale response extrema to recover the DoG pyramid. Third, we advance a gradient attention module in the GGIRNet to recover those gradients of Gaussian images. Finally, with the recovered DoG pyramid and gradients, we can regain SIFT key points. This divide-and-conquer scheme to set different objectives for SIFT detection and description leads to good robustness. Compared with state-of-the-art methods, experimental results demonstrate that our proposed algorithm achieves better performance in both the number of recovered SIFT key points and their accuracy.",2023-11-01T13:42:23Z,2023-11-01T13:42:23Z,http://arxiv.org/abs/2311.00518v1,http://arxiv.org/pdf/2311.00518v1,eess.IV
Learning graph-Fourier spectra of textured surface images for defect   localization,"Tapan Ganatma Nakkina, Adithyaa Karthikeyan, Yuhao Zhong, Ceyhun Eksin, Satish T. S. Bukkapatnam","In the realm of industrial manufacturing, product inspection remains a significant bottleneck, with only a small fraction of manufactured items undergoing inspection for surface defects. Advances in imaging systems and AI can allow automated full inspection of manufactured surfaces. However, even the most contemporary imaging and machine learning methods perform poorly for detecting defects in images with highly textured backgrounds, that stem from diverse manufacturing processes. This paper introduces an approach based on graph Fourier analysis to automatically identify defective images, as well as crucial graph Fourier coefficients that inform the defects in images amidst highly textured backgrounds. The approach capitalizes on the ability of graph representations to capture the complex dynamics inherent in high-dimensional data, preserving crucial locality properties in a lower dimensional space. A convolutional neural network model (1D-CNN) was trained with the coefficients of the graph Fourier transform of the images as the input to identify, with classification accuracy of 99.4%, if the image contains a defect. An explainable AI method using SHAP (SHapley Additive exPlanations) was used to further analyze the trained 1D-CNN model to discern important spectral coefficients for each image. This approach sheds light on the crucial contribution of low-frequency graph eigen waveforms to precisely localize surface defects in images, thereby advancing the realization of zero-defect manufacturing.",2023-11-25T17:25:07Z,2023-12-02T03:33:56Z,http://arxiv.org/abs/2311.15082v3,http://arxiv.org/pdf/2311.15082v3,eess.IV
Do High-Performance Image-to-Image Translation Networks Enable the   Discovery of Radiomic Features? Application to MRI Synthesis from Ultrasound   in Prostate Cancer,"Mohammad R. Salmanpour, Amin Mousavi, Yixi Xu, William B Weeks, Ilker Hacihaliloglu","This study investigates the foundational characteristics of image-to-image translation networks, specifically examining their suitability and transferability within the context of routine clinical environments, despite achieving high levels of performance, as indicated by a Structural Similarity Index (SSIM) exceeding 0.95. The evaluation study was conducted using data from 794 patients diagnosed with Prostate cancer. To synthesize MRI from Ultrasound images, we employed five widely recognized image to image translation networks in medical imaging: 2DPix2Pix, 2DCycleGAN, 3DCycleGAN, 3DUNET, and 3DAutoEncoder. For quantitative assessment, we report four prevalent evaluation metrics Mean Absolute Error, Mean Square Error, Structural Similarity Index (SSIM), and Peak Signal to Noise Ratio. Moreover, a complementary analysis employing Radiomic features (RF) via Spearman correlation coefficient was conducted to investigate, for the first time, whether networks achieving high performance, SSIM greater than 0.85, could identify low-level RFs. The RF analysis showed 75 features out of 186 RFs were discovered via just 2DPix2Pix algorithm while half of RFs were lost in the translation process. Finally, a detailed qualitative assessment by five medical doctors indicated a lack of low level feature discovery in image to image translation tasks.",2024-03-27T14:59:19Z,2024-07-25T20:19:51Z,http://arxiv.org/abs/2403.18651v4,http://arxiv.org/pdf/2403.18651v4,eess.IV
Performance of Medical Image Fusion in High-level Analysis Tasks: A   Mutual Enhancement Framework for Unaligned PAT and MRI Image Fusion,"Yutian Zhong, Jinchuan He, Zhichao Liang, Shuangyang Zhang, Qianjin Feng, Wufan Chen, Li Qi","Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion have made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we proposes a unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT-MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with contour segmentation and multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.",2024-07-04T15:13:32Z,2024-07-04T15:13:32Z,http://arxiv.org/abs/2407.03992v1,http://arxiv.org/pdf/2407.03992v1,eess.IV
Semantics Guided Disentangled GAN for Chest X-ray Image Rib Segmentation,"Lili Huang, Dexin Ma, Xiaowei Zhao, Chenglong Li, Haifeng Zhao, Jin Tang, Chuanfu Li","The label annotations for chest X-ray image rib segmentation are time consuming and laborious, and the labeling quality heavily relies on medical knowledge of annotators. To reduce the dependency on annotated data, existing works often utilize generative adversarial network (GAN) to generate training data. However, GAN-based methods overlook the nuanced information specific to individual organs, which degrades the generation quality of chest X-ray image. Hence, we propose a novel Semantics guided Disentangled GAN (SD-GAN), which can generate the high-quality training data by fully utilizing the semantic information of different organs, for chest X-ray image rib segmentation. In particular, we use three ResNet50 branches to disentangle features of different organs, then use a decoder to combine features and generate corresponding images. To ensure that the generated images correspond to the input organ labels in semantics tags, we employ a semantics guidance module to perform semantic guidance on the generated images. To evaluate the efficacy of SD-GAN in generating high-quality samples, we introduce modified TransUNet(MTUNet), a specialized segmentation network designed for multi-scale contextual information extracting and multi-branch decoding, effectively tackling the challenge of organ overlap. We also propose a new chest X-ray image dataset (CXRS). It includes 1250 samples from various medical institutions. Lungs, clavicles, and 24 ribs are simultaneously annotated on each chest X-ray image. The visualization and quantitative results demonstrate the efficacy of SD-GAN in generating high-quality chest X-ray image-mask pairs. Using generated data, our trained MTUNet overcomes the limitations of the data scale and outperforms other segmentation networks.",2024-07-22T12:13:02Z,2024-07-22T12:13:02Z,http://arxiv.org/abs/2407.15903v1,http://arxiv.org/pdf/2407.15903v1,eess.IV
Physics-augmented Deep Learning with Adversarial Domain Adaptation:   Applications to STM Image Denoising,"Jianxin Xie, Wonhee Ko, Rui-Xing Zhang, Bing Yao","Image denoising is a critical task in various scientific fields such as medical imaging and material characterization, where the accurate recovery of underlying structures from noisy data is essential. Although supervised denoising techniques have achieved significant advancements, they typically require large datasets of paired clean-noisy images for training. Unsupervised methods, while not reliant on paired data, typically necessitate a set of unpaired clean images for training, which are not always accessible. In this paper, we propose a physics-augmented deep learning with adversarial domain adaption (PDA-Net) framework for unsupervised image denoising, with applications to denoise real-world scanning tunneling microscopy (STM) images. Our PDA-Net leverages the underlying physics to simulate and envision the ground truth for denoised STM images. Additionally, built upon Generative Adversarial Networks (GANs), we incorporate a cycle-consistency module and a domain adversarial module into our PDA-Net to address the challenge of lacking paired training data and achieve information transfer between the simulated and real experimental domains. Finally, we propose to implement feature alignment and weight-sharing techniques to fully exploit the similarity between simulated and real experimental images, thereby enhancing the denoising performance in both the simulation and experimental domains. Experimental results demonstrate that the proposed PDA-Net successfully enhances the quality of STM images, offering promising applications to enhance scientific discovery and accelerate experimental quantum material research.",2024-09-08T14:57:37Z,2025-02-10T21:54:17Z,http://arxiv.org/abs/2409.05118v2,http://arxiv.org/pdf/2409.05118v2,"eess.IV, eess.SP"
Image Generation with Multimodule Semantic Feature-Aided Selection for   Semantic Communications,"Chengyang Liang, Dong Li","Semantic communication (SemCom) has emerged as a promising technique for the next-generation communication systems, in which the generation at the receiver side is allowed without semantic features' recovery. However, the majority of existing research predominantly utilizes a singular type of semantic information, such as text, images, or speech, to supervise and choose the generated source signals, which may not sufficiently encapsulate the comprehensive and accurate semantic information, and thus creating a performance bottleneck. In order to bridge this gap, in this paper, we propose and investigate a multimodal information-aided SemCom framework (MMSemCom) for image transmission. To be specific, in this framework, we first extract semantic features at both the image and text levels utilizing the Convolutional Neural Network (CNN) architecture and the Contrastive Language-Image Pre-Training (CLIP) model before transmission. Then, we employ a generative diffusion model at the receiver to generate multiple images. In order to ensure the accurate extraction and facilitate high-fidelity image reconstruction, we select the ""best"" image with the minimum reconstruction errors by taking both the aided image and text semantic features into account. We further extend MMSemCom to the multiuser scenario for orthogonal transmission. Experimental results demonstrate that the proposed framework can not only achieve the enhanced fidelity and robustness in image transmission compared with existing communication systems but also sustain a high performance in the low signal-to-noise ratio (SNR) conditions.",2024-11-26T13:34:12Z,2024-11-26T13:34:12Z,http://arxiv.org/abs/2411.17428v1,http://arxiv.org/pdf/2411.17428v1,eess.IV
Shadow Detection for Ultrasound Images Using Unlabeled Data and   Synthetic Shadows,"Suguru Yasutomi, Tatsuya Arakaki, Ryuji Hamamoto","Medical ultrasound is widely used technique for diagnosing internal organs. As common artifacts, shadows often appear in ultrasound images. Detecting such shadows is curious because they prevent accurate diagnosis. In this paper, we propose a novel shadow detection method based on auto-encoding structure. It once separates an input image into a shadow image and a content image using two decoders and combines them to reconstruct the input. To lead the network into separating the input, we inject synthetic shadows into the input and make the network to predict them as the shadow image. Since we know the rough shape of shadows as basic domain knowledge, we can generate plausible shadows. These processes are achieved by using only unlabeled data. Experiments on ultrasound images for fetal heart diagnosis shows the effectiveness of the method.",2019-08-05T01:47:57Z,2019-08-05T01:47:57Z,http://arxiv.org/abs/1908.01439v1,http://arxiv.org/pdf/1908.01439v1,eess.IV
Plug-and-Play Priors for Reconstruction-based Placental Image   Registration,"Jiarui Xing, Ulugbek Kamilov, Wenjie Wu, Yong Wang, Miaomiao Zhang","This paper presents a novel deformable registration framework, leveraging an image prior specified through a denoising function, for severely noise-corrupted placental images. Recent work on plug-and-play (PnP) priors has shown the state-of-the-art performance of reconstruction algorithms under such priors in a range of imaging applications. Integration of powerful image denoisers into advanced registration methods provides our model with a flexibility to accommodate datasets that have low signal-to-noise ratios (SNRs). We demonstrate the performance of our method under a wide variety of denoising models in the context of diffeomorphic image registration. Experimental results show that our model substantially improves the accuracy of spatial alignment in applications of 3D in-utero diffusion-weighted MR images (DW-MRI) that suffer from low SNR and large spatial transformations.",2019-09-03T13:34:53Z,2019-09-03T13:34:53Z,http://arxiv.org/abs/1909.01170v1,http://arxiv.org/pdf/1909.01170v1,eess.IV
Illumination Pattern Design with Deep Learning for Single-Shot Fourier   Ptychographic Microscopy,"Yi Fei Cheng, Megan Strachan, Zachary Weiss, Moniher Deb, Dawn Carone, Vidya Ganapati","Fourier ptychographic microscopy allows for the collection of images with a high space-bandwidth product at the cost of temporal resolution. In Fourier ptychographic microscopy, the light source of a conventional widefield microscope is replaced with a light-emitting diode (LED) matrix, and multiple images are collected with different LED illumination patterns. From these images, a higher-resolution image can be computationally reconstructed without sacrificing field-of-view. We use deep learning to achieve single-shot imaging without sacrificing the space-bandwidth product, reducing the acquisition time in Fourier ptychographic microscopy by a factor of 69. In our deep learning approach, a training dataset of high-resolution images is used to jointly optimize a single LED illumination pattern with the parameters of a reconstruction algorithm. Our work paves the way for high-throughput imaging in biological studies.",2018-10-05T16:41:32Z,2018-10-05T16:41:32Z,http://arxiv.org/abs/1810.03481v1,http://arxiv.org/pdf/1810.03481v1,eess.IV
Training a Neural Network for Gibbs and Noise Removal in Diffusion MRI,"Matthew J. Muckley, Benjamin Ades-Aron, Antonios Papaioannou, Gregory Lemberskiy, Eddy Solomon, Yvonne W. Lui, Daniel K. Sodickson, Els Fieremans, Dmitry S. Novikov, Florian Knoll","We develop and evaluate a neural network-based method for Gibbs artifact and noise removal. A convolutional neural network (CNN) was designed for artifact removal in diffusion-weighted imaging data. Two implementations were considered: one for magnitude images and one for complex images. Both models were based on the same encoder-decoder structure and were trained by simulating MRI acquisitions on synthetic non-MRI images. Both machine learning methods were able to mitigate artifacts in diffusion-weighted images and diffusion parameter maps. The CNN for complex images was also able to reduce artifacts in partial Fourier acquisitions. The proposed CNNs extend the ability of artifact correction in diffusion MRI. The machine learning method described here can be applied on each imaging slice independently, allowing it to be used flexibly in clinical applications.",2019-05-10T13:57:16Z,2019-05-15T13:53:53Z,http://arxiv.org/abs/1905.04176v2,http://arxiv.org/pdf/1905.04176v2,eess.IV
Deep learning based high-resolution incoherent x-ray imaging with a   single-pixel detector,"Yu-Hang He, Ai-Xin Zhang, Ming-Fei Li, Yi-Yi Huang, Bao-Gang Quan, Da-Zhang Li, Ling-An Wu, Li-Ming Chen","X-ray ""ghost"" imaging has drawn great attention for its potential to lower radiation dose in medical diagnosis. For practical implementation, however, the efficiency and image quality have to be greatly improved. Here we demonstrate a computational ghost imaging scheme where a bucket detector and specially designed modulation masks are used, together with a new robust deep learning algorithm in which a compressed set of Hadamard matrices is incorporated into a multi-level wavelet convolutional neural network. By this means we have obtained an image of a real object from only 18.75% of the Nyquist sampling rate, using a portable tabletop incoherent x-ray source of ~37 {\mu}m diameter. A high imaging resolution of ~10 {\mu}m is achieved, which represents a concrete step towards the realization of a practical low cost x-ray ghost imaging camera for applications in biomedicine, archeology, material science, and so forth.",2019-05-24T09:19:42Z,2019-05-24T09:19:42Z,http://arxiv.org/abs/1905.10364v1,http://arxiv.org/pdf/1905.10364v1,eess.IV
Combining Bayesian and Deep Learning Methods for the Delineation of the   Fan in Ultrasound Images,"Hind Dadoun, Hervé Delingette, Anne-Laure Rousseau, Eric de Kerviler, Nicholas Ayache","Ultrasound (US) images usually contain identifying information outside the ultrasound fan area and manual annotations placed by the sonographers during exams. For those images to be exploitable in a Deep Learning framework, one needs to first delineate the border of the fan which delimits the ultrasound fan area and then remove other annotations inside. We propose a parametric probabilistic approach for the first task. We make use of this method to generate a training data set with segmentation masks of the region of interest (ROI) and train a U-Net to perform the same task in a supervised way, thus considerably reducing computational time of the method, one hundred and sixty times faster. These images are then processed with existing inpainting methods to remove annotations present inside the fan area. To the best of our knowledge, this is the first parametric approach to quickly detect the fan in an ultrasound image without any other information than the image itself.",2021-02-02T09:49:55Z,2021-02-02T09:49:55Z,http://arxiv.org/abs/2102.02055v1,http://arxiv.org/pdf/2102.02055v1,eess.IV
Quantum mechanics-based signal and image representation: application to   denoising,"Sayantan Dutta, Adrian Basarab, Bertrand Georgeot, Denis Kouamé","Decomposition of digital signals and images into other basis or dictionaries than time or space domains is a very common approach in signal and image processing and analysis. Such a decomposition is commonly obtained using fixed transforms (e.g., Fourier or wavelet) or dictionaries learned from example databases or from the signal or image itself. In this work, we investigate in detail a new approach of constructing such a signal or image-dependent bases inspired by quantum mechanics tools, i.e., by considering the signal or image as a potential in the discretized Schroedinger equation. To illustrate the potential of the proposed decomposition, denoising results are reported in the case of Gaussian, Poisson, and speckle noise and compared to the state of the art algorithms based on wavelet shrinkage, total variation regularization or patch-wise sparse coding in learned dictionaries, non-local means image denoising, and graph signal processing.",2020-04-02T15:38:20Z,2021-03-16T11:24:40Z,http://arxiv.org/abs/2004.01078v3,http://arxiv.org/pdf/2004.01078v3,"eess.SP, eess.IV"
Manipulation Detection in Satellite Images Using Deep Belief Networks,"János Horváth, Daniel Mas Montserrat, Hanxiang Hao, Edward J. Delp","Satellite images are more accessible with the increase of commercial satellites being orbited. These images are used in a wide range of applications including agricultural management, meteorological prediction, damage assessment from natural disasters, and cartography. Image manipulation tools including both manual editing tools and automated techniques can be easily used to tamper and modify satellite imagery. One type of manipulation that we examine in this paper is the splice attack where a region from one image (or the same image) is inserted (spliced) into an image. In this paper, we present a one-class detection method based on deep belief networks (DBN) for splicing detection and localization without using any prior knowledge of the manipulations. We evaluate the performance of our approach and show that it provides good detection and localization accuracies in small forgeries compared to other approaches.",2020-04-26T17:35:33Z,2020-04-26T17:35:33Z,http://arxiv.org/abs/2004.12441v1,http://arxiv.org/pdf/2004.12441v1,eess.IV
CAD Applications and Emerging Research Potential in Medical Imaging,"Roshan P. Mathews, Greeta Mathews","Computer Aided Detection (CAD) is a valuable technique for precisely interpreting medical images and it has a global business opportunity of about USD 1.8 billion. The current aspects with reference to the four sub stages such as image pre-processing, segmentation, feature extraction and classification and the future scope of CAD in medical imaging has been discussed in this paper. Many reviewers have emphasized the need for synergy between engineers and medical professionals for successful development of CAD systems and the current work is a move in that direction. The engineering aspects of the above four stages in four imaging modalities viz. computed tomography, magnetic resonance imaging, mammography and bone scintigraphy used in the diagnosis of five critical diseases have been discussed with a clinical background. Automatic classification of image can play an important role in preliminary screening of very critical ailments bringing down the cost of health care. Another recent advancement is using artificial intelligence and machine learning techniques. This paper reviews these engineering aspects with a view to explore the opportunities to researchers as well as the medical industry to offer affordable medical services with accessibility in even remote locations.",2020-09-30T13:15:06Z,2020-09-30T13:15:06Z,http://arxiv.org/abs/2009.14657v1,http://arxiv.org/pdf/2009.14657v1,eess.IV
Widely-distributed Radar Imaging Based on Consensus ADMM,"Ruizhi Hu, Bhavani Shankar Mysore Rama Rao, Ahmed Murtada, Mohammad Alaee-Kerahroodi, Björn Ottersten","A widely-distributed radar system is a promising architecture to enhance radar imaging performance. However, most existing algorithms rely on isotropic scattering assumption, which is only satisfied in collocated radar systems. Moreover, due to noise and imaging model imperfections, artifacts such as layovers are common in radar images. In this paper, a novel $l_1$-regularized, consensus alternating direction method of multipliers (CADMM) based algorithm is proposed to mitigate artifacts by exploiting a widely-distributed radar system's spatial diversity. By imposing the consensus constraints on the local images formed by distributed antenna clusters and solving the resulting distributed optimization problem, the scenario's spatial-invariant common features are retained. Simultaneously, the spatial-variant artifacts are mitigated, and it will finally converge to a high-quality global image in the consensus of all distributed measurements. The proposed algorithm outperforms the joint sparsity-based composite imaging (JSC) algorithm in terms of artifacts mitigation. It can also reduce the computation and storage burden of large-scale imaging problems through its distributed and parallelizable optimization scheme.",2020-11-04T14:39:12Z,2020-11-08T09:46:45Z,http://arxiv.org/abs/2011.02319v2,http://arxiv.org/pdf/2011.02319v2,eess.SP
Fighting together against the pandemic: learning multiple models on   tomography images for COVID-19 diagnosis,"Mario Manzo, Simone Pellino","The great challenge for the humanity of the year 2020 is the fight against COVID-19. The whole world is making a huge effort to find an effective vaccine with purpose to protect people not yet infected. The alternative solution remains early diagnosis, carried out through real-time polymerase chain reaction (RT-PCR) test or thorax computer tomography (CT) scan images. Deep learning algorithms, specifically convolutional neural networks, represent a methodology for the image analysis. They optimize the classification design task, essential for an automatic approach on different types of images, including medical. In this paper, we adopt pretrained deep convolutional neural network architectures in order to diagnose COVID-19 disease on CT images. Our idea is inspired by what the whole of humanity is achieving, substantially the set of multiple contributions is better than the single one for the fight against the pandemic. Firstly, we adapt, and subsequently retrain, for our assumption some neural architectures adopted in other application domains. Secondly, we combine the knowledge extracted from images by neural architectures in an ensemble classification context. Experimental phase is performed on CT images dataset and results obtained show the effectiveness of the proposed approach with respect to state-of-the-art competitors.",2020-12-02T14:54:35Z,2020-12-02T14:54:35Z,http://arxiv.org/abs/2012.01251v1,http://arxiv.org/pdf/2012.01251v1,eess.IV
ER-IQA: Boosting Perceptual Quality Assessment Using External Reference   Images,"Jingyu Guo, Wei Wang, Wenming Yang, Qingmin Liao, Jie Zhou","Recently, image quality assessment (IQA) has achieved remarkable progress with the success of deep learning. However, the strict pre-condition of full-reference (FR) methods has limited its application in real scenarios. And the no-reference (NR) scheme is also inconvenient due to its unsatisfying performance as a result of ignoring the essence of image quality. In this paper, we introduce a brand new scheme, namely external-reference image quality assessment (ER-IQA), by introducing external reference images to bridge the gap between FR and NR-IQA. As the first implementation and a new baseline of ER-IQA, we propose a new Unpaired-IQA network to process images in a content-unpaired manner. A Mutual Attention-based Feature Enhancement (MAFE) module is well-designed for the unpaired features in ER-IQA. The MAFE module allows the network to extract quality-discriminative features from distorted images and content variability-robust features from external reference ones. Extensive experiments demonstrate that the proposed model outperforms the state-of-the-art NR-IQA methods, verifying the effectiveness of ER-IQA and the possibility of narrowing the gap of the two existing categories.",2021-05-06T06:54:51Z,2021-09-16T09:03:00Z,http://arxiv.org/abs/2105.02464v2,http://arxiv.org/pdf/2105.02464v2,eess.IV
DURRNet: Deep Unfolded Single Image Reflection Removal Network,"Jun-Jie Huang, Tianrui Liu, Zhixiong Yang, Shaojing Fu, Wentao Zhao, Pier Luigi Dragotti","Single image reflection removal problem aims to divide a reflection-contaminated image into a transmission image and a reflection image. It is a canonical blind source separation problem and is highly ill-posed. In this paper, we present a novel deep architecture called deep unfolded single image reflection removal network (DURRNet) which makes an attempt to combine the best features from model-based and learning-based paradigms and therefore leads to a more interpretable deep architecture. Specifically, we first propose a model-based optimization with transform-based exclusion prior and then design an iterative algorithm with simple closed-form solutions for solving each sub-problems. With the deep unrolling technique, we build the DURRNet with ProxNets to model natural image priors and ProxInvNets which are constructed with invertible networks to impose the exclusion prior. Comprehensive experimental results on commonly used datasets demonstrate that the proposed DURRNet achieves state-of-the-art results both visually and quantitatively.",2022-03-12T01:38:40Z,2022-03-12T01:38:40Z,http://arxiv.org/abs/2203.06306v1,http://arxiv.org/pdf/2203.06306v1,eess.IV
TransEM:Residual Swin-Transformer based regularized PET image   reconstruction,"Rui Hu, Huafeng Liu","Positron emission tomography(PET) image reconstruction is an ill-posed inverse problem and suffers from high level of noise due to limited counts received. Recently deep neural networks especially convolutional neural networks(CNN) have been successfully applied to PET image reconstruction. However, the local characteristics of the convolution operator potentially limit the image quality obtained by current CNN-based PET image reconstruction methods. In this paper, we propose a residual swin-transformer based regularizer(RSTR) to incorporate regularization into the iterative reconstruction framework. Specifically, a convolution layer is firstly adopted to extract shallow features, then the deep feature extraction is accomplished by the swin-transformer layer. At last, both deep and shallow features are fused with a residual operation and another convolution layer. Validations on the realistic 3D brain simulated low-count data show that our proposed method outperforms the state-of-the-art methods in both qualitative and quantitative measures.",2022-05-09T11:46:03Z,2022-10-24T13:28:15Z,http://arxiv.org/abs/2205.04204v2,http://arxiv.org/pdf/2205.04204v2,eess.IV
Face Image Lighting Enhancement Using a 3D Model,"Qiulin Chen, Jan P. Allebach","Image enhancement helps to generate balanced lighting distributions over faces. Our goal is to get an illuminance-balanced enhanced face image from a single view. Traditionally, image enhancement methods ignore the 3D geometry of the face or require a complicated multi-view geometry. Other methods cause color tone shifting or over saturation. Inspired by the new research achievements in face alignment and face 3D modeling, we propose an improved face image enhancement method by leveraging 3D face models. Given a face image as input, our method will first estimate its lighting distribution. Then we build an optimization process to refine the distribution. Finally, we generate an illuminance-balanced face image from a single view. Experiments on the FiveK dataset demonstrate that our method performs well and compares favorably with other methods.",2022-07-02T07:16:57Z,2022-07-02T07:16:57Z,http://arxiv.org/abs/2207.00761v1,http://arxiv.org/pdf/2207.00761v1,eess.IV
Two Dimensional Sparse-Regularization-Based InSAR Imaging with   Back-Projection Embedding,"Xu Zhan, Xiaoling Zhang, Shunjun Wei, Jun Shi","Interferometric Synthetic Aperture Radar (InSAR) Imaging methods are usually based on algorithms of match-filtering type, without considering the scene's characteristic, which causes limited imaging quality. Besides, post-processing steps are inevitable, like image registration, flat-earth phase removing and phase noise filtering. To solve these problems, we propose a new InSAR imaging method. First, to enhance the imaging quality, we propose a new imaging framework base on 2D sparse regularization, where the characteristic of scene is embedded. Second, to avoid the post processing steps, we establish a new forward observation process, where the back-projection imaging method is embedded. Third, a forward and backward iterative solution method is proposed based on proximal gradient descent algorithm. Experiments on simulated and measured data reveal the effectiveness of the proposed method. Compared with the conventional method, higher quality interferogram can be obtained directly from raw echoes without post-processing. Besides, in the under-sampling situation, it's also applicable.",2022-09-21T15:05:52Z,2022-09-21T15:05:52Z,http://arxiv.org/abs/2209.10417v1,http://arxiv.org/pdf/2209.10417v1,eess.SP
Near-Field SAR Image Restoration Based On Two Dimensional   Spatial-Variant Deconvolution,"Wensi Zhang, Xiaoling Zhang, Xu Zhan, Yuetonghui Xu, Jun Shi, Shunjun Wei","Images of near-field SAR contains spatial-variant sidelobes and clutter, subduing the image quality. Current image restoration methods are only suitable for small observation angle, due to their assumption of 2D spatial-invariant degradation operation. This limits its potential for large-scale objects imaging, like the aircraft. To ease this restriction, in this work an image restoration method based on the 2D spatial-variant deconvolution is proposed. First, the image degradation is seen as a complex convolution process with 2D spatial-variant operations. Then, to restore the image, the process of deconvolution is performed by cyclic coordinate descent algorithm. Experiments on simulation and measured data validate the effectiveness and superiority of the proposed method. Compared with current methods, higher precision estimation of the targets' amplitude and position is obtained.",2022-09-21T15:35:02Z,2022-09-21T15:35:02Z,http://arxiv.org/abs/2209.10442v1,http://arxiv.org/pdf/2209.10442v1,eess.SP
3D Super-Resolution Imaging Method for Distributed Millimeter-wave   Automotive Radar System,"Yanqin Xu, Xiaoling Zhang, Shunjun Wei, Jun Shi, Xu Zhan, Tianwen Zhang","Millimeter-wave (mmW) radar is widely applied to advanced autopilot assistance systems. However, its small antenna aperture causes a low imaging resolution. In this paper, a new distributed mmW radar system is designed to solve this problem. It forms a large sparse virtual planar array to enlarge the aperture, using multiple-input and multiple-output (MIMO) processing. However, in this system, traditional imaging methods cannot apply to the sparse array. Therefore, we also propose a 3D super-resolution imaging method specifically for this system in this paper. The proposed method consists of three steps: (1) using range FFT to get range imaging, (2) using 2D adaptive diagonal loading iterative adaptive approach (ADL-IAA) to acquire 2D super-resolution imaging, which can satisfy this sparsity under single-measurement, (3) using constant false alarm (CFAR) processing to gain final 3D super-resolution imaging. The simulation results show the proposed method can significantly improve imaging resolution under the sparse array and single-measurement.",2022-09-21T17:12:13Z,2022-09-21T17:12:13Z,http://arxiv.org/abs/2209.11037v1,http://arxiv.org/pdf/2209.11037v1,eess.SP
Compressive Image Classification using Deterministic Sensing Matrices,"Sheel Shah, Kushal Kejriwal",We look at the use of deterministic sensing matrices for compressed sensing and provide worst-case bounds on the classification accuracy of SVMs on compressively sensed data.,2022-10-15T11:53:40Z,2022-10-15T11:53:40Z,http://arxiv.org/abs/2210.10777v1,http://arxiv.org/pdf/2210.10777v1,eess.IV
On the Robustness of deep learning-based MRI Reconstruction to image   transformations,"Jinghan Jia, Mingyi Hong, Yimeng Zhang, Mehmet Akçakaya, Sijia Liu","Although deep learning (DL) has received much attention in accelerated magnetic resonance imaging (MRI), recent studies show that tiny input perturbations may lead to instabilities of DL-based MRI reconstruction models. However, the approaches of robustifying these models are underdeveloped. Compared to image classification, it could be much more challenging to achieve a robust MRI image reconstruction network considering its regression-based learning objective, limited amount of training data, and lack of efficient robustness metrics. To circumvent the above limitations, our work revisits the problem of DL-based image reconstruction through the lens of robust machine learning. We find a new instability source of MRI image reconstruction, i.e., the lack of reconstruction robustness against spatial transformations of an input, e.g., rotation and cutout. Inspired by this new robustness metric, we develop a robustness-aware image reconstruction method that can defend against both pixel-wise adversarial perturbations as well as spatial transformations. Extensive experiments are also conducted to demonstrate the effectiveness of our proposed approaches.",2022-11-09T14:58:37Z,2022-11-21T16:51:31Z,http://arxiv.org/abs/2211.04930v2,http://arxiv.org/pdf/2211.04930v2,eess.IV
Centroid adapted frequency selective extrapolation for reconstruction of   lost image areas,"Wolfgang Schnurrer, Markus Jonscher, Jürgen Seiler, Thomas Richter, Michel Bätz, André Kaup","Lost image areas with different size and arbitrary shape can occur in many scenarios such as error-prone communication, depth-based image rendering or motion compensated wavelet lifting. The goal of image reconstruction is to restore these lost image areas as close to the original as possible. Frequency selective extrapolation is a block-based method for efficiently reconstructing lost areas in images. So far, the actual shape of the lost area is not considered directly. We propose a centroid adaption to enhance the existing frequency selective extrapolation algorithm that takes the shape of lost areas into account. To enlarge the test set for evaluation we further propose a method to generate arbitrarily shaped lost areas. On our large test set, we obtain an average reconstruction gain of 1.29 dB.",2023-01-12T06:56:57Z,2023-01-12T06:56:57Z,http://arxiv.org/abs/2301.04840v1,http://arxiv.org/pdf/2301.04840v1,eess.IV
A Simplified 3D Ultrasound Freehand Imaging Framework Using 1D Linear   Probe and Low-Cost Mechanical Track,"Antony Jerald, A. N. Madhavanunni, Gayathri Malamal, Pisharody Harikrishnan Gopalakrishnan, Mahesh Raveendranatha Panicker","Ultrasound imaging is the most popular medical imaging modality for point-of-care bedside imaging. However, 2D ultrasound imaging provides only limited views of the organ of interest, making diagnosis challenging. To overcome this, 3D ultrasound imaging was developed, which uses 2D ultrasound images and their orientation/position to reconstruct 3D volumes. The accurate position estimation of the ultrasound probe at low cost has always stood as a challenging task in 3D reconstruction. In this study, we propose a novel approach of using a mechanical track for ultrasound scanning, which restricts the probe motion to a linear plane, simplifying the acquisition and hence the reconstruction process. We also present an end-to-end pipeline for 3D ultrasound volume reconstruction and demonstrate its efficacy with an in-vitro tube phantom study and an ex-vivo bone experiment. The comparison between a sensorless freehand and the proposed mechanical track based acquisition is available online (shorturl.at/jqvX0).",2023-02-16T13:50:07Z,2023-02-16T13:50:07Z,http://arxiv.org/abs/2302.08297v1,http://arxiv.org/pdf/2302.08297v1,"eess.IV, eess.SP"
3D Masked Autoencoders with Application to Anomaly Detection in   Non-Contrast Enhanced Breast MRI,"Daniel M. Lang, Eli Schwartz, Cosmin I. Bercea, Raja Giryes, Julia A. Schnabel","Self-supervised models allow (pre-)training on unlabeled data and therefore have the potential to overcome the need for large annotated cohorts. One leading self-supervised model is the masked autoencoder (MAE) which was developed on natural imaging data. The MAE is masking out a high fraction of visual transformer (ViT) input patches, to then recover the uncorrupted images as a pretraining task. In this work, we extend MAE to perform anomaly detection on breast magnetic resonance imaging (MRI). This new model, coined masked autoencoder for medical imaging (MAEMI) is trained on two non-contrast enhanced MRI sequences, aiming at lesion detection without the need for intravenous injection of contrast media and temporal image acquisition. During training, only non-cancerous images are presented to the model, with the purpose of localizing anomalous tumor regions during test time. We use a public dataset for model development. Performance of the architecture is evaluated in reference to subtraction images created from dynamic contrast enhanced (DCE)-MRI.",2023-03-10T11:31:02Z,2023-03-10T11:31:02Z,http://arxiv.org/abs/2303.05861v1,http://arxiv.org/pdf/2303.05861v1,eess.IV
MRI Reconstruction with Side Information using Diffusion Models,"Brett Levac, Ajil Jalal, Kannan Ramchandran, Jonathan I. Tamir","Magnetic resonance imaging (MRI) exam protocols consist of multiple contrast-weighted images of the same anatomy to emphasize different tissue properties. Due to the long acquisition times required to collect fully sampled k-space measurements, it is common to only collect a fraction of k-space for each scan and subsequently solve independent inverse problems for each image contrast. Recently, there has been a push to further accelerate MRI exams using data-driven priors, and generative models in particular, to regularize the ill-posed inverse problem of image reconstruction. These methods have shown promising improvements over classical methods. However, many of the approaches neglect the additional information present in a clinical MRI exam like the multi-contrast nature of the data and treat each scan as an independent reconstruction. In this work we show that by learning a joint Bayesian prior over multi-contrast data with a score-based generative model we are able to leverage the underlying structure between random variables related to a given imaging problem. This leads to an improvement in image reconstruction fidelity over generative models that rely only on a marginal prior over the image contrast of interest.",2023-03-26T19:00:53Z,2023-06-06T20:52:44Z,http://arxiv.org/abs/2303.14795v2,http://arxiv.org/pdf/2303.14795v2,"eess.IV, eess.SP"
DrDisco: Deep Registration for Distortion Correction of Diffusion MRI   with single phase-encoding,"Zhangxing Bian, Muhan Shao, Aaron Carass, Jerry L. Prince","Diffusion-weighted magnetic resonance imaging (DW-MRI) is a non-invasive way of imaging white matter tracts in the human brain. DW-MRIs are usually acquired using echo-planar imaging (EPI) with high gradient fields, which could introduce severe geometric distortions that interfere with further analyses. Most tools for correcting distortion require two minimally weighted DW-MRI images (B0) acquired with different phase-encoding directions, and they can take hours to process per subject. Since a great amount of diffusion data are only acquired with a single phase-encoding direction, the application of existing approaches is limited. We propose a deep learning-based registration approach to correct distortion using only the B0 acquired from a single phase-encoding direction. Specifically, we register undistorted T1-weighted images and distorted B0 to remove the distortion through a deep learning model. We apply a differentiable mutual information loss during training to improve inter-modality alignment. Experiments on the Human Connectome Project dataset show the proposed method outperforms SyN and VoxelMorph on several metrics, and only takes a few seconds to process one subject.",2023-04-01T04:04:06Z,2023-04-01T04:04:06Z,http://arxiv.org/abs/2304.00217v1,http://arxiv.org/pdf/2304.00217v1,eess.IV
On The Application Of Log Compression and Enhanced Denoising In Contrast   Enhancement Of Digital Radiography Images,"M. S. Asif, Mahesh Raveendranatha Panicker","Digital radiography (DR) is becoming popular for the point of care imaging in the recent past. To reduce the radiation exposure, controlled radiation based on as low as reasonably achievable (ALARA) principle is employed and this results in low contrast images. To address this issue, post-processing algorithms such as the Multiscale Image Contrast Amplification (MUSICA) algorithm can be used to enhance the contrast of DR images even with a low radiation dose. In this study, a modification of the MUSICA algorithm is investigated to determine the potential for further contrast improvement specifically for DR images. The conclusion is that combining log compression and its inverse at the appropriate stage with a multi-stage MUSICA and denoising is very promising. The proposed method resulted in an average of 66.5 % increase in the mean contrast-to-noise ratio (CNR) for the test images considered.",2023-04-08T14:28:29Z,2023-04-18T10:51:45Z,http://arxiv.org/abs/2304.04018v2,http://arxiv.org/pdf/2304.04018v2,eess.IV
Advancing Intra-operative Precision: Dynamic Data-Driven Non-Rigid   Registration for Enhanced Brain Tumor Resection in Image-Guided Neurosurgery,"Nikos Chrisochoides, Andriy Fedorov, Fotis Drakopoulos, Andriy Kot, Yixun Liu, Panos Foteinos, Angelos Angelopoulos, Olivier Clatz, Nicholas Ayache, Peter M. Black, Alex J. Golby, Ron Kikinis","During neurosurgery, medical images of the brain are used to locate tumors and critical structures, but brain tissue shifts make pre-operative images unreliable for accurate removal of tumors. Intra-operative imaging can track these deformations but is not a substitute for pre-operative data. To address this, we use Dynamic Data-Driven Non-Rigid Registration (NRR), a complex and time-consuming image processing operation that adjusts the pre-operative image data to account for intra-operative brain shift. Our review explores a specific NRR method for registering brain MRI during image-guided neurosurgery and examines various strategies for improving the accuracy and speed of the NRR method. We demonstrate that our implementation enables NRR results to be delivered within clinical time constraints while leveraging Distributed Computing and Machine Learning to enhance registration accuracy by identifying optimal parameters for the NRR method. Additionally, we highlight challenges associated with its use in the operating room.",2023-08-18T03:33:21Z,2023-08-31T19:50:27Z,http://arxiv.org/abs/2308.10868v2,http://arxiv.org/pdf/2308.10868v2,eess.IV
Frequency-Space Prediction Filtering for Phase Aberration Correction in   Plane-Wave Ultrasound,"Mostafa Sharifzadeh, Habib Benali, Hassan Rivaz","Ultrasound imaging often suffers from image degradation stemming from phase aberration, which represents a significant contributing factor to the overall image degradation in ultrasound imaging. Frequency-space prediction filtering or FXPF is a technique that has been applied within focused ultrasound imaging to alleviate the phase aberration effect. It presupposes the existence of an autoregressive (AR) model across the signals received at the transducer elements and removes any components that do not conform to the established model. In this study, we illustrate the challenge of applying this technique to plane-wave imaging, where, at shallower depths, signals from more distant elements lose relevance, and a fewer number of elements contribute to image reconstruction. While the number of contributing signals varies, adopting a fixed-order AR model across all depths, results in suboptimal performance. To address this challenge, we propose an AR model with an adaptive order and quantify its effectiveness using contrast and generalized contrast-to-noise ratio metrics.",2023-08-22T23:29:13Z,2023-08-22T23:29:13Z,http://arxiv.org/abs/2308.11830v1,http://arxiv.org/pdf/2308.11830v1,"eess.IV, eess.SP"
Accelerated Parallel Magnetic Resonance Imaging with Compressed Sensing   using Structured Sparsity,"Nicholas Dwork, Erin K. Englund","Compressed sensing is an imaging paradigm that allows one to invert an underdetermined linear system by imposing the a priori knowledge that the sought after solution is sparse (i.e., mostly zeros). Previous works have shown that if one also knows something about the sparsity pattern (the locations where non-zero entries exist), one can take advantage of this structure to improve the quality of the result. A significant application of compressed sensing is magnetic resonance imaging (MRI), where samples are acquired in the Fourier domain. Compressed sensing allows one to reconstruct a high-quality image with fewer samples which can be collected with a faster scan. This increases the robustness of MRI to patient motion since less motion is possible during the shorter scan. Parallel imaging, where multiple coils are used to gather data, is another an more ubiquitously used method for accelerating MRI. Existing combinations of these acceleration methods, such as Sparse SENSE, yield high quality images with an even shorter scan time than either technique alone. In this work, we show how to modify Sparse SENSE with structured sparsity to reconstruct a high quality image with even fewer samples.",2023-12-04T04:01:13Z,2023-12-04T04:01:13Z,http://arxiv.org/abs/2312.01610v1,http://arxiv.org/pdf/2312.01610v1,eess.IV
RoTIR: Rotation-Equivariant Network and Transformers for Fish Scale   Image Registration,"Ruixiong Wang, Alin Achim, Renata Raele-Rolfe, Qiao Tong, Dylan Bergen, Chrissy Hammond, Stephen Cross","Image registration is an essential process for aligning features of interest from multiple images. With the recent development of deep learning techniques, image registration approaches have advanced to a new level. In this work, we present 'Rotation-Equivariant network and Transformers for Image Registration' (RoTIR), a deep-learning-based method for the alignment of fish scale images captured by light microscopy. This approach overcomes the challenge of arbitrary rotation and translation detection, as well as the absence of ground truth data. We employ feature-matching approaches based on Transformers and general E(2)-equivariant steerable CNNs for model creation. Besides, an artificial training dataset is employed for semi-supervised learning. Results show RoTIR successfully achieves the goal of fish scale image registration.",2024-01-20T16:54:55Z,2024-07-27T10:47:05Z,http://arxiv.org/abs/2401.11270v2,http://arxiv.org/pdf/2401.11270v2,eess.IV
Artificial Intelligence in Image-based Cardiovascular Disease Analysis:   A Comprehensive Survey and Future Outlook,"Xin Wang, Hongtu Zhu","Recent advancements in Artificial Intelligence (AI) have significantly influenced the field of Cardiovascular Disease (CVD) analysis, particularly in image-based diagnostics. Our paper presents an extensive review of AI applications in image-based CVD analysis, offering insights into its current state and future potential. We systematically categorize the literature based on the primary anatomical structures related to CVD, dividing them into non-vessel structures (such as ventricles and atria) and vessel structures (including the aorta and coronary arteries). This categorization provides a structured approach to explore various imaging modalities like Magnetic Resonance Imaging (MRI), which are commonly used in CVD research. Our review encompasses these modalities, giving a broad perspective on the diverse imaging techniques integrated with AI for CVD analysis. Additionally, we compile a list of publicly accessible cardiac image datasets and code repositories, intending to support research reproducibility and facilitate data and algorithm sharing within the community. We conclude with an examination of the challenges and limitations inherent in current AI-based CVD analysis methods and suggest directions for future research to overcome these hurdles.",2024-02-04T19:56:06Z,2024-10-11T14:16:35Z,http://arxiv.org/abs/2402.03394v3,http://arxiv.org/pdf/2402.03394v3,eess.IV
Transformer-based Learned Image Compression for Joint Decoding and   Denoising,"Yi-Hsin Chen, Kuan-Wei Ho, Shiau-Rung Tsai, Guan-Hsun Lin, Alessandro Gnutti, Wen-Hsiao Peng, Riccardo Leonardi","This work introduces a Transformer-based image compression system. It has the flexibility to switch between the standard image reconstruction and the denoising reconstruction from a single compressed bitstream. Instead of training separate decoders for these tasks, we incorporate two add-on modules to adapt a pre-trained image decoder from performing the standard image reconstruction to joint decoding and denoising. Our scheme adopts a two-pronged approach. It features a latent refinement module to refine the latent representation of a noisy input image for reconstructing a noise-free image. Additionally, it incorporates an instance-specific prompt generator that adapts the decoding process to improve on the latent refinement. Experimental results show that our method achieves a similar level of denoising quality to training a separate decoder for joint decoding and denoising at the expense of only a modest increase in the decoder's model size and computational complexity.",2024-02-20T10:33:35Z,2024-02-20T10:33:35Z,http://arxiv.org/abs/2402.12888v1,http://arxiv.org/pdf/2402.12888v1,eess.IV
Off-Grid Ultrasound Imaging by Stochastic Optimization,"Vincent van de Schaft, Oisín Nolan, Ruud J. G. van Sloun","Ultrasound images formed by delay-and-sum beamforming are plagued by artifacts that only clear up after compounding many transmissions. Some prior works pose imaging as an inverse problem. This approach can yield high image quality with few transmits, but requires a very fine image grid and is not robust to changes in measurement model parameters. We present INverse grid-Free Estimation of Reflectivities (INFER), an off-grid and stochastic algorithm that solves the inverse scattering problem in ultrasound imaging. Our method jointly optimizes for the locations of the gridpoints, their reflectivities, and the measurement model parameters such as the speed of sound. This approach allows us to use significantly fewer gridpoints, while obtaining better contrast and resolution and being more robust to changes in the imaging target and the hardware. The use of stochastic optimization enables solving for multiple transmissions simultaneously without increasing the required memory or computational load per iteration. We show that our method works across different imaging targets and across different transmit schemes and compares favorably against other beamforming and inverse solvers. The source code and the dataset to reproduce the results in this paper are available at www.github.com/vincentvdschaft/off-grid-ultrasound.",2024-07-02T14:19:35Z,2024-07-02T14:19:35Z,http://arxiv.org/abs/2407.02285v1,http://arxiv.org/pdf/2407.02285v1,eess.SP
Accelerated Image-Aware Generative Diffusion Modeling,"Tanmay Asthana, Yufang Bao, Hamid Krim","We propose in this paper an analytically new construct of a diffusion model whose drift and diffusion parameters yield an exponentially time-decaying Signal to Noise Ratio in the forward process. In reverse, the construct cleverly carries out the learning of the diffusion coefficients on the structure of clean images using an autoencoder. The proposed methodology significantly accelerates the diffusion process, reducing the required diffusion time steps from around 1000 seen in conventional models to 200-500 without compromising image quality in the reverse-time diffusion. In a departure from conventional models which typically use time-consuming multiple runs, we introduce a parallel data-driven model to generate a reverse-time diffusion trajectory in a single run of the model. The resulting collective block-sequential generative model eliminates the need for MCMC-based sub-sampling correction for safeguarding and improving image quality, to further improve the acceleration of image generation. Collectively, these advancements yield a generative model that is an order of magnitude faster than conventional approaches, while maintaining high fidelity and diversity in generated images, hence promising widespread applicability in rapid image synthesis tasks.",2024-08-15T17:58:55Z,2024-08-15T17:58:55Z,http://arxiv.org/abs/2408.08306v1,http://arxiv.org/pdf/2408.08306v1,eess.IV
Variable Resolution Pixel Quantization for Low Power Machine Vision   Application on Edge,"Senorita Deb, Sai Sanjeet, Prabir Kumar Biswas, Bibhu Datta Sahoo","This work describes an approach towards pixel quantization using variable resolution which is made feasible using image transformation in the analog domain. The main aim is to reduce the average bits-per-pixel (BPP) necessary for representing an image while maintaining the classification accuracy of a Convolutional Neural Network (CNN) that is trained for image classification. The proposed algorithm is based on the Hadamard transform that leads to a low-resolution variable quantization by the analog-to-digital converter (ADC) thus reducing the power dissipation in hardware at the sensor node. Despite the trade-offs inherent in image transformation, the proposed algorithm achieves competitive accuracy levels across various image sizes and ADC configurations, highlighting the importance of considering both accuracy and power consumption in edge computing applications. The schematic of a novel 1.5 bit ADC that incorporates the Hadamard transform is also proposed. A hardware implementation of the analog transformation followed by software-based variable quantization is done for the CIFAR-10 test dataset. The digitized data shows that the network can still identify transformed images with a remarkable 90% accuracy for 3-BPP transformed images following the proposed method.",2024-10-07T16:48:01Z,2024-10-07T16:48:01Z,http://arxiv.org/abs/2410.05189v1,http://arxiv.org/pdf/2410.05189v1,eess.IV
Compensation based Dictionary Transfer for Similar Multispectral Image   Spectral Super-resolution,"Xiaolin Han, Huan Zhang, Lijuan Niu, Weidong Sun","Utilizing a spectral dictionary learned from a couple of similar-scene multi- and hyperspectral image, it is possible to reconstruct a desired hyperspectral image only with one single multispectral image. However, the differences between the similar scene and the desired hyperspectral image make it difficult to directly apply the spectral dictionary from the training domain to the task domain. To this end, a compensation matrix based dictionary transfer method for the similar-scene multispectral image spectral super-resolution is proposed in this paper, trying to reconstruct a more accurate high spatial resolution hyperspectral image. Specifically, a spectral dictionary transfer scheme is established by using a compensation matrix with similarity constraint, to transfer the spectral dictionary learned in the training domain to the spectral super-resolution domain. Subsequently, the sparse coefficient matrix is optimized under sparse and low-rank constraints. Experimental results on two AVIRIS datasets from different scenes indicate that, the proposed method outperforms other related SOTA methods.",2025-01-27T10:34:37Z,2025-01-27T10:34:37Z,http://arxiv.org/abs/2501.15937v1,http://arxiv.org/pdf/2501.15937v1,eess.IV
Evaluation of 3D GANs for Lung Tissue Modelling in Pulmonary CT,"Sam Ellis, Octavio E. Martinez Manzanera, Vasileios Baltatzis, Ibrahim Nawaz, Arjun Nair, Loïc Le Folgoc, Sujal Desai, Ben Glocker, Julia A. Schnabel","GANs are able to model accurately the distribution of complex, high-dimensional datasets, e.g. images. This makes high-quality GANs useful for unsupervised anomaly detection in medical imaging. However, differences in training datasets such as output image dimensionality and appearance of semantically meaningful features mean that GAN models from the natural image domain may not work `out-of-the-box' for medical imaging, necessitating re-implementation and re-evaluation. In this work we adapt and evaluate three GAN models to the task of modelling 3D healthy image patches for pulmonary CT. To the best of our knowledge, this is the first time that such an evaluation has been performed. The DCGAN, styleGAN and the bigGAN architectures were investigated due to their ubiquity and high performance in natural image processing. We train different variants of these methods and assess their performance using the FID score. In addition, the quality of the generated images was evaluated by a human observer study, the ability of the networks to model 3D domain-specific features was investigated, and the structure of the GAN latent spaces was analysed. Results show that the 3D styleGAN produces realistic-looking images with meaningful 3D structure, but suffer from mode collapse which must be addressed during training to obtain samples diversity. Conversely, the 3D DCGAN models show a greater capacity for image variability, but at the cost of poor-quality images. The 3D bigGAN models provide an intermediate level of image quality, but most accurately model the distribution of selected semantically meaningful features. The results suggest that future development is required to realise a 3D GAN with sufficient capacity for patch-based lung CT anomaly detection and we offer recommendations for future areas of research, such as experimenting with other architectures and incorporation of position-encoding.",2022-08-17T09:43:56Z,2022-08-17T09:43:56Z,http://arxiv.org/abs/2208.08184v1,http://arxiv.org/pdf/2208.08184v1,eess.IV
Edge-Aware Extended Star-Tetrix Transforms for CFA-Sampled Raw Camera   Image Compression,"Taizo Suzuki, Liping Huang","Codecs using spectral-spatial transforms efficiently compress raw camera images captured with a color filter array (CFA-sampled raw images) by changing their RGB color space into a decorrelated color space. This study describes two types of spectral-spatial transform, called extended Star-Tetrix transforms (XSTTs), and their edge-aware versions, called edge-aware XSTTs (EXSTTs), with no extra bits (side information) and little extra complexity. They are obtained by (i) extending the Star-Tetrix transform (STT), which is one of the latest spectral-spatial transforms, to a new version of our previously proposed wavelet-based spectral-spatial transform and a simpler version, (ii) considering that each 2-D predict step of the wavelet transform is a combination of two 1-D diagonal or horizontal-vertical transforms, and (iii) weighting the transforms along the edge directions in the images. Compared with XSTTs, the EXSTTs can decorrelate CFA-sampled raw images well: they reduce the difference in energy between the two green components by about $3.38$--$30.08$ \% for high-quality camera images and $8.97$--$14.47$ \% for mobile phone images. The experiments on JPEG 2000-based lossless and lossy compression of CFA-sampled raw images show better performance than conventional methods. For high-quality camera images, the XSTTs/EXSTTs produce results equal to or better than the conventional methods: especially for images with many edges, the type-I EXSTT improves them by about $0.03$--$0.19$ bpp in average lossless bitrate and the XSTTs improve them by about $0.16$--$0.96$ dB in average Bj\o ntegaard delta peak signal-to-noise ratio. For mobile phone images, our previous work perform the best, whereas the XSTTs/EXSTTs show similar trends to the case of high-quality camera images.",2022-09-02T10:09:22Z,2023-09-20T02:28:19Z,http://arxiv.org/abs/2209.00932v2,http://arxiv.org/pdf/2209.00932v2,"eess.IV, eess.SP"
Beyond MR Image Harmonization: Resolution Matters Too,"Savannah P. Hays, Samuel W. Remedios, Lianrui Zuo, Ellen M. Mowry, Scott D. Newsome, Peter A. Calabresi, Aaron Carass, Blake E. Dewey, Jerry L. Prince","Magnetic resonance (MR) imaging is commonly used in the clinical setting to non-invasively monitor the body. There exists a large variability in MR imaging due to differences in scanner hardware, software, and protocol design. Ideally, a processing algorithm should perform robustly to this variability, but that is not always the case in reality. This introduces a need for image harmonization to overcome issues of domain shift when performing downstream analysis such as segmentation. Most image harmonization models focus on acquisition parameters such as inversion time or repetition time, but they ignore an important aspect in MR imaging -- resolution. In this paper, we evaluate the impact of image resolution on harmonization using a pretrained harmonization algorithm. We simulate 2D acquisitions of various slice thicknesses and gaps from 3D acquired, 1mm3 isotropic MR images and demonstrate how the performance of a state-of-the-art image harmonization algorithm varies as resolution changes. We discuss the most ideal scenarios for image resolution including acquisition orientation when 3D imaging is not available, which is common for many clinical scanners. Our results show that harmonization on low-resolution images does not account for acquisition resolution and orientation variations. Super-resolution can be used to alleviate resolution variations but it is not always used. Our methodology can generalize to help evaluate the impact of image acquisition resolution for multiple tasks. Determining the limits of a pretrained algorithm is important when considering preprocessing steps and trust in the results.",2024-08-29T14:30:17Z,2024-08-30T13:19:57Z,http://arxiv.org/abs/2408.16562v2,http://arxiv.org/pdf/2408.16562v2,eess.IV
FDG-PET Parametric Imaging by Total Variation Minimization,"Hongbin Guo, Rosemary Renaut, Kewei Chen, Eric Reiman",Parametric imaging of the cerebral metabolic rate for glucose (CMRGlc) using [18F]-fluorodeoxyglucose positron emission tomography is considered. Traditional imaging is hindered due to low signal to noise ratios at individual voxels. We propose to minimize the total variation of the tracer uptake rates while requiring good fit of traditional Patlak equations. This minimization guarantees spatial homogeneity within brain regions and good distinction between brain regions. Brain phantom simulations demonstrate significant improvement in quality of images by the proposed method as compared to Patlak images with post-filtering using Gaussian or median filters.,2009-04-17T06:05:56Z,2009-04-17T06:05:56Z,http://arxiv.org/abs/0904.2639v1,http://arxiv.org/pdf/0904.2639v1,q-bio.QM
Compressed ghost edge imaging,"Hui Guo, Le Wang, Shengmei Zhao","In this paper, we propose an advanced framework of ghost edge imaging, named compressed ghost edge imaging (CGEI). In the scheme, a set of structured speckle patterns with pixel shifting are illuminated on an unknown object, and the output is collected by a bucket detector without any spatial resolution. By using compressed sensing algorithm, we obtain the horizontal and vertical edge information of the unknown object with the bucket detector detection results and the known structured speckle patterns. The edge is finally constructed by the two-dimentional edge information. The experimental and numerical simulations results show that the proposed scheme has a higher quality and reduces the number of measurements, in comparison with the existed edge detection schemes based on ghost imaging.",2019-02-22T12:40:57Z,2019-02-22T12:40:57Z,http://arxiv.org/abs/1902.09344v1,http://arxiv.org/pdf/1902.09344v1,eess.IV
Through-the-Wall Imaging Exploiting 2.4GHz Commodity Wi-Fi,"Wei Zhong, Kai He, Lianlin Li","In this letter, we experimentally investigate a low-cost through-the-wall imaging exploiting Wi-Fi signals in an indoor environment from the perspective of holographic imaging. In our experiments, a pair of antennas in a synthetic aperture mode is used to acquire signals produced by commodity Wi-Fi devices and reflected from the scene in a synthetic aperture mode. The classical filtered back propagation (FBP) algorithm is then employed to form the image based on these signals. We use an IEEE 802.11n wireless router working at 2.4GHz with bandwidth of 20MHz. Selected experimental results are provided to demonstrate the performance of the proposed Wi-Fi based imaging scheme.",2019-03-10T00:56:26Z,2019-03-10T00:56:26Z,http://arxiv.org/abs/1903.03895v1,http://arxiv.org/pdf/1903.03895v1,eess.SP
Cell image classification: a comparative overview,"Mohammad Shifat-E-Rabbi, Xuwang Yin, Cailey Elizabeth Fitzgerald, Gustavo K. Rohde","Cell image classification methods are currently being used in numerous applications in cell biology and medicine. Applications include understanding the effects of genes and drugs in screening experiments, understanding the role and subcellular localization of different proteins, as well as diagnosis and prognosis of cancer from images acquired using cytological and histological techniques. We review three different approaches for cell image classification: numerical feature extraction, end to end classification with neural networks, and transport-based morphometry. In addition, we provide comparisons on four different cell imaging datasets to highlight the relative strength of each method.",2019-06-07T20:00:38Z,2022-03-02T20:43:10Z,http://arxiv.org/abs/1906.03316v2,http://arxiv.org/pdf/1906.03316v2,q-bio.QM
Enhancing Patch-Based Methods with Inter-frame Connectivity for   Denoising Multi-frame Images,"Kireeti Bodduna, Joachim Weickert","The 3D block matching (BM3D) method is among the state-of-art methods for denoising images corrupted with additive white Gaussian noise. With the help of a novel inter-frame connectivity strategy, we propose an extension of the BM3D method for the scenario where we have multiple images of the same scene. Our proposed extension outperforms all the existing trivial and non-trivial extensions of patch-based denoising methods for multi-frame images. We can achieve a quality difference of as high as 28% over the next best method without using any additional parameters. Our method can also be easily generalised to other similar existing patch-based methods.",2019-06-17T16:23:13Z,2019-06-17T16:23:13Z,http://arxiv.org/abs/1906.07109v1,http://arxiv.org/pdf/1906.07109v1,eess.IV
Deep Residual Learning for Image Compression,"Zhengxue Cheng, Heming Sun, Masaru Takeuchi, Jiro Katto","In this paper, we provide a detailed description on our approach designed for CVPR 2019 Workshop and Challenge on Learned Image Compression (CLIC). Our approach mainly consists of two proposals, i.e. deep residual learning for image compression and sub-pixel convolution as up-sampling operations. Experimental results have indicated that our approaches, Kattolab, Kattolabv2 and KattolabSSIM, achieve 0.972 in MS-SSIM at the rate constraint of 0.15bpp with moderate complexity during the validation phase.",2019-06-24T05:31:41Z,2019-06-24T05:31:41Z,http://arxiv.org/abs/1906.09731v1,http://arxiv.org/pdf/1906.09731v1,eess.IV
CNN-Based Segmentation of the Cardiac Chambers and Great Vessels in   Non-Contrast-Enhanced Cardiac CT,"Steffen Bruns, Jelmer M. Wolterink, Robbert W. van Hamersvelt, Tim Leiner, Ivana Išgum","Quantification of cardiac structures in non-contrast CT (NCCT) could improve cardiovascular risk stratification. However, setting a manual reference to train a fully convolutional network (FCN) for automatic segmentation of NCCT images is hardly feasible, and an FCN trained on coronary CT angiography (CCTA) images would not generalize to NCCT. Therefore, we propose to train an FCN with virtual non-contrast (VNC) images from a dual-layer detector CT scanner and a reference standard obtained on perfectly aligned CCTA images.",2019-08-21T07:22:54Z,2019-08-21T07:22:54Z,http://arxiv.org/abs/1908.07727v1,http://arxiv.org/pdf/1908.07727v1,eess.IV
A Generalized Network for MRI Intensity Normalization,"A. Simkó, T. Löfstedt, A. Garpebring, T. Nyholm, J. Jonsson","Image normalization, the correction for intra-volume inhomogeneities in magnetic resonance imaging (MRI) data has little significance for visual diagnosis, but is a crucial step before automated radiotherapy solutions. There are several well-established normalization methods, however they are usually time expensive and difficult to tune for a specific dataset. In this study, we show how an artificial neural network (ANN) can be trained on non-medical images --- making the model general --- for intensity normalization on medical MRI images. Compared to one of the most well-known correction methods, N4ITK, the trained network achieves a higher accuracy with a speedup-factor of almost 70.",2019-09-12T07:00:24Z,2019-09-12T07:00:24Z,http://arxiv.org/abs/1909.05484v1,http://arxiv.org/pdf/1909.05484v1,eess.IV
Implementation of Digital Image Processing and Computation Technology on   Measurement and Testing of Various Woven Fabric Parameters,"Andrian Wijayono, Irwan, Siti Rohmah, Valentinus Galih Vidia Putra","Quality is one of the important things to be maintained in a weaving industry. Along with the times, technological developments in the field of image processing and computing have changed the old method of visual evaluation of woven fabric to be better. This chapter will explain the implementation of image and computational processing techniques on woven fabric.   Keywords: woven fabric, digital image processing.",2018-09-28T18:09:42Z,2018-09-28T18:09:42Z,http://arxiv.org/abs/1810.07651v1,http://arxiv.org/pdf/1810.07651v1,eess.IV
Impulse Denoising From Hyper-Spectral Images: A Blind Compressed Sensing   Approach,"Angshul Majumdar, Naushad Ansari, Hemant Aggarwal, Pravesh Biyani","In this work we propose a technique to remove sparse impulse noise from hyperspectral images. Our algorithm accounts for the spatial redundancy and spectral correlation of such images. The proposed method is based on the recently introduced Blind Compressed Sensing (BCS) framework, i.e. it empirically learns the spatial and spectral sparsifying dictionaries while denoising the images. The BCS framework differs from existing CS techniques - which assume the sparsifying dictionaries to be data independent, and from prior dictionary learning studies which learn the dictionary in an offline training phase. Our proposed formulation have shown over 5 dB improvement in PSNR over other techniques.",2019-12-11T12:43:56Z,2019-12-11T12:43:56Z,http://arxiv.org/abs/1912.06630v1,http://arxiv.org/pdf/1912.06630v1,"eess.IV, eess.SP"
The Property of Frequency Shift in 2D-FRFT Domain with Application to   Image Encryption,"Lei Gao, Lin Qi, Ling Guan","The Fractional Fourier Transform (FRFT) has been playing a unique and increasingly important role in signal and image processing. In this letter, we investigate the property of frequency shift in two-dimensional FRFT (2D-FRFT) domain. It is shown that the magnitude of image reconstruction from phase information is frequency shift-invariant in 2D-FRFT domain, enhancing the robustness of image encryption, an important multimedia security task. Experiments are conducted to demonstrate the effectiveness of this property against the frequency shift attack, improving the robustness of image encryption.",2021-02-28T01:08:04Z,2021-02-28T01:08:04Z,http://arxiv.org/abs/2103.00365v1,http://arxiv.org/pdf/2103.00365v1,eess.SP
Segmentation Algorithms for Ground-Based Infrared Cloud Images,"Guillermo Terrén-Serrano, Manel Martínez-Ramón","The increasing number of Photovoltaic (PV) systems connected to the power grid are vulnerable to the projection of shadows from moving clouds. Global Solar Irradiance (GSI) forecasting allows smart grids to optimize the energy dispatch, preventing energy shortages caused by occlusion of the sun. This investigation compares the performances of machine learning algorithms (not requiring labelled images for training) for real-time segmentation of clouds in images acquired using a ground-based infrared sky imager. Real-time segmentation is utilized to extract cloud features using only the pixels in which clouds are detected.",2021-02-19T20:35:00Z,2021-08-11T23:59:34Z,http://arxiv.org/abs/2102.10151v3,http://arxiv.org/pdf/2102.10151v3,eess.IV
Improved SAR Imaging Via Cross-Learning from Camera Images,"Shahzad Gishkori, David Wright, Liam Daniel, Marina Gashinova, Bernard Mulgrew","In this paper, we propose a novel concept of cross-learning, in order to improve SAR images by learning from the camera images. We use a multi-level abstraction approach to materialise knowledge transfer between the two modalities. We also compare the performance of other possible approaches. We provide experimental results on real data to validate the proposed concept.",2020-04-14T18:24:27Z,2020-04-14T18:24:27Z,http://arxiv.org/abs/2004.06749v1,http://arxiv.org/pdf/2004.06749v1,"eess.SP, eess.IV"
Accelerating computed tomographic imaging spectrometer reconstruction   using a parallel algorithm exploiting spatial shift-invariance,"Larz White, W. Bryan Bell, Ryan Haygood","Computed Tomographic Imaging Spectrometers (CTIS) capture hyperspectral images in realtime. However, post processing the imagery can require enormous computational resources; thus, limiting its application to non-realtime scenarios. To overcome these challenges we developed a highly parallelizable algorithm that exploits spatial shift-invariance. To demonstrate the versatility of our new algorithm, we developed implementations on a desktop and an embedded graphics processing unit (GPU). To our knowledge, our results show the fastest image reconstruction times reported.",2020-06-02T12:51:54Z,2020-06-02T12:51:54Z,http://arxiv.org/abs/2006.01573v1,http://arxiv.org/pdf/2006.01573v1,eess.IV
New Filters for Image Interpolation and Resizing,Amir Said,"We propose a new class of kernels to simplify the design of filters for image interpolation and resizing. Their properties are defined according to two parameters, specifying the width of the transition band and the height of a unique sidelobe. By varying these parameters it is possible to efficiently explore the space with only the filters that are suitable for image interpolation and resizing, and identify the filter that is best for a given application. These two parameters are also sufficient to obtain very good approximations of many commonly-used interpolation kernels. We also show that, because the Fourier transforms of these kernels have very fast decay, these filters produce better results when time-stretched for image downsizing.",2023-12-01T20:56:50Z,2023-12-01T20:56:50Z,http://arxiv.org/abs/2312.00926v1,http://arxiv.org/pdf/2312.00926v1,"eess.IV, eess.SP"
Cool-Chic: Perceptually Tuned Low Complexity Overfitted Image Coder,"Théo Ladune, Pierrick Philippe, Gordon Clare, Félix Henry, Thomas Leguay","This paper summarises the design of the Cool-Chic candidate for the Challenge on Learned Image Compression. This candidate attempts to demonstrate that neural coding methods can lead to low complexity and lightweight image decoders while still offering competitive performance. The approach is based on the already published overfitted lightweight neural networks Cool-Chic, further adapted to the human subjective viewing targeted in this challenge.",2024-01-04T09:08:14Z,2024-01-04T09:08:14Z,http://arxiv.org/abs/2401.02156v1,http://arxiv.org/pdf/2401.02156v1,eess.IV
GSBIQA: Green Saliency-guided Blind Image Quality Assessment Method,"Zhanxuan Mei, Yun-Cheng Wang, C. -C. Jay Kuo","Blind Image Quality Assessment (BIQA) is an essential task that estimates the perceptual quality of images without reference. While many BIQA methods employ deep neural networks (DNNs) and incorporate saliency detectors to enhance performance, their large model sizes limit deployment on resource-constrained devices. To address this challenge, we introduce a novel and non-deep-learning BIQA method with a lightweight saliency detection module, called Green Saliency-guided Blind Image Quality Assessment (GSBIQA). It is characterized by its minimal model size, reduced computational demands, and robust performance. Experimental results show that the performance of GSBIQA is comparable with state-of-the-art DL-based methods with significantly lower resource requirements.",2024-07-08T03:56:55Z,2024-07-08T03:56:55Z,http://arxiv.org/abs/2407.05590v1,http://arxiv.org/pdf/2407.05590v1,eess.IV
Stain Normalization of Hematology Slides using Neural Color Transfer,"M. Muneeb Arshad, Hasan Sajid, M. Jawad Khan","Deep learning is popularly used for analyzing pathology images, but variations in image properties can limit the effectiveness of the models. The study aims to develop a method that transfers the variability present in the training set to unseen images, improving the model's ability to make accurate inferences. YOLOv5 was trained on peripheral blood and bone marrow sample images and Neural Color Transfer techniques were used to incorporate invariance. The results showed significant improvement in detecting WBCs from untrained samples after normalization, highlighting the potential of deep learning-based normalization techniques for inference robustness.",2024-09-10T05:39:14Z,2024-09-10T05:39:14Z,http://arxiv.org/abs/2409.06742v1,http://arxiv.org/pdf/2409.06742v1,eess.IV
RIS-Aided Radar Imaging Utilizing the Virtual Source Principle,"Furkan H. Ilgac, Mounia Bouabdellah, Aydin Sezgin","This paper investigates signle-antenna radar imaging with a reconfigurable intelligent surface (RIS). Configuring phase shifts in a RIS-aided radar system can be thought as synthetic aperture radar (SAR) imaging with a moving virtual source. With this perspective, the problem is modeled in the wavenumber domain and image forming algorithms are formulated for near and far field regions. Thus, a novel and intuitive perspective has been introduced to the RIS-aided radar imaging formation problem, opening a new avenue for adapting well-known SAR methods in the literature to these systems.",2024-12-17T19:44:29Z,2024-12-17T19:44:29Z,http://arxiv.org/abs/2412.13291v1,http://arxiv.org/pdf/2412.13291v1,eess.SP
A Convex Model for Edge-Histogram Specification with Applications to   Edge-preserving Smoothing,"Kelvin C. K. Chan, Raymond H. Chan, Mila Nikolova","The goal of edge-histogram specification is to find an image whose edge image has a histogram that matches a given edge-histogram as much as possible. Mignotte has proposed a non-convex model for the problem [M. Mignotte. An energy-based model for the image edge-histogram specification problem. IEEE Transactions on Image Processing, 21(1):379--386, 2012]. In his work, edge magnitudes of an input image are first modified by histogram specification to match the given edge-histogram. Then, a non-convex model is minimized to find an output image whose edge-histogram matches the modified edge-histogram. The non-convexity of the model hinders the computations and the inclusion of useful constraints such as the dynamic range constraint. In this paper, instead of considering edge magnitudes, we directly consider the image gradients and propose a convex model based on them. Furthermore, we include additional constraints in our model based on different applications. The convexity of our model allows us to compute the output image efficiently using either Alternating Direction Method of Multipliers or Fast Iterative Shrinkage-Thresholding Algorithm. We consider several applications in edge-preserving smoothing including image abstraction, edge extraction, details exaggeration, and documents scan-through removal. Numerical results are given to illustrate that our method successfully produces decent results efficiently.",2018-06-21T08:07:07Z,2018-06-21T08:07:07Z,http://arxiv.org/abs/1806.08101v1,http://arxiv.org/pdf/1806.08101v1,eess.IV
Biomedical Image Reconstruction: From the Foundations to Deep Neural   Networks,"Michael T. McCann, Michael Unser","This tutorial covers biomedical image reconstruction, from the foundational concepts of system modeling and direct reconstruction to modern sparsity and learning-based approaches.   Imaging is a critical tool in biological research and medicine, and most imaging systems necessarily use an image-reconstruction algorithm to create an image; the design of these algorithms has been a topic of research since at least the 1960's. In the last few years, machine learning-based approaches have shown impressive performance on image reconstruction problems, triggering a wave of enthusiasm and creativity around the paradigm of learning. Our goal is to unify this body of research, identifying common principles and reusable building blocks across decades and among diverse imaging modalities.   We first describe system modeling, emphasizing how a few building blocks can be used to describe a broad range of imaging modalities. We then discuss reconstruction algorithms, grouping them into three broad generations. The first are the classical direct methods, including Tikhonov regularization; the second are the variational methods based on sparsity and the theory of compressive sensing; and the third are the learning-based (also called data-driven) methods, especially those using deep convolutional neural networks. There are strong links between these generations: classical (first-generation) methods appear as modules inside the latter two, and the former two are used to inspire new designs for learning-based (third-generation) methods. As a result, a solid understanding of all of three generations is necessary for the design of state-of-the-art algorithms.",2019-01-11T12:07:16Z,2021-03-11T16:34:07Z,http://arxiv.org/abs/1901.03565v3,http://arxiv.org/pdf/1901.03565v3,eess.IV
Learning Image and Video Compression through Spatial-Temporal Energy   Compaction,"Zhengxue Cheng, Heming Sun, Masaru Takeuchi, Jiro Katto","Compression has been an important research topic for many decades, to produce a significant impact on data transmission and storage. Recent advances have shown a great potential of learning image and video compression. Inspired from related works, in this paper, we present an image compression architecture using a convolutional autoencoder, and then generalize image compression to video compression, by adding an interpolation loop into both encoder and decoder sides. Our basic idea is to realize spatial-temporal energy compaction in learning image and video compression. Thereby, we propose to add a spatial energy compaction-based penalty into loss function, to achieve higher image compression performance. Furthermore, based on temporal energy distribution, we propose to select the number of frames in one interpolation loop, adapting to the motion characteristics of video contents. Experimental results demonstrate that our proposed image compression outperforms the latest image compression standard with MS-SSIM quality metric, and provides higher performance compared with state-of-the-art learning compression methods at high bit rates, which benefits from our spatial energy compaction approach. Meanwhile, our proposed video compression approach with temporal energy compaction can significantly outperform MPEG-4 and is competitive with commonly used H.264. Both our image and video compression can produce more visually pleasant results than traditional standards.",2019-06-24T01:14:13Z,2019-06-28T01:18:22Z,http://arxiv.org/abs/1906.09683v2,http://arxiv.org/pdf/1906.09683v2,eess.IV
Weighted Contourlet Parametric (WCP) Feature Based Breast Tumor   Classification from B-Mode Ultrasound Image,"Shahriar Mahmud Kabir, Md. Sayed Tanveer, ASM Shihavuddin, Mohammed Imamul Hassan Bhuiyan","Automated detection of breast tumor in early stages using B-Mode Ultrasound image is crucial for preventing widespread breast cancer specially among women. This paper is primarily focusing on the classification of breast tumors through statistical modelling such as Rician inverse Gaussian (RiIG) pdf of contourlet transformed B-Mode image of breast tumors which is not reported yet in other earlier works. The suitability of RiIG distribution in modeling the contourlet coefficients is illustrated and compared with that of Nakagami distribution. The proposed method consists of pre-processing to remove the speckle noise, segmentation of the lesion region, contourlet transform on the B-Mode Ultrasound image and using the corresponding contourlet sub-band coefficients and the RiIG parameters, production of contourlet parametric (CP) images and weighted contourlet parametric (WCP) images. A number of geometrical, statistical, and texture features are calculated from B-Mode and the contourlet parametric images. In order to classify the features, seven different classifiers are employed. The proposed approach is applied to two different datasets (Mendeley Data and Dataset B) those are available publicly. It is shown that with parametric images, accuracies in the range of 94-97% are achieved for different classifiers. Specifically, with the support vector machine and k-nearest-neighbor classifier, very high accuracies of 97.2% and 97.55% can be obtained for the Mendeley Data and Dataset B,respectively, using the weighted contourlet parametric images.The reported classification performance is also compared with that of other works using the datasets employed in this paper. It is seen that the proposed approach using weighted contourlet parametric images can provide a superior performance.",2021-02-11T09:03:56Z,2021-02-11T09:03:56Z,http://arxiv.org/abs/2102.05896v1,http://arxiv.org/pdf/2102.05896v1,eess.IV
Using Deep Convolutional Neural Networks to Circumvent Morphological   Feature Specification when Classifying Subvisible Protein Aggregates from   Micro-Flow Images,"Christopher P. Calderon, Austin L. Daniels, Theodore W. Randolph","Flow-Imaging Microscopy (FIM) is commonly used in both academia and industry to characterize subvisible particles (those $\le 25 \mu m$ in size) in protein therapeutics. Pharmaceutical companies are required to record vast volumes of FIM data on protein therapeutic products, but are only mandated under US FDA regulations (i.e., USP $\big \langle 788 \big \rangle$) to control the number of particles exceeding $10$ and $25 \mu m$ in delivered products. Hence, a vast amount of digital images are available to analyze. Current state-of-the-art methods rely on a relatively low-dimensional list of ""morphological features"" to characterize particles, but these methods ignore an enormous amount of information encoded in the existing large digital image repositories. Deep Convolutional Neural Networks (CNNs or ""ConvNets"") have demonstrated the ability to extract predictive information from raw macroscopic image data without requiring the selection or specification of ""morphological features"" in a variety of tasks. However, the heterogeneity, polydispersity of protein therapeutics, and optical phenomena associated with subvisible FIM particle measurements introduce new challenges regarding the application of CNNs to FIM image analysis. In this article, we demonstrate a supervised learning technique leveraging CNNs to extract information from raw images in order to predict the process conditions or stress states (freeze-thaw, mechanical shaking, etc.) that produced a variety of different protein images. We demonstrate that our new classifier (in combination with a sample ""image pooling"" strategy) can obtain nearly perfect predictions using as few as 20 FIM images from a given protein formulation in a variety of scenarios of relevance to protein therapeutics quality control and process monitoring.",2017-09-01T04:36:45Z,2017-09-01T04:36:45Z,http://arxiv.org/abs/1709.00152v1,http://arxiv.org/pdf/1709.00152v1,q-bio.QM
Estimating Depth-Salient Edges And its Application To Stereoscopic Image   Quality Assessment,"Sameeulla Khan Md, Sumohana Channappayya","The human visual system pays attention to salient regions while perceiving an image. When viewing a stereoscopic 3D (S3D) image, we hypothesize that while most of the contribution to saliency is provided by the 2D image, a small but significant contribution is provided by the depth component. Further, we claim that only a subset of image edges contribute to depth perception while viewing an S3D image. In this paper, we propose a systematic approach for depth saliency estimation, called Salient Edges with respect to Depth perception (SED) which localizes the depth-salient edges in an S3D image. We demonstrate the utility of SED in full reference stereoscopic image quality assessment (FRSIQA). We consider gradient magnitude and inter-gradient maps for predicting structural similarity. A coarse quality estimate is derived first by comparing the 2D saliency and gradient maps of reference and test stereo pairs. We refine this quality using SED maps for evaluating depth quality. Finally, we combine this luminance and depth quality to obtain an overall stereo image quality. We perform a comprehensive evaluation of our metric on seven publicly available S3D IQA databases. The proposed metric shows competitive performance on all seven databases with state-of-the-art performance on three of them.",2018-02-12T04:11:49Z,2018-09-21T10:25:42Z,http://arxiv.org/abs/1802.03883v3,http://arxiv.org/pdf/1802.03883v3,eess.IV
Di-chromatic Interpolation of Magnetic Resonance Metabolic Imagery,"Nicholas Dwork, Jeremy W. Gordon, Shuyu Tang, Daniel O'Connor, Esben Sovso Szocska Hansen, Christoffer Laustsen, Peder E. Z. Larson","Magnetic resonance imaging with hyperpolarized contrast agents can provide unprecedented \textit{in-vivo} measurements of metabolism, but yields images that are lower resolution than that achieved with proton anatomical imaging. In order to spatially localize the metabolic activity, the metabolic image must be interpolated to the size of the proton image. The most common methods for choosing the unknown values rely exclusively on values of the original un-interpolated image. In this work, we present an alternative method that uses the higher-resolution proton image to provide additional spatial structure. The interpolated image is the result of a convex optimization algorithm which is solved with the Fast Iterative Shrinkage Threshold Algorithm (FISTA). Results are shown with images of hyperpolarized pyruvate, lactate, and bicarbonate using data of the heart and brain from healthy human volunteers, a healthy porcine heart, and a human with prostate cancer.",2020-03-11T00:12:03Z,2021-02-12T18:42:05Z,http://arxiv.org/abs/2003.05042v4,http://arxiv.org/pdf/2003.05042v4,eess.IV
A semi-analytic reconstruction method for Diffuse Optical Tomography,"Tapan Das, P. K. Dutta","The Diffuse Optical Tomography (DOT) has received considerable attention in the recent years in the field of biomedical imaging and disease detection. However, imaging through highly diffusive medium is a challenge and stability is always an issue due to the inverse problem. Here a non-linear continous wave (CW) semi-analytic reconstruction method is discussed that used curved-beam paths for tomographic imaging with no assumption on inclusion, unlike iterative methods.The non-linear Rosenbrock's function is used to approximate the paths followed by majority photons as curved ones. The modified Beer-Lambert Law (MBLL) in proposed differntial form is used to calculate the absorption coefficient of all the avilable photon paths. The computed values are back-projected along these channels and serve as the basis for image reconstruction without solving the inverse problem. For three-dimensional (3-D) imaging, measurements at three different depths covering the entire depth of the phantom are taken. These slices are stacked together followed by interpolation to form the volumetric image of the phantom to complete the tomographic imaging in its true sense. Numerical simulations, wax phantom experiments with different geometries and contrast are carried out with satisfactory results. This semi-analytic reconstruction method is simple and efficient and is suitable for real-time applications that reqiure fast absorption image reconstruction. The method is compared with the Greedy algorithms for further validation. Also, different performance evaluation matrices are estimated to assess the accuracy of the reconstructed images and the results are rather satisfactory.",2020-03-28T13:37:26Z,2020-03-28T13:37:26Z,http://arxiv.org/abs/2003.12790v1,http://arxiv.org/pdf/2003.12790v1,eess.IV
Development of novel algorithm to visualize blood vessels on 3D   ultrasound images during liver surgery,"Fatemeh Salehihafshejani, Alireza Ahmadian, Afshin Shoeibi, Roohallah Alizadehsani, Habibollah Dashti, Niloofar Ayoobi Yazdi, Abbas Khosravi, Saeid Nahavandi","Volume visualization is a method that displays three-dimensional (3D) data in two-dimensional (2D) space. Using 3D datasets instead of 2D traditional images improves the visualization of anatomical structures, and volume visualization helps radiologists and surgeons to review large datasets comprehensively so that diagnosis and treatment can be enhanced. In liver surgery, blood vessel detection is important. Liver vessels have various shapes and due to the presence of noise in the ultrasound images, they can be confused with noise. Suboptimal images can sometimes lead to surgical errors where the surgeon may cut the blood vessel in error. The ultrasound system is versatile and portable and has the advantage of being able to be used in the operating theatre. Due to the nature of B-mode ultrasound, 1-D transfer function volume visualization of images cannot abrogate shadow artifacts. While multi-dimensional transfer function improves the ability to define features of interest, the high dimensionality in the parameter domain renders it unwieldy and difficult for clinicians to work with. To overcome these limitations, an algorithm for volume visualization that can provide effective 3D visualization of noisy B-mode ultrasound images, which can be useful for clinicians, is proposed. We propose a method that is appropriate for liver ultrasound images focusing on vessels and tumors (if present) in order to delineate their structure and positions clearly to preempt surgical error during operation. This method can prevent possible errors during liver surgery by providing more detailed high quality 3D images for clinicians. Key Words: Visualization, 3D ultrasound image, Volume Rendering, Liver surgery, Liver vessels.",2020-08-19T06:06:27Z,2020-08-19T06:06:27Z,http://arxiv.org/abs/2008.08280v1,http://arxiv.org/pdf/2008.08280v1,eess.IV
L2-Constrained RemNet for Camera Model Identification and Image   Manipulation Detection,"Abdul Muntakim Rafi, Jonathan Wu, Md. Kamrul Hasan","Source camera model identification (CMI) and image manipulation detection are of paramount importance in image forensics. In this paper, we propose an L2-constrained Remnant Convolutional Neural Network (L2-constrained RemNet) for performing these two crucial tasks. The proposed network architecture consists of a dynamic preprocessor block and a classification block. An L2 loss is applied to the output of the preprocessor block, and categorical crossentropy loss is calculated based on the output of the classification block. The whole network is trained in an end-to-end manner by minimizing the total loss, which is a combination of the L2 loss and the categorical crossentropy loss. Aided by the L2 loss, the data-adaptive preprocessor learns to suppress the unnecessary image contents and assists the classification block in extracting robust image forensics features. We train and test the network on the Dresden database and achieve an overall accuracy of 98.15%, where all the test images are from devices and scenes not used during training to replicate practical applications. The network also outperforms other state-of-the-art CNNs even when the images are manipulated. Furthermore, we attain an overall accuracy of 99.68% in image manipulation detection, which implies that it can be used as a general-purpose network for image forensic tasks.",2020-09-10T17:04:50Z,2020-09-14T16:15:34Z,http://arxiv.org/abs/2009.05379v2,http://arxiv.org/pdf/2009.05379v2,"eess.IV, eess.SP"
Complex Convolutional Neural Networks for Ultrafast Ultrasound Image   Reconstruction from In-Phase/Quadrature Signal,"Jingfeng Lu, Fabien Millioz, Damien Garcia, Sebastien Salles, Dong Ye, Denis Friboulet","Ultrafast ultrasound imaging remains an active area of interest in the ultrasound community due to its ultra-high frame rates. Recently, a wide variety of studies based on deep learning have sought to improve ultrafast ultrasound imaging. Most of these approaches have been performed on radio frequency (RF) signals. However, inphase/quadrature (I/Q) digital beamformers are now widely used as low-cost strategies. In this work, we used complex convolutional neural networks for reconstruction of ultrasound images from I/Q signals. We recently described a convolutional neural network architecture called ID-Net, which exploited an inception layer designed for reconstruction of RF diverging-wave ultrasound images. In the present study, we derive the complex equivalent of this network; i.e., the Complex-valued Inception for Diverging-wave Network (CID-Net) that operates on I/Q data. We provide experimental evidence that CID-Net provides the same image quality as that obtained from RF-trained convolutional neural networks; i.e., using only three I/Q images, the CID-Net produces high-quality images that can compete with those obtained by coherently compounding 31 RF images. Moreover, we show that CID-Net outperforms the straightforward architecture that consists of processing the real and imaginary parts of the I/Q signal separately, which thereby indicates the importance of consistently processing the I/Q signals using a network that exploits the complex nature of such signals.",2020-09-24T07:55:11Z,2021-11-01T03:44:46Z,http://arxiv.org/abs/2009.11536v3,http://arxiv.org/pdf/2009.11536v3,"eess.IV, eess.SP"
Compactification of the Rigid Motions Group in Image Processing,"Tamir Bendory, Ido Hadi, Nir Sharon","Image processing problems in general, and in particular in the field of single-particle cryo-electron microscopy, often require considering images up to their rotations and translations. Such problems were tackled successfully when considering images up to rotations only, using quantities which are invariant to the action of rotations on images. Extending these methods to cases where translations are involved is more complicated. Here we present a computationally feasible and theoretically sound approximate invariant to the action of rotations and translations on images. It allows one to approximately reduce image processing problems to similar problems over the sphere, a compact domain acted on by the group of 3D rotations, a compact group. We show that this invariant is induced by a family of mappings deforming, and thereby compactifying, the group structure of rotations and translations of the plane, i.e., the group of rigid motions, into the group of 3D rotations. Furthermore, we demonstrate its viability in two image processing tasks: multi-reference alignment and classification. To our knowledge, this is the first instance of a quantity that is either exactly or approximately invariant to rotations and translations of images that both rests on a sound theoretical foundation and also applicable in practice.",2021-06-25T08:55:43Z,2022-02-03T04:31:59Z,http://arxiv.org/abs/2106.13505v2,http://arxiv.org/pdf/2106.13505v2,eess.IV
WINNet: Wavelet-inspired Invertible Network for Image Denoising,"Jun-Jie Huang, Pier Luigi Dragotti","Image denoising aims to restore a clean image from an observed noisy image. The model-based image denoising approaches can achieve good generalization ability over different noise levels and are with high interpretability. Learning-based approaches are able to achieve better results, but usually with weaker generalization ability and interpretability. In this paper, we propose a wavelet-inspired invertible network (WINNet) to combine the merits of the wavelet-based approaches and learningbased approaches. The proposed WINNet consists of K-scale of lifting inspired invertible neural networks (LINNs) and sparsity-driven denoising networks together with a noise estimation network. The network architecture of LINNs is inspired by the lifting scheme in wavelets. LINNs are used to learn a non-linear redundant transform with perfect reconstruction property to facilitate noise removal. The denoising network implements a sparse coding process for denoising. The noise estimation network estimates the noise level from the input image which will be used to adaptively adjust the soft-thresholds in LINNs. The forward transform of LINNs produce a redundant multi-scale representation for denoising. The denoised image is reconstructed using the inverse transform of LINNs with the denoised detail channels and the original coarse channel. The simulation results show that the proposed WINNet method is highly interpretable and has strong generalization ability to unseen noise levels. It also achieves competitive results in the non-blind/blind image denoising and in image deblurring.",2021-09-14T01:08:32Z,2021-09-14T01:08:32Z,http://arxiv.org/abs/2109.06381v1,http://arxiv.org/pdf/2109.06381v1,eess.IV
Guided Nonlocal Patch Regularization and Efficient Filtering-Based   Inversion for Multiband Fusion,"Unni V. S., Pravin Nair, Kunal N. Chaudhury","In multiband fusion, an image with a high spatial and low spectral resolution is combined with an image with a low spatial but high spectral resolution to produce a single multiband image having high spatial and spectral resolutions. This comes up in remote sensing applications such as pansharpening~(MS+PAN), hyperspectral sharpening~(HS+PAN), and HS-MS fusion~(HS+MS). Remote sensing images are textured and have repetitive structures. Motivated by nonlocal patch-based methods for image restoration, we propose a convex regularizer that (i) takes into account long-distance correlations, (ii) penalizes patch variation, which is more effective than pixel variation for capturing texture information, and (iii) uses the higher spatial resolution image as a guide image for weight computation. We come up with an efficient ADMM algorithm for optimizing the regularizer along with a standard least-squares loss function derived from the imaging model. The novelty of our algorithm is that by expressing patch variation as filtering operations and by judiciously splitting the original variables and introducing latent variables, we are able to solve the ADMM subproblems efficiently using FFT-based convolution and soft-thresholding. As far as the reconstruction quality is concerned, our method is shown to outperform state-of-the-art variational and deep learning techniques.",2022-10-09T06:32:51Z,2022-10-09T06:32:51Z,http://arxiv.org/abs/2210.04184v1,http://arxiv.org/pdf/2210.04184v1,eess.IV
Jointly Resampling and Reconstructing Corrupted Images for Image   Classification using Frequency-Selective Mesh-to-Grid Resampling,"Viktoria Heimann, Andreas Spruck, André Kaup","Neural networks became the standard technique for image classification throughout the last years. They are extracting image features from a large number of images in a training phase. In a following test phase, the network is applied to the problem it was trained for and its performance is measured. In this paper, we focus on image classification. The amount of visual data that is interpreted by neural networks grows with the increasing usage of neural networks. Mostly, the visual data is transmitted from the application side to a central server where the interpretation is conducted. If the transmission is disturbed, losses occur in the transmitted images. These losses have to be reconstructed using postprocessing. In this paper, we incorporate the widely applied bilinear and bicubic interpolation and the high-quality reconstruction Frequency-Selective Reconstruction (FSR) for the reconstruction of corrupted images. However, we propose to use Frequency-Selective Mesh-to-Grid Resampling (FSMR) for the joint reconstruction and resizing of corrupted images. The performance in terms of classification accuracy of EfficientNetB0, DenseNet121, DenseNet201, ResNet50 and ResNet152 is examined. Results show that the reconstruction with FSMR leads to the highest classification accuracy for most networks. Average improvements of up to 6.7 percentage points are possible for DenseNet121.",2022-10-27T14:06:35Z,2023-11-27T17:13:16Z,http://arxiv.org/abs/2210.15444v3,http://arxiv.org/pdf/2210.15444v3,eess.IV
High-resolution and reliable automatic target recognition based on   photonic ISAR imaging system with explainable deep learning,"Xiuting Zou, Anyi Deng, Yiheng Hu, Shiyu Hua, Linbo Zhang, Shaofu Xu, Weiwen Zou","Automatic target recognition (ATR) based on inverse synthetic aperture radar (ISAR) images, which is extensively utilized to surveil environment in military and civil fields, must be high-precision and reliable. Photonic technologies' advantage of broad bandwidth enables ISAR systems to realize high-resolution imaging, which is in favor of achieving high-performance ATR. Deep learning (DL) algorithms have achieved excellent recognition accuracies. However, the lack of interpretability of DL algorithms causes the head-scratching problem of credibility. In this paper, we exploit the inner relationship between a photonic ISAR imaging system and behaviors of a convolutional neural network (CNN) to deeply comprehend the intelligent recognition. Specifically, we manipulate imaging physical process and analyze network outputs, the relevance between the ISAR image and network output, and the visualization of features in the network output layer. Consequently, the broader imaging bandwidths and appropriate imaging angles lead to more detailed structural and contour features and the bigger discrepancy among ISAR images of different targets, which contributes to the CNN recognizing and distinguishing objects according to physical laws. Then, based on the photonic ISAR imaging system and the explainable CNN, we accomplish a high-accuracy and reliable ATR. To the best of our knowledge, there is no precedent of explaining the DL algorithms by exploring the influence of the physical process of data generation on network behaviors. It is anticipated that this work can not only inspire the accomplishment of a high-performance ATR but also bring new insights to explore network behaviors and thus achieve better intelligent abilities.",2022-12-03T07:13:29Z,2022-12-03T07:13:29Z,http://arxiv.org/abs/2212.01560v1,http://arxiv.org/pdf/2212.01560v1,eess.SP
SPHR-SAR-Net: Superpixel High-resolution SAR Imaging Network Based on   Nonlocal Total Variation,"Guoru Zhou, Zhongqiu Xu, Yizhe Fan, Zhe Zhang, Xiaolan Qiu, Bingchen Zhang, Kun Fu, Yirong Wu","High-resolution is a key trend in the development of synthetic aperture radar (SAR), which enables the capture of fine details and accurate representation of backscattering properties. However, traditional high-resolution SAR imaging algorithms face several challenges. Firstly, these algorithms tend to focus on local information, neglecting non-local information between different pixel patches. Secondly, speckle is more pronounced and difficult to filter out in high-resolution SAR images. Thirdly, the process of high-resolution SAR imaging generally involves high time and computational complexity, making real-time imaging difficult to achieve. To address these issues, we propose a Superpixel High-Resolution SAR Imaging Network (SPHR-SAR-Net) for rapid despeckling in high-resolution SAR mode. Based on the concept of superpixel techniques, we initially combine non-convex and non-local total variation as compound regularization. This approach more effectively despeckles and manages the relationship between pixels while reducing bias effects caused by convex constraints. Subsequently, we solve the compound regularization model using the Alternating Direction Method of Multipliers (ADMM) algorithm and unfold it into a Deep Unfolded Network (DUN). The network's parameters are adaptively learned in a data-driven manner, and the learned network significantly increases imaging speed. Additionally, the Deep Unfolded Network is compatible with high-resolution imaging modes such as spotlight, staring spotlight, and sliding spotlight. In this paper, we demonstrate the superiority of SPHR-SAR-Net through experiments in both simulated and real SAR scenarios. The results indicate that SPHR-SAR-Net can rapidly perform high-resolution SAR imaging from raw echo data, producing accurate imaging results.",2023-04-10T07:21:07Z,2023-04-10T07:21:07Z,http://arxiv.org/abs/2304.04428v1,http://arxiv.org/pdf/2304.04428v1,eess.SP
Crucial Feature Capture and Discrimination for Limited Training Data SAR   ATR,"Chenwei Wang, Siyi Luo, Jifang Pei, Yulin Huang, Yin Zhang, Jianyu Yang","Although deep learning-based methods have achieved excellent performance on SAR ATR, the fact that it is difficult to acquire and label a lot of SAR images makes these methods, which originally performed well, perform weakly. This may be because most of them consider the whole target images as input, but the researches find that, under limited training data, the deep learning model can't capture discriminative image regions in the whole images, rather focus on more useless even harmful image regions for recognition. Therefore, the results are not satisfactory. In this paper, we design a SAR ATR framework under limited training samples, which mainly consists of two branches and two modules, global assisted branch and local enhanced branch, feature capture module and feature discrimination module. In every training process, the global assisted branch first finishes the initial recognition based on the whole image. Based on the initial recognition results, the feature capture module automatically searches and locks the crucial image regions for correct recognition, which we named as the golden key of image. Then the local extract the local features from the captured crucial image regions. Finally, the overall features and local features are input into the classifier and dynamically weighted using the learnable voting parameters to collaboratively complete the final recognition under limited training samples. The model soundness experiments demonstrate the effectiveness of our method through the improvement of feature distribution and recognition probability. The experimental results and comparisons on MSTAR and OPENSAR show that our method has achieved superior recognition performance.",2023-08-20T12:57:33Z,2023-08-20T12:57:33Z,http://arxiv.org/abs/2308.10911v1,http://arxiv.org/pdf/2308.10911v1,eess.IV
Towards Non-contact 3D Ultrasound for Wrist Imaging,"Antony Jerald, A. N. Madhavanunni, Gayathri Malamal, Mahesh Raveendranatha Panicker","Objective: The objective of this work is an attempt towards non-contact freehand 3D ultrasound imaging with minimal complexity added to the existing point of care ultrasound (POCUS) systems. Methods: This study proposes a novel approach of using a mechanical track for non-contact ultrasound (US) scanning. The approach thus restricts the probe motion to a linear plane, to simplify the acquisition and 3D reconstruction process. A pipeline for US 3D volume reconstruction employing an US research platform and a GPU-based edge device is developed. Results: The efficacy of the proposed approach is demonstrated through ex-vivo and in-vivo experiments. Conclusion: The proposed approach with the adjustable field of view capability, non-contact design, and low cost of deployment without significantly altering the existing setup would open doors for up gradation of traditional systems to a wide range of 3D US imaging applications. Significance: Ultrasound (US) imaging is a popular clinical imaging modality for the point-of-care bedside imaging, particularly of the wrist/knee in the pediatric population due to its non-invasive and radiation free nature. However, the limited views of tissue structures obtained with 2D US in such scenarios make the diagnosis challenging. To overcome this, 3D US imaging which uses 2D US images and their orientation/position to reconstruct 3D volumes was developed. The accurate position estimation of the US probe at low cost has always stood as a challenging task in 3D reconstruction. Additionally, US imaging involves contact, which causes difficulty to pediatric subjects while monitoring live fractures or open wounds. Towards overcoming these challenges, a novel framework is attempted in this work.",2023-10-06T14:59:40Z,2023-10-06T14:59:40Z,http://arxiv.org/abs/2310.04296v1,http://arxiv.org/pdf/2310.04296v1,eess.IV
AI-Generated Annotations Dataset for Diverse Cancer Radiology   Collections in NCI Image Data Commons,"Gowtham Krishnan Murugesan, Diana McCrumb, Mariam Aboian, Tej Verma, Rahul Soni, Fatima Memon, Keyvan Farahani, Linmin Pei, Ulrike Wagner, Andrey Y. Fedorov, David Clunie, Stephen Moore, Jeff Van Oss","The National Cancer Institute (NCI) Image Data Commons (IDC) offers publicly available cancer radiology collections for cloud computing, crucial for developing advanced imaging tools and algorithms. Despite their potential, these collections are minimally annotated; only 4% of DICOM studies in collections considered in the project had existing segmentation annotations. This project increases the quantity of segmentations in various IDC collections. We produced high-quality, AI-generated imaging annotations dataset of tissues, organs, and/or cancers for 11 distinct IDC image collections. These collections contain images from a variety of modalities, including computed tomography (CT), magnetic resonance imaging (MRI), and positron emission tomography (PET). The collections cover various body parts, such as the chest, breast, kidneys, prostate, and liver. A portion of the AI annotations were reviewed and corrected by a radiologist to assess the performance of the AI models. Both the AI's and the radiologist's annotations were encoded in conformance to the Digital Imaging and Communications in Medicine (DICOM) standard, allowing for seamless integration into the IDC collections as third-party analysis collections. All the models, images and annotations are publicly accessible.",2023-10-23T13:06:08Z,2024-10-21T16:51:09Z,http://arxiv.org/abs/2310.14897v3,http://arxiv.org/pdf/2310.14897v3,eess.IV
Arbitrary Scale Super-Resolution Assisted Lunar Crater Detection in   Satellite Images,"Atal Tewari, Nitin Khanna","Craters are one of the most studied planetary features used for different scientific analyses, such as estimation of surface age and surface processes. Satellite images utilized for crater detection often have low resolution (LR) due to hardware constraints and transmission time. Super-resolution (SR) is a practical and cost-effective solution; however, most SR approaches work on fixed integer scale factors, i.e., a single model can generate images of a specific resolution. In practical applications, SR on multiple scales provides various levels of detail, but training for each scale is resource-intensive. Therefore, this paper proposes a system for crater detection assisted with an arbitrary scale super-resolution approach (i.e., a single model can be used for multiple scale factors) for the lunar surface. Our work is composed of two subsystems. The first sub-system employs an arbitrary scale SR approach to generate super-resolved images of multiple resolutions. Subsequently, the second sub-system passes super-resolved images of multiple resolutions to a deep learning-based crater detection framework for identifying craters on the lunar surface. Employed arbitrary scale SR approach is based on a combination of convolution and transformer modules. For the crater detection sub-system, we utilize the Mask-RCNN framework. Using SR images of multiple resolutions, the proposed system detects 13.47% more craters from the ground truth than the craters detected using only the LR images. Further, in complex crater settings, specifically in overlapping and degraded craters, 11.84% and 15.01% more craters are detected as compared to the crater detection networks using only the LR images. The proposed system also leads to better localization performance, 3.19% IoU increment compared to the LR images",2024-02-07T18:19:58Z,2024-02-07T18:19:58Z,http://arxiv.org/abs/2402.05068v1,http://arxiv.org/pdf/2402.05068v1,eess.IV
ProxNF: Neural Field Proximal Training for High-Resolution 4D Dynamic   Image Reconstruction,"Luke Lozenski, Refik Mert Cam, Mark D. Pagel, Mark A. Anastasio, Umberto Villa","Accurate spatiotemporal image reconstruction methods are needed for a wide range of biomedical research areas but face challenges due to data incompleteness and computational burden. Data incompleteness arises from the undersampling often required to increase frame rates, while computational burden emerges due to the memory footprint of high-resolution images with three spatial dimensions and extended time horizons. Neural fields (NFs), an emerging class of neural networks that act as continuous representations of spatiotemporal objects, have previously been introduced to solve these dynamic imaging problems by reframing image reconstruction as a problem of estimating network parameters. Neural fields can address the twin challenges of data incompleteness and computational burden by exploiting underlying redundancies in these spatiotemporal objects. This work proposes ProxNF, a novel neural field training approach for spatiotemporal image reconstruction leveraging proximal splitting methods to separate computations involving the imaging operator from updates of the network parameters. Specifically, ProxNF evaluates the (subsampled) gradient of the data-fidelity term in the image domain and uses a fully supervised learning approach to update the neural field parameters. This method is demonstrated in two numerical phantom studies and an in-vivo application to tumor perfusion imaging in small animal models using dynamic contrast-enhanced photoacoustic computed tomography (DCE PACT).",2024-03-06T17:10:15Z,2024-10-09T15:20:41Z,http://arxiv.org/abs/2403.03860v3,http://arxiv.org/pdf/2403.03860v3,eess.IV
"Imaging transformer for MRI denoising with the SNR unit training:   enabling generalization across field-strengths, imaging contrasts, and   anatomy","Hui Xue, Sarah Hooper, Azaan Rehman, Iain Pierce, Thomas Treibel, Rhodri Davies, W Patricia Bandettini, Rajiv Ramasawmy, Ahsan Javed, Zheren Zhu, Yang Yang, James Moon, Adrienne Campbell, Peter Kellman","The ability to recover MRI signal from noise is key to achieve fast acquisition, accurate quantification, and high image quality. Past work has shown convolutional neural networks can be used with abundant and paired low and high-SNR images for training. However, for applications where high-SNR data is difficult to produce at scale (e.g. with aggressive acceleration, high resolution, or low field strength), training a new denoising network using a large quantity of high-SNR images can be infeasible.   In this study, we overcome this limitation by improving the generalization of denoising models, enabling application to many settings beyond what appears in the training data. Specifically, we a) develop a training scheme that uses complex MRIs reconstructed in the SNR units (i.e., the images have a fixed noise level, SNR unit training) and augments images with realistic noise based on coil g-factor, and b) develop a novel imaging transformer (imformer) to handle 2D, 2D+T, and 3D MRIs in one model architecture. Through empirical evaluation, we show this combination improves performance compared to CNN models and improves generalization, enabling a denoising model to be used across field-strengths, image contrasts, and anatomy.",2024-04-03T00:51:07Z,2024-04-03T00:51:07Z,http://arxiv.org/abs/2404.02382v1,http://arxiv.org/pdf/2404.02382v1,eess.IV
Convolutional Neural Network Transformer (CNNT) for Fluorescence   Microscopy image Denoising with Improved Generalization and Fast Adaptation,"Azaan Rehman, Alexander Zhovmer, Ryo Sato, Yosuke Mukoyama, Jiji Chen, Alberto Rissone, Rosa Puertollano, Harshad Vishwasrao, Hari Shroff, Christian A. Combs, Hui Xue","Deep neural networks have been applied to improve the image quality of fluorescence microscopy imaging. Previous methods are based on convolutional neural networks (CNNs) which generally require more time-consuming training of separate models for each new imaging experiment, impairing the applicability and generalization. Once the model is trained (typically with tens to hundreds of image pairs) it can then be used to enhance new images that are like the training data. In this study, we proposed a novel imaging-transformer based model, Convolutional Neural Network Transformer (CNNT), to outperform the CNN networks for image denoising. In our scheme we have trained a single CNNT based backbone model from pairwise high-low SNR images for one type of fluorescence microscope (instance structured illumination, iSim). Fast adaption to new applications was achieved by fine-tuning the backbone on only 5-10 sample pairs per new experiment. Results show the CNNT backbone and fine-tuning scheme significantly reduces the training time and improves the image quality, outperformed training separate models using CNN approaches such as - RCAN and Noise2Fast. Here we show three examples of the efficacy of this approach on denoising wide-field, two-photon and confocal fluorescence data. In the confocal experiment, which is a 5 by 5 tiled acquisition, the fine-tuned CNNT model reduces the scan time form one hour to eight minutes, with improved quality.",2024-04-06T20:34:14Z,2024-04-06T20:34:14Z,http://arxiv.org/abs/2404.04726v1,http://arxiv.org/pdf/2404.04726v1,q-bio.QM
Domain Influence in MRI Medical Image Segmentation: spatial versus   k-space inputs,"Erik Gösche, Reza Eghbali, Florian Knoll, Andreas M Rauschecker","Transformer-based networks applied to image patches have achieved cutting-edge performance in many vision tasks. However, lacking the built-in bias of convolutional neural networks (CNN) for local image statistics, they require large datasets and modifications to capture relationships between patches, especially in segmentation tasks. Images in the frequency domain might be more suitable for the attention mechanism, as local features are represented globally. By transforming images into the frequency domain, local features are represented globally. Due to MRI data acquisition properties, these images are particularly suitable. This work investigates how the image domain (spatial or k-space) affects segmentation results of deep learning (DL) models, focusing on attention-based networks and other non-convolutional models based on MLPs. We also examine the necessity of additional positional encoding for Transformer-based networks when input images are in the frequency domain. For evaluation, we pose a skull stripping task and a brain tissue segmentation task. The attention-based models used are PerceiverIO and a vanilla Transformer encoder. To compare with non-attention-based models, an MLP and ResMLP are also trained and tested. Results are compared with the Swin-Unet, the state-of-the-art medical image segmentation model. Experimental results show that using k-space for the input domain can significantly improve segmentation results. Also, additional positional encoding does not seem beneficial for attention-based networks if the input is in the frequency domain. Although none of the models matched the Swin-Unet's performance, the less complex models showed promising improvements with a different domain choice.",2024-07-01T15:21:41Z,2024-08-05T06:58:01Z,http://arxiv.org/abs/2407.01367v3,http://arxiv.org/pdf/2407.01367v3,eess.IV
Can Generative AI Replace Immunofluorescent Staining Processes? A   Comparison Study of Synthetically Generated CellPainting Images from   Brightfield,"Xiaodan Xing, Siofra Murdoch, Chunling Tang, Giorgos Papanastasiou, Jan Cross-Zamirski, Yunzhe Guo, Xianglu Xiao, Carola-Bibiane Schönlieb, Yinhai Wang, Guang Yang","Cell imaging assays utilizing fluorescence stains are essential for observing sub-cellular organelles and their responses to perturbations. Immunofluorescent staining process is routinely in labs, however the recent innovations in generative AI is challenging the idea of IF staining are required. This is especially true when the availability and cost of specific fluorescence dyes is a problem to some labs. Furthermore, staining process takes time and leads to inter-intra technician and hinders downstream image and data analysis, and the reusability of image data for other projects. Recent studies showed the use of generated synthetic immunofluorescence (IF) images from brightfield (BF) images using generative AI algorithms in the literature. Therefore, in this study, we benchmark and compare five models from three types of IF generation backbones, CNN, GAN, and diffusion models, using a publicly available dataset. This paper not only serves as a comparative study to determine the best-performing model but also proposes a comprehensive analysis pipeline for evaluating the efficacy of generators in IF image synthesis. We highlighted the potential of deep learning-based generators for IF image synthesis, while also discussed potential issues and future research directions. Although generative AI shows promise in simplifying cell phenotyping using only BF images with IF staining, further research and validations are needed to address the key challenges of model generalisability, batch effects, feature relevance and computational costs.",2024-06-15T09:42:11Z,2024-07-16T22:19:39Z,http://arxiv.org/abs/2407.09507v2,http://arxiv.org/pdf/2407.09507v2,eess.IV
Hardware Architecture Design of Model-Based Image Reconstruction Towards   Palm-size Photoacoustic Tomography,"Yuwei Zheng, Zijian Gao, Yuting Shen, Jiadong Zhang, Daohuai Jiang, Fengyu Liu, Feng Gao, Fei Gao","Photoacoustic (PA) imaging technology combines the advantages of optical imaging and ultrasound imaging, showing great potential in biomedical applications. Many preclinical studies and clinical applications urgently require fast, high-quality, low-cost and portable imaging system. Translating advanced image reconstruction algorithms into hardware implementations is highly desired. However, existing iterative PA image reconstructions, although exhibit higher accuracy than delay-and-sum algorithm, suffer from high computational cost. In this paper, we introduce a model-based hardware acceleration architecture based on superposed Wave (s-Wave) for palm-size PA tomography (palm-PAT), aiming at enhancing both the speed and performance of image reconstruction at a much lower system cost. To achieve this, we propose an innovative data reuse method that significantly reduces hardware storage resource consumption. We conducted experiments by FPGA implementation of the algorithm, using both phantoms and in vivo human finger data to verify the feasibility of the proposed method. The results demonstrate that our proposed architecture can substantially reduce system cost while maintaining high imaging performance. The hardware-accelerated implementation of the model-based algorithm achieves a speedup of up to approximately 270 times compared to the CPU, while the corresponding energy efficiency ratio is improved by more than 2700 times.",2024-08-12T10:51:17Z,2024-08-12T10:51:17Z,http://arxiv.org/abs/2408.06049v1,http://arxiv.org/pdf/2408.06049v1,eess.IV
Breaking the Barriers of One-to-One Usage of Implicit Neural   Representation in Image Compression: A Linear Combination Approach with   Performance Guarantees,"Sai Sanjeet, Seyyedali Hosseinalipour, Jinjun Xiong, Masahiro Fujita, Bibhu Datta Sahoo","In an era where the exponential growth of image data driven by the Internet of Things (IoT) is outpacing traditional storage solutions, this work explores and advances the potential of Implicit Neural Representation (INR) as a transformative approach to image compression. INR leverages the function approximation capabilities of neural networks to represent various types of data. While previous research has employed INR to achieve compression by training small networks to reconstruct large images, this work proposes a novel advancement: representing multiple images with a single network. By modifying the loss function during training, the proposed approach allows a small number of weights to represent a large number of images, even those significantly different from each other. A thorough analytical study of the convergence of this new training method is also carried out, establishing upper bounds that not only confirm the validity of the method but also offer insights into optimal hyperparameter design. The proposed method is evaluated on the Kodak, ImageNet, and CIFAR-10 datasets. Experimental results demonstrate that all 24 images in the Kodak dataset can be represented by linear combinations of two sets of weights, achieving a peak signal-to-noise ratio (PSNR) of 26.5 dB with as low as 0.2 bits per pixel (BPP). The proposed method matches the rate-distortion performance of state-of-the-art image codecs, such as BPG, on the CIFAR-10 dataset. Additionally, the proposed method maintains the fundamental properties of INR, such as arbitrary resolution reconstruction of images.",2024-09-19T22:57:40Z,2024-09-19T22:57:40Z,http://arxiv.org/abs/2409.13117v1,http://arxiv.org/pdf/2409.13117v1,eess.IV
Advancements in Image Resolution: Super-Resolution Algorithm for   Enhanced EOS-06 OCM-3 Data,"Ankur Garg, Tushar Shukla, Purvee Joshi, Debojyoti Ganguly, Ashwin Gujarati, Meenakshi Sarkar, KN Babu, Mehul Pandya, S. Manthira Moorthi, Debajyoti Dhar","The Ocean Color Monitor-3 (OCM-3) sensor is instrumental in Earth observation, achieving a critical balance between high-resolution imaging and broad coverage. This paper explores innovative imaging methods employed in OCM-3 and the transformative potential of super-resolution techniques to enhance image quality. The super-resolution model for OCM-3 (SOCM-3) addresses the challenges of contemporary satellite imaging by effectively navigating the trade-off between image clarity and swath width. With resolutions below 240 meters in Local Area Coverage (LAC) mode and below 750 meters in Global Area Coverage (GAC) mode, coupled with a wide 1550-kilometer swath and a 2-day revisit time, SOCM-3 emerges as a leading asset in remote sensing. The paper details the intricate interplay of atmospheric, motion, optical, and detector effects that impact image quality, emphasizing the necessity for advanced computational techniques and sophisticated algorithms for effective image reconstruction. Evaluation methods are thoroughly discussed, incorporating visual assessments using the Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE) metric and computational metrics such as Line Spread Function (LSF), Full Width at Half Maximum (FWHM), and Super-Resolution (SR) ratio. Additionally, statistical analyses, including power spectrum evaluations and target-wise spectral signatures, are employed to gauge the efficacy of super-resolution techniques. By enhancing both spatial resolution and revisit frequency, this study highlights significant advancements in remote sensing capabilities, providing valuable insights for applications across cryospheric, vegetation, oceanic, coastal, and domains. Ultimately, the findings underscore the potential of SOCM-3 to contribute meaningfully to our understanding of finescale oceanic phenomena and environmental monitoring.",2024-10-24T12:37:08Z,2024-10-24T12:37:08Z,http://arxiv.org/abs/2410.18690v1,http://arxiv.org/pdf/2410.18690v1,"eess.IV, eess.SP"
Color Correction Meets Cross-Spectral Refinement: A Distribution-Aware   Diffusion for Underwater Image Restoration,"Laibin Chang, Yunke Wang, Bo Du, Chang Xu","Underwater imaging often suffers from significant visual degradation, which limits its suitability for subsequent applications. While recent underwater image enhancement (UIE) methods rely on the current advances in deep neural network architecture designs, there is still considerable room for improvement in terms of cross-scene robustness and computational efficiency. Diffusion models have shown great success in image generation, prompting us to consider their application to UIE tasks. However, directly applying them to UIE tasks will pose two challenges, \textit{i.e.}, high computational budget and color unbalanced perturbations. To tackle these issues, we propose DiffColor, a distribution-aware diffusion and cross-spectral refinement model for efficient UIE. Instead of diffusing in the raw pixel space, we transfer the image into the wavelet domain to obtain such low-frequency and high-frequency spectra, it inherently reduces the image spatial dimensions by half after each transformation. Unlike single-noise image restoration tasks, underwater imaging exhibits unbalanced channel distributions due to the selective absorption of light by water. To address this, we design the Global Color Correction (GCC) module to handle the diverse color shifts, thereby avoiding potential global degradation disturbances during the denoising process. For the sacrificed image details caused by underwater scattering, we further present the Cross-Spectral Detail Refinement (CSDR) to enhance the high-frequency details, which are integrated with the low-frequency signal as input conditions for guiding the diffusion. This way not only ensures the high-fidelity of sampled content but also compensates for the sacrificed details. Comprehensive experiments demonstrate the superior performance of DiffColor over state-of-the-art methods in both quantitative and qualitative evaluations.",2025-01-08T03:26:45Z,2025-01-08T03:26:45Z,http://arxiv.org/abs/2501.04740v1,http://arxiv.org/pdf/2501.04740v1,eess.IV
Rethinking domain generalization in medical image segmentation: One   image as one domain,"Jin Hong, Bo Liu, Guoli Long","Domain shifts in medical image segmentation, particularly when data comes from different centers, pose significant challenges. Intra-center variability, such as differences in scanner models or imaging protocols, can cause domain shifts as large as, or even larger than, those between centers. To address this, we propose the ""one image as one domain"" (OIOD) hypothesis, which treats each image as a unique domain, enabling flexible and robust domain generalization. Based on this hypothesis, we develop a unified disentanglement-based domain generalization (UniDDG) framework, which simultaneously handles both multi-source and single-source domain generalization without requiring explicit domain labels. This approach simplifies training with a fixed architecture, independent of the number of source domains, reducing complexity and enhancing scalability. We decouple each input image into content representation and style code, then exchange and combine these within the batch for segmentation, reconstruction, and further disentanglement. By maintaining distinct style codes for each image, our model ensures thorough decoupling of content representations and style codes, improving domain invariance of the content representations. Additionally, we enhance generalization with expansion mask attention (EMA) for boundary preservation and style augmentation (SA) to simulate diverse image styles, improving robustness to domain shifts. Extensive experiments show that our method achieves Dice scores of 84.43% and 88.91% for multi-source to single-center and single-center generalization in optic disc and optic cup segmentation, respectively, and 86.96% and 88.56% for prostate segmentation, outperforming current state-of-the-art domain generalization methods, offering superior performance and adaptability across clinical settings.",2025-01-08T03:29:52Z,2025-01-08T03:29:52Z,http://arxiv.org/abs/2501.04741v1,http://arxiv.org/pdf/2501.04741v1,eess.IV
Deep Task-Based Beamforming and Channel Data Augmentations for Enhanced   Ultrasound Imaging,"Ariel Amar, Ahuva Grubstein, Eli Atar, Keren Peri-Hanania, Nimrod Glazer, Ronnie Rosen, Shlomi Savariego, Yonina C. Eldar","This paper introduces a deep learning (DL)-based framework for task-based ultrasound (US) beamforming, aiming to enhance clinical outcomes by integrating specific clinical tasks directly into the beamforming process. Task-based beamforming optimizes the beamformer not only for image quality but also for performance on a particular clinical task, such as lesion classification. The proposed framework explores two approaches: (1) a Joint Beamformer and Classifier (JBC) that classifies the US images generated by the beamformer to provide feedback for image quality improvement; and (2) a Channel Data Classifier Beamformer (CDCB) that incorporates classification directly at the channel data representation within the beamformer's bottleneck layer. Additionally, we introduce channel data augmentations to address challenges posed by noisy and limited in-vivo data. Numerical evaluations demonstrate that training with channel data augmentations significantly improves image quality. The proposed methods were evaluated against conventional Delay-and-Sum (DAS) and Minimum Variance (MV) beamforming techniques, demonstrating superior performance in terms of both image contrast and clinical relevance. Among all methods, the CDCB approach achieves the best results, outperforming others in terms of image quality and clinical relevance. These approaches exhibit significant potential for improving clinical relevance and image quality in ultrasound imaging.",2025-02-01T18:53:23Z,2025-02-01T18:53:23Z,http://arxiv.org/abs/2502.00524v1,http://arxiv.org/pdf/2502.00524v1,eess.IV
Fine-Tuning and Training of DenseNet for Histopathology Image   Representation Using TCGA Diagnostic Slides,"Abtin Riasatian, Morteza Babaie, Danial Maleki, Shivam Kalra, Mojtaba Valipour, Sobhan Hemati, Manit Zaveri, Amir Safarpoor, Sobhan Shafiei, Mehdi Afshari, Maral Rasoolijaberi, Milad Sikaroudi, Mohd Adnan, Sultaan Shah, Charles Choi, Savvas Damaskinos, Clinton JV Campbell, Phedias Diamandis, Liron Pantanowitz, Hany Kashani, Ali Ghodsi, H. R. Tizhoosh","Feature vectors provided by pre-trained deep artificial neural networks have become a dominant source for image representation in recent literature. Their contribution to the performance of image analysis can be improved through finetuning. As an ultimate solution, one might even train a deep network from scratch with the domain-relevant images, a highly desirable option which is generally impeded in pathology by lack of labeled images and the computational expense. In this study, we propose a new network, namely KimiaNet, that employs the topology of the DenseNet with four dense blocks, fine-tuned and trained with histopathology images in different configurations. We used more than 240,000 image patches with 1000x1000 pixels acquired at 20x magnification through our proposed ""highcellularity mosaic"" approach to enable the usage of weak labels of 7,126 whole slide images of formalin-fixed paraffin-embedded human pathology samples publicly available through the The Cancer Genome Atlas (TCGA) repository. We tested KimiaNet using three public datasets, namely TCGA, endometrial cancer images, and colorectal cancer images by evaluating the performance of search and classification when corresponding features of different networks are used for image representation. As well, we designed and trained multiple convolutional batch-normalized ReLU (CBR) networks. The results show that KimiaNet provides superior results compared to the original DenseNet and smaller CBR networks when used as feature extractor to represent histopathology images.",2021-01-20T00:03:29Z,2021-01-20T00:03:29Z,http://arxiv.org/abs/2101.07903v1,http://arxiv.org/pdf/2101.07903v1,eess.IV
DDPET-3D: Dose-aware Diffusion Model for 3D Ultra Low-dose PET Imaging,"Huidong Xie, Weijie Gan, Bo Zhou, Xiongchao Chen, Qiong Liu, Xueqi Guo, Liang Guo, Hongyu An, Ulugbek S. Kamilov, Ge Wang, Chi Liu","As PET imaging is accompanied by substantial radiation exposure and cancer risk, reducing radiation dose in PET scans is an important topic. Recently, diffusion models have emerged as the new state-of-the-art generative model to generate high-quality samples and have demonstrated strong potential for various tasks in medical imaging. However, it is difficult to extend diffusion models for 3D image reconstructions due to the memory burden. Directly stacking 2D slices together to create 3D image volumes would results in severe inconsistencies between slices. Previous works tried to either apply a penalty term along the z-axis to remove inconsistencies or reconstruct the 3D image volumes with 2 pre-trained perpendicular 2D diffusion models. Nonetheless, these previous methods failed to produce satisfactory results in challenging cases for PET image denoising. In addition to administered dose, the noise levels in PET images are affected by several other factors in clinical settings, e.g. scan time, medical history, patient size, and weight, etc. Therefore, a method to simultaneously denoise PET images with different noise-levels is needed. Here, we proposed a Dose-aware Diffusion model for 3D low-dose PET imaging (DDPET-3D) to address these challenges. We extensively evaluated DDPET-3D on 100 patients with 6 different low-dose levels (a total of 600 testing studies), and demonstrated superior performance over previous diffusion models for 3D imaging problems as well as previous noise-aware medical image denoising models. The code is available at: https://github.com/xxx/xxx.",2023-11-07T08:10:16Z,2023-11-28T06:40:37Z,http://arxiv.org/abs/2311.04248v2,http://arxiv.org/pdf/2311.04248v2,eess.IV
"Comparing LBP, HOG and Deep Features for Classification of   Histopathology Images","Taha J. Alhindi, Shivam Kalra, Ka Hin Ng, Anika Afrin, Hamid R. Tizhoosh","Medical image analysis has become a topic under the spotlight in recent years. There is a significant progress in medical image research concerning the usage of machine learning. However, there are still numerous questions and problems awaiting answers and solutions, respectively. In the present study, comparison of three classification models is conducted using features extracted using local binary patterns, the histogram of gradients, and a pre-trained deep network. Three common image classification methods, including support vector machines, decision trees, and artificial neural networks are used to classify feature vectors obtained by different feature extractors. We use KIMIA Path960, a publicly available dataset of $960$ histopathology images extracted from $20$ different tissue scans to test the accuracy of classification and feature extractions models used in the study, specifically for the histopathology images. SVM achieves the highest accuracy of $90.52\%$ using local binary patterns as features which surpasses the accuracy obtained by deep features, namely $81.14\%$.",2018-05-03T14:50:57Z,2018-05-03T14:50:57Z,http://arxiv.org/abs/1805.05837v1,http://arxiv.org/pdf/1805.05837v1,eess.IV
Detection of delayed target response in SAR,"Mikhail Gilman, Semyon Tsynkov","Delayed target response in synthetic aperture radar (SAR) imaging can be obscured by the range-delay ambiguity and speckle. To analyze the range-delay ambiguity, one extends the standard SAR formulation and allows both the target reflectivity and the image to depend not only on the coordinates, but also on the response delay. However, this still leaves the speckle unaccounted for. Yet speckle is commonly found in SAR images of extended targets, and a statistical approach is usually employed to describe it. We have developed a simple model of a delayed scatterer by modifying the random function that describes a homogeneous extended scatterer. Our model allows us to obtain a relation between the deterministic parameters of the target model and statistical moments of the SAR image. We assume a regular shape of the antenna trajectory, and our model targets are localized in at least one space-time coordinate; this permits analytical formulation for statistical moments of the image. The problem of reconstruction of coordinate-delay reflectivity function is reduced to that of discrimination between instantaneous and delayed scatterers; for the latter problem, the maximum likelihood based image processing procedure has been developed. We perform Monte-Carlo simulation and evaluate performance of the classification procedure for a simple dependence of scatterer reflectivity on the delay time.",2019-01-15T21:32:29Z,2019-01-15T21:32:29Z,http://arxiv.org/abs/1901.05441v1,http://arxiv.org/pdf/1901.05441v1,eess.IV
Color imaging through the scattering media based on phase retrieval with   triple correlation,"Lei Zhu, Yuxiang Wu, Jietao Liu, Tengfei Wu, Lixian Liu, Xiaopeng Shao","Light passing through scattering media will be strongly scattered and diffused into complex speckle pattern, which however contains almost all the spatial information and color information of the objects. Although various technologies have been proposed to realize color imaging through the scattering media, current technologies are still complex with long sequence of measurement for each imaging pixel or spectral point spread functions of optical system. Here we theoretically prove the spatial averaging of triple correlation technique can be used to retrieve the Fourier phase of object, and experimentally demonstrate it can be applied in color imaging through scattering media. Compared to other phase retrieval techniques, the phase retrieval with triple correlation technique can retain the orientation information of objects, and can composite color image without rotation operation. Furthermore, our approach has the potential of realizing spectral imaging through scattering media.",2019-01-31T10:22:32Z,2019-07-29T07:55:33Z,http://arxiv.org/abs/1902.00379v4,http://arxiv.org/pdf/1902.00379v4,eess.IV
Optimization of light fields in ghost imaging using dictionary learning,"Chenyu Hu, Zhisheng Tong, Zhentao Liu, Zengfeng Huang, Jian Wang, Shensheng Han","Ghost imaging (GI) is a novel imaging technique based on the second-order correlation of light fields. Due to limited number of samplings in practice, traditional GI methods often reconstruct objects with unsatisfactory quality. To improve the imaging results, many reconstruction methods have been developed, yet the reconstruction quality is still fundamentally restricted by the modulated light fields. In this paper, we propose to improve the imaging quality of GI by optimizing the light fields, which is realized via matrix optimization for a learned dictionary incorporating the sparsity prior of objects. A closed-form solution of the sampling matrix, which enables successive sampling, is derived. Through simulation and experimental results, it is shown that the proposed scheme leads to better imaging quality compared to the state-of-the-art optimization methods for light fields, especially at a low sampling rate.",2019-06-07T12:34:38Z,2019-08-06T04:33:25Z,http://arxiv.org/abs/1906.03050v3,http://arxiv.org/pdf/1906.03050v3,eess.IV
Statistical characterization of scattering delay in synthetic aperture   radar imaging,"Mikhail Gilman, Semyon Tsynkov","Distinguishing between the instantaneous and delayed scatterers in synthetic aperture radar (SAR) images is important for target identification and characterization. To perform this task, one can use the autocorrelation analysis of coordinate-delay images. However, due to the range-delay ambiguity the difference in the correlation properties between the instantaneous and delayed targets may be small. Moreover, the reliability of discrimination is affected by speckle, which is ubiquitous in SAR images, and requires statistical treatment.   Previously, we have developed a maximum likelihood based approach for discriminating between the instantaneous and delayed targets in SAR images. To test it, we employed simple statistical models. They allowed us to simulate ensembles of images that depend on various parameters, including aperture width and target contrast.   In the current paper, we enhance our previously developed methodology by establishing confidence levels for the discrimination between the instantaneous and delayed scatterers. Our procedure takes into account the difference in thresholds for different target contrasts without making any assumptions about the statistics of those contrasts.",2019-08-21T21:43:31Z,2019-09-22T21:25:36Z,http://arxiv.org/abs/1908.08124v2,http://arxiv.org/pdf/1908.08124v2,eess.IV
A Hardware Realization of Superresolution Combining Random Coding and   Blurring,"Kevin Beale, Jianbo Chen, Kevin F. Kelly, Justin Romberg","Resolution enhancements are often desired in imaging applications where high-resolution sensor arrays are difficult to obtain. Many computational imaging methods have been proposed to encode high-resolution scene information on low-resolution sensors by cleverly modulating light from the scene before it hits the sensor. These methods often require movement of some portion of the imaging apparatus or only acquire images up to the resolution of a modulating element. Here a technique is presented for resolving beyond the resolutions of both a pointwise-modulating mask element and a sensor array through the introduction of a controlled blur into the optical pathway. The analysis contains an intuitive and exact expression for the overall superresolvability of the system, and arguments are presented to explain how the combination of random coding and blurring makes the superresolution problem well-posed. Experimental results demonstrate that a resolution enhancement of approximately $4\times$ is possible in practice using standard optical components, without mechanical motion of the imaging apparatus, and without any a priori assumptions on scene structure.",2018-10-20T21:43:48Z,2018-10-20T21:43:48Z,http://arxiv.org/abs/1810.08855v1,http://arxiv.org/pdf/1810.08855v1,eess.IV
Patch-based Interferometric Phase Estimation via Mixture of Gaussian   Density Modelling & Non-local Averaging in the Complex Domain,"Joshin P. Krishnan, José M. Bioucas-Dias","This paper addresses interferometric phase (InPhase) image denoising, i.e., the denoising of phase modulo-2p images from sinusoidal 2p-periodic and noisy observations. The wrapping discontinuities present in the InPhase images, which are to be preserved carefully, make InPhase denoising a challenging inverse problem. We propose a novel two-step algorithm to tackle this problem by exploiting the non-local self-similarity of the InPhase images. In the first step, the patches of the phase images are modelled using Mixture of Gaussian (MoG) densities in the complex domain. An Expectation Maximization(EM) algorithm is formulated to learn the parameters of the MoG from the noisy data. The learned MoG is used as a prior for estimating the InPhase images from the noisy images using Minimum Mean Square Error (MMSE) estimation. In the second step, an additional exploitation of non-local self-similarity is done by performing a type of non-local mean filtering. Experiments conducted on simulated and real (MRI and InSAR) datasets show results which are competitive with the state-of-the-art techniques.",2018-10-24T18:30:17Z,2018-10-24T18:30:17Z,http://arxiv.org/abs/1810.10571v1,http://arxiv.org/pdf/1810.10571v1,eess.SP
Increase the frame rate of a camera via temporal ghost imaging,"Wenjie Jiang, Xianye Li, Shan Jiang, Yupeng Wang, Zexin Zhang, Guanbai He, Baoqing Sun","Computational temporal ghost imaging (CTGI) allows the reconstruction of a fast signal from a two dimensional detection with no temporal resolution. High speed spatial modulation is implemented to encode temporal detail of the signal into the two dimensional detection. By calculating the correlation between the modulation and the rendered image, the temporal information can be retrieved. CTGI indicates a way to detect high speed non-reproducible signal from a slow detector. Based on CTGI, we propose an innovative scheme that can increase the frame rate of a camera by resolving the temporal detail of every camera image. To achieve this, CTGI is conducted parallelly to different areas of the scene. High speed spatial multiplexed modulation is performed, constraining the continuous scene into a series of short-time-scale frames. All the modulated frames are accumulated into one image that is eventually used in the correlation retrieval process. By performing CTGI reconstruction on each area independently, the temporal detail of the whole scene can be obtained. This method can have a strong application in ultrafast imaging.",2018-12-02T07:46:24Z,2018-12-02T07:46:24Z,http://arxiv.org/abs/1812.00348v1,http://arxiv.org/pdf/1812.00348v1,eess.IV
Composition-Aware Spectroscopic Tomography,"Luke Pfister, Rohit Bhargava, Yoram Bresler, P. Scott Carney","Chemical imaging provides information about the distribution of chemicals within a target. When combined with structural information about the target, in situ chemical imaging opens the door to applications ranging from tissue classification to industrial process monitoring. The combination of infrared spectroscopy and optical microscopy is a powerful tool for chemical imaging of thin targets. Unfortunately, extending this technique to targets with appreciable depth is prohibitively slow.   We combine confocal microscopy and infrared spectroscopy to provide chemical imaging in three spatial dimensions. Interferometric measurements are acquired at a small number of focal depths, and images are formed by solving a regularized inverse scattering problem. A low-dimensional signal model is key to our approach: we assume the target comprises a finite number of distinct chemical species. We establish conditions on the constituent spectra and the number of measurements needed for unique recovery of the target. Simulations illustrate imaging of cellular phantoms and sub-wavelength targets from noisy measurements.",2019-12-28T00:39:39Z,2020-09-04T23:50:38Z,http://arxiv.org/abs/1912.12374v3,http://arxiv.org/pdf/1912.12374v3,eess.IV
GAN-based Hyperspectral Anomaly Detection,"Sertac Arisoy, Nasser M. Nasrabadi, Koray Kayabol","In this paper, we propose a generative adversarial network (GAN)-based hyperspectral anomaly detection algorithm. In the proposed algorithm, we train a GAN model to generate a synthetic background image which is close to the original background image as much as possible. By subtracting the synthetic image from the original one, we are able to remove the background from the hyperspectral image. Anomaly detection is performed by applying Reed-Xiaoli (RX) anomaly detector (AD) on the spectral difference image. In the experimental part, we compare our proposed method with the classical RX, Weighted-RX (WRX) and support vector data description (SVDD)-based anomaly detectors and deep autoencoder anomaly detection (DAEAD) method on synthetic and real hyperspectral images. The detection results show that our proposed algorithm outperforms the other methods in the benchmark.",2020-07-05T20:31:50Z,2020-07-05T20:31:50Z,http://arxiv.org/abs/2007.02441v1,http://arxiv.org/pdf/2007.02441v1,eess.IV
Temporal Feature Fusion with Sampling Pattern Optimization for   Multi-echo Gradient Echo Acquisition and Image Reconstruction,"Jinwei Zhang, Hang Zhang, Chao Li, Pascal Spincemaille, Mert Sabuncu, Thanh D. Nguyen, Yi Wang","Quantitative imaging in MRI usually involves acquisition and reconstruction of a series of images at multi-echo time points, which possibly requires more scan time and specific reconstruction technique compared to conventional qualitative imaging. In this work, we focus on optimizing the acquisition and reconstruction process of multi-echo gradient echo pulse sequence for quantitative susceptibility mapping as one important quantitative imaging method in MRI. A multi-echo sampling pattern optimization block extended from LOUPE-ST is proposed to optimize the k-space sampling patterns along echoes. Besides, a recurrent temporal feature fusion block is proposed and inserted into a backbone deep ADMM network to capture the signal evolution along echo time during reconstruction. Experiments show that both blocks help improve multi-echo image reconstruction performance.",2021-03-10T05:36:04Z,2021-03-10T05:36:04Z,http://arxiv.org/abs/2103.05878v1,http://arxiv.org/pdf/2103.05878v1,"eess.SP, eess.IV"
Enhanced Radar Imaging Using a Complex-valued Convolutional Neural   Network,"Jingkun Gao, Bin Deng, Yuliang Qin, Hongqiang Wang, Xiang Li","Convolutional neural networks (CNN) have been successfully employed to tackle several remote sensing tasks such as image classification and show better performance than previous techniques. For the radar imaging community, a natural question is: Can CNN be introduced to radar imaging and enhance its performance? The presented letter gives an affirmative answer to this question. We firstly propose a processing framework by which a complex-valued CNN (CV-CNN) is used to enhance radar imaging. Then we introduce two modifications to the CV-CNN to adapt it to radar imaging tasks. Subsequently, the method to generate training data is shown and some implementation details are presented. Finally, simulations and experiments are carried out, and both results show the superiority of the proposed method on imaging quality and computational efficiency.",2017-12-29T02:14:25Z,2018-06-30T01:39:37Z,http://arxiv.org/abs/1712.10096v2,http://arxiv.org/pdf/1712.10096v2,eess.SP
A SARS-CoV-2 Microscopic Image Dataset with Ground Truth Images and   Visual Features,"Chen Li, Jiawei Zhang, Frank Kulwa, Shouliang Qi, Ziyu Qi","SARS-CoV-2 has characteristics of wide contagion and quick propagation velocity. To analyse the visual information of it, we build a SARS-CoV-2 Microscopic Image Dataset (SC2-MID) with 48 electron microscopic images and also prepare their ground truth images. Furthermore, we extract multiple classical features and novel deep learning features to describe the visual information of SARS-CoV-2. Finally, it is proved that the visual features of the SARS-CoV-2 images which are observed under the electron microscopic can be extracted and analysed.",2020-04-07T14:07:08Z,2021-03-06T04:49:51Z,http://arxiv.org/abs/2004.03416v5,http://arxiv.org/pdf/2004.03416v5,eess.IV
Microwave Photonic Imaging Radar with a Millimeter-level Resolution,"Cong Ma, Yue Yang, Ce Liu, Beichen Fan, Xingwei Ye, Yamei Zhang, Xiangchuan Wang, Shilong Pan","Microwave photonic radars enable fast or even real-time high-resolution imaging thanks to its broad bandwidth. Nevertheless, the frequency range of the radars usually overlaps with other existed radio-frequency (RF) applications, and only a centimeter-level imaging resolution has been reported, making them insufficient for civilian applications. Here, we propose a microwave photonic imaging radar with a millimeter-level resolution by introducing a frequency-stepped chirp signal based on an optical frequency shifting loop. As compared with the conventional linear-frequency modulated (LFM) signal, the frequency-stepped chirp signal can bring the system excellent capability of anti-interference. In an experiment, a frequency-stepped chirp signal with a total bandwidth of 18.2 GHz (16.9 to 35.1 GHz) is generated. Postprocessing the radar echo, radar imaging with a two-dimensional imaging resolution of ~8.5 mm$\times$~8.3 mm is achieved. An auto-regressive algorithm is used to reconstruct the disturbed signal when a frequency interference exists, and the high-resolution imaging is sustained.",2020-04-09T16:17:32Z,2020-04-09T16:17:32Z,http://arxiv.org/abs/2004.06047v1,http://arxiv.org/pdf/2004.06047v1,eess.SP
On Solving SAR Imaging Inverse Problems Using Non-Convex Regularization   with a Cauchy-based Penalty,"Oktay Karakuş, Alin Achim","Synthetic aperture radar (SAR) imagery can provide useful information in a multitude of applications, including climate change, environmental monitoring, meteorology, high dimensional mapping, ship monitoring, or planetary exploration. In this paper, we investigate solutions to a number of inverse problems encountered in SAR imaging. We propose a convex proximal splitting method for the optimization of a cost function that includes a non-convex Cauchy-based penalty. The convergence of the overall cost function optimization is ensured through careful selection of model parameters within a forward-backward (FB) algorithm. The performance of the proposed penalty function is evaluated by solving three standard SAR imaging inverse problems, including super-resolution, image formation, and despeckling, as well as ship wake detection for maritime applications. The proposed method is compared to several methods employing classical penalty functions such as total variation ($TV$) and $L_1$ norms, and to the generalized minimax-concave (GMC) penalty. We show that the proposed Cauchy-based penalty function leads to better image reconstruction results when compared to the reference penalty functions for all SAR imaging inverse problems in this paper.",2020-05-01T23:56:07Z,2020-06-03T11:17:00Z,http://arxiv.org/abs/2005.00657v2,http://arxiv.org/pdf/2005.00657v2,"eess.SP, eess.IV"
Blind De-Blurring of Microscopy Images for Cornea Cell Counting,"Alon Tchelet, Leonardo Mussa, Stefano Vojinovic","Cornea cell count is an important diagnostic tool commonly used by practitioners to assess the health of a patient's cornea. Unfortunately, clinical specular microscopy requires the acquisition of a large number of images at different focus depths because the curved shape of the cornea makes it impossible to acquire a single all-in-focus image. This paper describes two methods and their implementations to reduce the number of images required to run a cell-counting algorithm, thus shortening the duration of the examination and increasing the patient's comfort. The basic idea is to apply de-blurring techniques on the raw images to reconstruct the out-of-focus areas and expand the sharp regions of the image. Our approach is based on blind-deconvolution reconstruction that performs a depth-from-deblur so to either model Gaussian kernel or to fit kernels from an ad hoc lookup table.",2020-06-05T17:13:43Z,2020-06-05T17:13:43Z,http://arxiv.org/abs/2006.03562v1,http://arxiv.org/pdf/2006.03562v1,eess.IV
Online Graph-Based Change Point Detection in Multiband Image Sequences,"Ricardo Augusto Borsoi, Cédric Richard, André Ferrari, Jie Chen, José Carlos Moreira Bermudez","The automatic detection of changes or anomalies between multispectral and hyperspectral images collected at different time instants is an active and challenging research topic. To effectively perform change-point detection in multitemporal images, it is important to devise techniques that are computationally efficient for processing large datasets, and that do not require knowledge about the nature of the changes. In this paper, we introduce a novel online framework for detecting changes in multitemporal remote sensing images. Acting on neighboring spectra as adjacent vertices in a graph, this algorithm focuses on anomalies concurrently activating groups of vertices corresponding to compact, well-connected and spectrally homogeneous image regions. It fully benefits from recent advances in graph signal processing to exploit the characteristics of the data that lie on irregular supports. Moreover, the graph is estimated directly from the images using superpixel decomposition algorithms. The learning algorithm is scalable in the sense that it is efficient and spatially distributed. Experiments illustrate the detection and localization performance of the method.",2020-06-24T20:40:53Z,2020-06-24T20:40:53Z,http://arxiv.org/abs/2006.14033v1,http://arxiv.org/pdf/2006.14033v1,"eess.SP, eess.IV"
Pan-Sharpening with Color-Aware Perceptual Loss and Guided   Re-Colorization,"Juan Luis Gonzalez Bello, Soomin Seo, Munchurl Kim","We present a novel color-aware perceptual (CAP) loss for learning the task of pan-sharpening. Our CAP loss is designed to focus on the deep features of a pre-trained VGG network that are more sensitive to spatial details and ignore color information to allow the network to extract the structural information from the PAN image while keeping the color from the lower resolution MS image. Additionally, we propose ""guided re-colorization"", which generates a pan-sharpened image with real colors from the MS input by ""picking"" the closest MS pixel color for each pan-sharpened pixel, as a human operator would do in manual colorization. Such a re-colorized (RC) image is completely aligned with the pan-sharpened (PS) network output and can be used as a self-supervision signal during training, or to enhance the colors in the PS image during test. We present several experiments where our network trained with our CAP loss generates naturally looking pan-sharpened images with fewer artifacts and outperforms the state-of-the-arts on the WorldView3 dataset in terms of ERGAS, SCC, and QNR metrics.",2020-06-30T07:42:48Z,2020-06-30T07:42:48Z,http://arxiv.org/abs/2006.16583v1,http://arxiv.org/pdf/2006.16583v1,eess.IV
Model-based iterative reconstruction for spectral-domain optical   coherence tomography,"Jonathan H. Mason, Yvonne Reinwald, Ying Yang, Sarah Waters, Alicia El Haj, Pierre O. Bagnaninchi","Spectral domain optical coherence tomography (OCT) offers high resolution multidimensional imaging, but generally suffers from defocussing, intensity falloff and shot noise, causing artifacts and image degradation along the imaging depth. In this work, we develop an iterative statistical reconstruction technique, based upon the interferometric synthetic aperture microscopy (ISAM) model with additive noise, to actively compensate for these effects. For the ISAM re-sampling, we use a non uniform FFT with Kaiser-Bessel interpolation, offering efficiency and high accuracy. We then employ an accelerated gradient descent based algorithm, to minimize the negative log-likelihood of the model, and include spatial or wavelet sparsity based penalty functions, to provide appropriate regularization for given image structures. We evaluate our approach with titanium oxide micro-bead and cucumber samples with a commercial spectral domain OCT system, under various subsampling regimes, and demonstrate superior image quality over traditional reconstruction and ISAM methods.",2021-08-02T11:45:18Z,2021-08-02T11:45:18Z,http://arxiv.org/abs/2108.01438v1,http://arxiv.org/pdf/2108.01438v1,eess.IV
Iterative Self-consistent Parallel Magnetic Resonance Imaging   Reconstruction based on Nonlocal Low-Rank Regularization,"Ting Pan, Jizhong Duan, Junfeng Wang, Yu Liu","Iterative self-consistent parallel imaging reconstruction (SPIRiT) is an effective self-calibrated reconstruction model for parallel magnetic resonance imaging (PMRI). The joint L1 norm of wavelet coefficients and joint total variation (TV) regularization terms are incorporated into the SPIRiT model to improve the reconstruction performance. The simultaneous two-directional low-rankness (STDLR) in k-space data is incorporated into SPIRiT to realize improved reconstruction. Recent methods have exploited the nonlocal self-similarity (NSS) of images by imposing nonlocal low-rankness of similar patches to achieve a superior performance. To fully utilize both the NSS in Magnetic resonance (MR) images and calibration consistency in the k-space domain, we propose a nonlocal low-rank (NLR)-SPIRiT model by incorporating NLR regularization into the SPIRiT model. We apply the weighted nuclear norm (WNN) as a surrogate of the rank and employ the Nash equilibrium (NE) formulation and alternating direction method of multipliers (ADMM) to efficiently solve the NLR-SPIRiT model. The experimental results demonstrate the superior performance of NLR-SPIRiT over the state-of-the-art methods via three objective metrics and visual comparison.",2021-08-10T08:45:28Z,2022-04-17T08:27:50Z,http://arxiv.org/abs/2108.04517v2,http://arxiv.org/pdf/2108.04517v2,"eess.IV, eess.SP"
0.8% Nyquist computational ghost imaging via non-experimental deep   learning,"Haotian Song, Xiaoyu Nie, Hairong Su, Hui Chen, Yu Zhou, Xingchen Zhao, Tao Peng, Marlan O. Scully","We present a framework for computational ghost imaging based on deep learning and customized pink noise speckle patterns. The deep neural network in this work, which can learn the sensing model and enhance image reconstruction quality, is trained merely by simulation. To demonstrate the sub-Nyquist level in our work, the conventional computational ghost imaging results, reconstructed imaging results using white noise and pink noise via deep learning are compared under multiple sampling rates at different noise conditions. We show that the proposed scheme can provide high-quality images with a sampling rate of 0.8% even when the object is outside the training dataset, and it is robust to noisy environments. This method is excellent for various applications, particularly those that require a low sampling rate, fast reconstruction efficiency, or experience strong noise interference.",2021-08-17T15:15:02Z,2021-08-17T15:15:02Z,http://arxiv.org/abs/2108.07673v1,http://arxiv.org/pdf/2108.07673v1,eess.IV
Sparse regularization with a non-convex penalty for SAR imaging and   autofocusing,"Zi-Yao Zhang, Odysseas Pappas, Igor G. Rizaev, Alin Achim","In this paper, SAR image reconstruction with joint phase error estimation (autofocusing) is formulated as an inverse problem. An optimization model utilising a sparsity-enforcing Cauchy regularizer is proposed, and an alternating minimization framework is used to solve it, in which the desired image and the phase errors are optimized alternatively. For the image reconstruction sub-problem (f-sub-problem), two methods are presented capable of handling the problem's complex nature, and we thus present two variants of our SAR image autofocusing algorithm. Firstly, we design a complex version of the forward-backward splitting algorithm (CFBA) to solve the f-sub-problem iteratively. For the second variant, the Wirtinger alternating minimization autofocusing (WAMA) method is presented, in which techniques of Wirtinger calculus are utilized to minimize the complex-valued cost function in the f-sub-problem in a direct fashion. For both methods, the phase error estimation sub-problem is solved by simply expanding and observing its cost function. Moreover, the convergence of both algorithms is discussed in detail. By conducting experiments on both simulated scenes and real SAR images, the proposed method is demonstrated to give impressive autofocusing results compared to other state of the art methods.",2021-08-22T21:57:44Z,2021-08-22T21:57:44Z,http://arxiv.org/abs/2108.09855v1,http://arxiv.org/pdf/2108.09855v1,"eess.IV, eess.SP"
Noise-specific denoising method with applications to high-frequency   ultrasonic images,"Gonzalo D. Maso Talou, Pablo J. Blanco","Denoising is of utmost importance for the visualization and processing of images featuring low signal-to-noise ratio. Total variation methods are among the most popular techniques to perform this task improving the signal-to-noise ratio while preserving coherent intensity discontinuities. In this work, a novel method, termed maximum likelihood data, is proposed, endowing the total variation formulation with the capability to deal with noise-specific models and pre-processing stages for a certain image of interest. To do this, the data fidelity term is modified by means of a maximum likelihood estimator between the original and the denoised image. To assess the improvements of the proposed method with respect to the total variation formulation, we study the denoising of high-frequency ultrasonic images on in-silico and in-vivo setups. The proposed method delivered a better contrast, preservation and localization of the structures while diminishing the intensity bias of the total variation formulation for the multiplicative noise. The enhancement of medical images through denoising helps to improve the outcome of subsequently applied image processing such as registration and segmentation procedures.",2022-01-21T03:33:30Z,2022-01-21T03:33:30Z,http://arxiv.org/abs/2201.08527v1,http://arxiv.org/pdf/2201.08527v1,eess.SP
Noise Perturbation for Saliency Prediction with Psychophysical Synthetic   Images,Qiang Li,"Convolutional neural networks (CNNs) have achieved great success in natural image saliency prediction. The primary goal of this study is to investigate the performance of saliency prediction in CNN and classic models with psychophysical synthetic images under noise perturbation. Is it still as decent as natural images in terms of performance? In the meantime, it can be used to investigate the relationship between CNNs and human vision, mainly low-level vision functions. On the other hand, are CNNs exact replicas of human visual function? This study used CNNs, Fourier, and spectral models inspired by low-level vision systems to investigate saliency prediction on psychophysical synthetic images rather than natural images. According to our findings, saliency prediction models inspired by Fourier and spectral theory outperformed current pre-trained deep neural networks on psychophysical images with noise perturbation. However, psychophysical models were more unstable in noise than pre-trained deep neural networks. Meanwhile, we suggested that investigating CNNs with psychophysical methods could benefit visual neuroscience and artificial neural network studies.",2022-04-12T20:19:20Z,2023-09-28T18:51:39Z,http://arxiv.org/abs/2204.06071v7,http://arxiv.org/pdf/2204.06071v7,q-bio.NC
Online multi-resolution fusion of space-borne multispectral images,"Haoqing Li, Bhavia Duvviri, Ricardo Borsoi, Tales Imbiriba, Edward Beighley, Deniz Erdogmus, Pau Closas","Satellite imaging has a central role in monitoring, detecting and estimating the intensity of key natural phenomena. One important feature of satellite images is the trade-off between spatial/spectral resolution and their revisiting time, a consequence of design and physical constraints imposed by satellite orbit among other technical limitations. In this paper, we focus on fusing multi-temporal, multi-spectral images where data acquired from different instruments with different spatial resolutions is used. We leverage the spatial relationship between images at multiple modalities to generate high-resolution image sequences at higher revisiting rates. To achieve this goal, we formulate the fusion method as a recursive state estimation problem and study its performance in filtering and smoothing contexts. The proposed strategy clearly outperforms competing methodologies, which is shown in the paper for real data acquired by the Landsat and MODIS instruments.",2022-04-26T19:59:09Z,2022-04-26T19:59:09Z,http://arxiv.org/abs/2204.12566v1,http://arxiv.org/pdf/2204.12566v1,eess.IV
Image Acquisition System Using On Sensor Compressed Sampling Technique,"Pravir Singh Gupta, Gwan Seong Choi","Advances in CMOS technology have made high resolution image sensors possible. These image sensor pose significant challenges in terms of the amount of raw data generated, energy efficiency and frame rate. This paper presents a new design methodology for an imaging system and a simplified novel image sensor pixel design to be used in such system so that Compressed Sensing (CS) technique can be implemented easily at the sensor level. This results in significant energy savings as it not only cuts the raw data rate but also reduces transistor count per pixel, decreases pixel size, increases fill factor, simplifies ADC, JPEG encoder and JPEG decoder design and decreases wiring as well as address decoder size by half. Thus CS has the potential to increase the resolution of image sensors for a given technology and die size while significantly decreasing the power consumption and design complexity. We show that it has potential to reduce power consumption by about 23%-65%.",2017-09-20T19:19:58Z,2018-01-11T13:29:04Z,http://arxiv.org/abs/1709.07041v2,http://arxiv.org/pdf/1709.07041v2,eess.IV
Having your cake and eating it too: Scripted workflows for image   manipulation,"Paul A. Thompson, Norm Matloff, Alex Fu, Ariel Shin","The reproducibility issue in science has come under increased scrutiny. One consistent suggestion lies in the use of scripted methods or workflows for data analysis. Image analysis is one area in science in which little can be done in scripted methods. The SWIIM Project (Scripted Workflows to Improve Image Manipulation) is designed to generate workflows from popular image manipulation tools. In the project, 2 approaches are being taken to construct workflows in the image analysis area. First, the open-source tool GIMP is being enhanced to produce an active log (which can be run on a stand-alone basis to perform the same manipulation). Second, the R system Shiny tool is being used to construct a graphical user interface (GUI) which works with EBImage code to modify images, and to produce an active log which can perform the same operations. This process has been successful to date, but is not complete. The basic method for each component is discussed, and example code is shown.",2017-08-29T21:10:07Z,2017-08-29T21:10:07Z,http://arxiv.org/abs/1709.07406v1,http://arxiv.org/pdf/1709.07406v1,eess.IV
The Coupled TuFF-BFF Algorithm for Automatic 3D Segmentation of   Microglia,"Tiffany Ly, Jeremy Thompson, Tajie Harris, Scott T. Acton","We propose an automatic 3D segmentation algorithm for multiphoton microscopy images of microglia. Our method is capable of segmenting tubular and blob-like structures from noisy images. Current segmentation techniques and software fail to capture the fine processes and soma of the microglia cells, useful for the study of the microglia role in the brain during healthy and diseased states. Our coupled tubularity flow field (TuFF)-blob flow field (BFF) method evolves a level set toward the object boundary using the directional tubularity and blobness measure of 3D images. Our method found a 20% performance increase against state of the art segmentation methods on a dataset of 3D images of microglia even in images with intensity heterogeneity throughout the object. The coupled TuFF-BFF segmentation results also yielded 40% improvement in accuracy for the ramification index of the processes, which displays the efficacy of our method.",2018-02-12T16:07:01Z,2018-02-12T16:07:01Z,http://arxiv.org/abs/1802.04156v1,http://arxiv.org/pdf/1802.04156v1,eess.IV
Joint Bilateral Filter for Signal Recovery from Phase Preserved Curvelet   Coefficients for Image Denoising,"Supratim Gupta, Susant Kumar Panigrahi","Thresholding of Curvelet Coefficients, for image denoising, drains out subtle signal component in noise subspace. This produces ringing artifacts near edges and granular effect in the denoised image. We found the noise sensitivity of Curvelet phases (in contrast to their magnitude) reduces with higher noise level. Thus, we preserved the phase of the coefficients below threshold at coarser scale and estimated their magnitude by Joint Bilateral Filtering (JBF) technique from the thresholded and noisy coefficients. In the finest scale, we apply Bilateral Filter (BF) to keep edge information. Further, the Guided Image Filter (GIF) is applied on the reconstructed image to localize the edges and to preserve the small image details and textures. The lower noise sensitivity of Curvelet phase at higher noise strength accelerate the performance of proposed method over several state-of-theart techniques and provides comparable outcome at lower noise levels.",2018-04-16T06:13:50Z,2018-04-16T06:13:50Z,http://arxiv.org/abs/1804.05512v1,http://arxiv.org/pdf/1804.05512v1,eess.IV
Sparse Representation of 3D Images for Piecewise Dimensionality   Reduction with High Quality Reconstruction,"Laura Rebollo-Neira, Daniel Whitehouse","Sparse representation of 3D images is considered within the context of data reduction. The goal is to produce high quality approximations of 3D images using fewer elementary components than the number of intensity points in the 3D array. This is achieved by means of a highly redundant dictionary and a dedicated pursuit strategy especially designed for low memory requirements. The benefit of the proposed framework is illustrated in the first instance by demonstrating the gain in dimensionality reduction obtained when approximating true color images as very thin 3D arrays, instead of performing an independent channel by channel approximation. The full power of the approach is further exemplified by producing high quality approximations of hyper-spectral images with a reduction of up to 371 times the number of data points in the representation.",2018-07-29T22:46:09Z,2019-06-10T20:36:04Z,http://arxiv.org/abs/1807.11116v2,http://arxiv.org/pdf/1807.11116v2,eess.IV
Fast Super-resolution 3D SAR Imaging Using an Unfolded Deep Network,"Jingkun Gao, Bin Deng, Yuliang Qin, Hongqiang Wang, Xiang Li","For 3D Synthetic Aperture Radar (SAR) imaging, one typical approach is to achieve the cross-track 1D focusing for each range-azimuth pixel after obtaining a stack of 2D complex-valued images. The cross-track focusing is the main difficulty as its aperture length is limited and the antenna positions are usually non-uniformly distributed. Sparsity regularization methods are widely used to tackle these problems. However, these methods are of obvious limitations. The most well-known ones are their heavy computational burdens and unsatisfied stabilities. In this letter, an efficient deep network-based cross-track imaging method is proposed. When trained, the imaging process, i.e. the forward propagation of the network, is made up of simple matrix-vector calculations and element-wise nonlinearity operations, which significantly speed up the imaging. Also, we find that the deep network is of good robustness against noise and model errors. Comprehensive simulations and experiments have been carried out, and the superiority of the proposed method can be clearly seen.",2018-08-27T01:34:37Z,2018-08-27T01:34:37Z,http://arxiv.org/abs/1808.08658v1,http://arxiv.org/pdf/1808.08658v1,"eess.SP, eess.IV"
Inertia Sensor Aided Alignment for Burst Pipeline in Low Light   Conditions,"Shuang Zhang, Robert L. Stevenson","Merging short-exposure frames can provide an image with reduced noise in low light conditions. However, how best to align images before merging is an open problem. To improve the performance of alignment, we propose an inertia-sensor aided algorithm for smartphone burst photography, which takes rotation and out-plane relative movement into account. To calculate homography between frames, a three by three rotation matrix is calculated from gyro data recorded by smartphone inertia sensor and three-dimensional translation vector are estimated by matched feature points detected from two frames. The rotation matrix and translations are combined to form the initial guess of homography. An unscented Kalman filter is utilized to provide a more accurate homography estimation. We have tested the algorithm on a variety of different scenes with different camera relative motions. We compare the proposed method to benchmark single-image and multi-image denoising methods with favorable results.",2018-11-05T20:04:23Z,2018-11-05T20:04:23Z,http://arxiv.org/abs/1811.02013v1,http://arxiv.org/pdf/1811.02013v1,eess.IV
A Generalized Structured Low-Rank Matrix Completion Algorithm for MR   Image Recovery,"Yue Hu, Xiaohan Liu, Mathews Jacob","Recent theory of mapping an image into a structured low-rank Toeplitz or Hankel matrix has become an effective method to restore images. In this paper, we introduce a generalized structured low-rank algorithm to recover images from their undersampled Fourier coefficients using infimal convolution regularizations. The image is modeled as the superposition of a piecewise constant component and a piecewise linear component. The Fourier coefficients of each component satisfy an annihilation relation, which results in a structured Toeplitz matrix, respectively. We exploit the low-rank property of the matrices to formulate a combined regularized optimization problem. In order to solve the problem efficiently and to avoid the high memory demand resulting from the large-scale Toeplitz matrices, we introduce a fast and memory efficient algorithm based on the half-circulant approximation of the Toeplitz matrix. We demonstrate our algorithm in the context of single and multi-channel MR images recovery. Numerical experiments indicate that the proposed algorithm provides improved recovery performance over the state-of-the-art approaches.",2018-11-27T02:31:29Z,2018-11-27T02:31:29Z,http://arxiv.org/abs/1811.10778v1,http://arxiv.org/pdf/1811.10778v1,eess.IV
Block-level Double JPEG Compression Detection for Image Forgery   Localization,"Vinay Verma, Deepak Singh, Nitin Khanna","Forged images have a ubiquitous presence in today's world due to ease of availability of image manipulation tools. In this letter, we propose a deep learning-based novel approach which utilizes the inherent relationship between DCT coefficient histograms and corresponding quantization step sizes to distinguish between original and forged regions in a JPEG image, based on the detection of single and double compressed blocks, without fully decompressing the JPEG image. We consider a diverse set of 1,120 quantization matrices collected in a recent study as compared to standard 100 quantization matrices for training, testing, and creating realistic forgeries. In particular, we carefully design the input to DenseNet with a specific combination of quantization step sizes and the respective histograms for a JPEG block. Using this input to learn the compression artifacts produces state-of-the-art results for the detection of single and double compressed blocks of sizes $256 \times 256$ and gives better results for smaller blocks of sizes $128 \times 128$ and $64 \times 64$. Consequently, improved forgery localization performances are obtained on realistic forged images. Also, in the case of test blocks compressed with completely different quantization matrices as compared to matrices used in training, the proposed method outperforms the current state-of-the-art.",2020-03-20T17:00:36Z,2020-03-20T17:00:36Z,http://arxiv.org/abs/2003.09393v1,http://arxiv.org/pdf/2003.09393v1,eess.IV
Adaptive Compressive Sampling for Mid-infrared Spectroscopic Imaging,"Mahsa Lotfollahi, Nguyen Tran, Sebastian Berisha, Chalapathi Gajjela, Zhu Han, David Mayerich, Rohith Reddy","Minfrared spectroscopic imaging (MIRSI) is an emerging class of label-free, biochemically quantitative technologies targeting digital histopathology. Conventional histopathology relies on chemical stains that alter tissue color. This approach is qualitative, often making histopathologic examination subjective and difficult to quantify. MIRSI addresses these challenges through quantitative and repeatable imaging that leverages native molecular contrast. Fourier transform infrared (FTIR) imaging, the best-known MIRSI technology, has two challenges that have hindered its widespread adoption: data collection speed and spatial resolution. Recent technological breakthroughs, such as photothermal MIRSI, provide an order of magnitude improvement in spatial resolution. However, this comes at the cost of acquisition speed, which is impractical for clinical tissue samples. This paper introduces an adaptive compressive sampling technique to reduce hyperspectral data acquisition time by an order of magnitude by leveraging spectral and spatial sparsity. This method identifies the most informative spatial and spectral features, integrates a fast tensor completion algorithm to reconstruct megapixel-scale images, and demonstrates speed advantages over FTIR imaging while providing spatial resolutions comparable to new photothermal approaches.",2020-08-02T21:23:35Z,2022-07-25T12:24:33Z,http://arxiv.org/abs/2008.00566v3,http://arxiv.org/pdf/2008.00566v3,"eess.IV, eess.SP"
Displaced Sensor Automotive Radar Imaging,"Guohua Wang, Kumar Vijay Mishra","Displaced automotive sensor imaging exploits joint processing of the data acquired from multiple radar units, each of which may have limited individual resources, to enhance the localization accuracy. Prior works either consider perfect synchronization among the sensors, employ single antenna radars, entail high processing cost, or lack performance analyses. Contrary to these works, we develop a displaced multiple-input multiple-output (MIMO) frequency-modulated continuous-wave (FMCW) radar signal model under coarse synchronization with only frame-level alignment. We derive Bayesian performance bounds for the common automotive radar processing modes such as point-cloud-based fusion as well as raw-signal-based non-coherent and coherent imaging. For the non-coherent mode, which offers a compromise between low computational load and improved localization, we exploit the block sparsity of range profiles for signal reconstruction to avoid direct computational imaging with massive data. For the high-resolution coherent imaging, we develop a method that automatically estimates the synchronization error and performs displaced radar imaging by exploiting sparsity-driven recovery models. Our extensive numerical experiments demonstrate these advantages. Our proposed non-coherent processing of displaced MIMO FMCW radars improves position estimation by an order over the conventional point-cloud fusion.",2020-10-06T04:58:46Z,2020-10-06T04:58:46Z,http://arxiv.org/abs/2010.04085v1,http://arxiv.org/pdf/2010.04085v1,"eess.SP, eess.IV"
A Reduced Codebook and Re-Interpolation Approach for Enhancing Quality   in Chroma Subsampling,"Kuo-Liang Chung, Chen-Wei Kao","Prior to encoding RGB full-color images or Bayer color filter array (CFA) images, chroma subsampling is a necessary and crucial step at the server side. In this paper, we first propose a flow diagram approach to analyze the coordinate-inconsistency (CI) problem and the upsampling process-inconsistency (UPI) problem existing in the traditional and state-of-the-art chroma subsampling methods under the current coding environment. In addition, we explain why the two problems degrade the quality of the reconstructed images. Next, we propose a reduced codebook and re-interpolation (RCRI) approach to solve the two problems for enhancing the quality of the reconstructed images. Based on the testing RGB full-color images and Bayer CFA images, the comprehensive experimental results demonstrated at least 1.4 dB and 2.4 dB quality improvement effects, respectively, of our RCRI approach against the CI and UPI problems for the traditional and state-of-the-art chroma subsampling methods.",2021-01-04T06:26:19Z,2021-01-04T06:26:19Z,http://arxiv.org/abs/2101.00796v1,http://arxiv.org/pdf/2101.00796v1,eess.IV
Underwater Image Enhancement based on Deep Learning and Image Formation   Model,"Xuelei Chen, Pin Zhang, Lingwei Quan, Chao Yi, Cunyue Lu","Underwater robots play an important role in oceanic geological exploration, resource exploitation, ecological research, and other fields. However, the visual perception of underwater robots is affected by various environmental factors. The main challenge now is that images captured by underwater robots are color-distorted. The hue of underwater images tends to be close to green and blue. In addition, the contrast is low and the details are fuzzy. In this paper, a new underwater image enhancement algorithm based on deep learning and image formation model is proposed. Experimental results show that the advantages of the proposed method are that it eliminates the influence of underwater environmental factors, enriches the color, enhances details, achieves higher scores in PSNR and SSIM metrics, and helps feature key-point point matching get better results. Another significant advantage is that its computation speed is much faster than other methods.",2021-01-04T14:03:50Z,2021-01-07T14:45:42Z,http://arxiv.org/abs/2101.00991v2,http://arxiv.org/pdf/2101.00991v2,eess.IV
Distributed Parallel Image Signal Extrapolation Framework using Message   Passing Interface,"Jürgen Seiler, André Kaup","This paper introduces a framework for distributed parallel image signal extrapolation. Since high-quality image signal processing often comes along with a high computational complexity, a parallel execution is desirable. The proposed framework allows for the application of existing image signal extrapolation algorithms without the need to modify them for a parallel processing. The unaltered application of existing algorithms is achieved by dividing input images into overlapping tiles which are distributed to compute nodes via Message Passing Interface. In order to keep the computational overhead low, a novel image tiling algorithm is proposed. Using this algorithm, a nearly optimum tiling is possible at a very small processing time. For showing the efficacy of the framework, it is used for parallelizing a high-complexity extrapolation algorithm. Simulation results show that the proposed framework has no negative impact on extrapolation quality while at the same time offering good scaling behavior on compute clusters.",2022-07-01T07:05:41Z,2022-07-01T07:05:41Z,http://arxiv.org/abs/2207.00238v1,http://arxiv.org/pdf/2207.00238v1,eess.IV
Stabilised Inverse Flowline Evolution for Anisotropic Image Sharpening,"Kristina Schaefer, Joachim Weickert","The central limit theorem suggests Gaussian convolution as a generic blur model for images. Since Gaussian convolution is equivalent to homogeneous diffusion filtering, one way to deblur such images is to diffuse them backwards in time. However, backward diffusion is highly ill-posed. Thus, it requires stabilisation in the model as well as highly sophisticated numerical algorithms. Moreover, sharpening is often only desired across image edges but not along them, since it may cause very irregular contours. This creates the need to model a stabilised anisotropic backward evolution and to devise an appropriate numerical algorithm for this ill-posed process.   We address both challenges. First we introduce stabilised inverse flowline evolution (SIFE) as an anisotropic image sharpening flow. Outside extrema, its partial differential equation (PDE) is backward parabolic in gradient direction. Interestingly, it is sufficient to stabilise it in extrema by imposing a zero flow there. We show that morphological derivatives - which are not common in the numerics of PDEs - are ideal for the numerical approximation of SIFE: They effortlessly approximate directional derivatives in gradient direction. Our scheme adapts one-sided morphological derivatives to the underlying image structure. It allows to progress in subpixel accuracy and enables us to prove stability properties. Our experiments show that SIFE allows nonflat steady states and outperforms other sharpening flows.",2022-07-20T09:43:13Z,2022-07-20T09:43:13Z,http://arxiv.org/abs/2207.09779v1,http://arxiv.org/pdf/2207.09779v1,eess.IV
Edge-Aware Autoencoder Design for Real-Time Mixture-of-Experts Image   Compression,"Elvira Fleig, Jonas Geistert, Erik Bochinski, Rolf Jongebloed, Thomas Sikora","Steered-Mixtures-of-Experts (SMoE) models provide sparse, edge-aware representations, applicable to many use-cases in image processing. This includes denoising, super-resolution and compression of 2D- and higher dimensional pixel data. Recent works for image compression indicate that compression of images based on SMoE models can provide competitive performance to the state-of-the-art. Unfortunately, the iterative model-building process at the encoder comes with excessive computational demands. In this paper we introduce a novel edge-aware Autoencoder (AE) strategy designed to avoid the time-consuming iterative optimization of SMoE models. This is done by directly mapping pixel blocks to model parameters for compression, in spirit similar to recent works on ""unfolding"" of algorithms, while maintaining full compatibility to the established SMoE framework. With our plug-in AE encoder, we achieve a quantum-leap in performance with encoder run-time savings by a factor of 500 to 1000 with even improved image reconstruction quality. For image compression the plug-in AE encoder has real-time properties and improves RD-performance compared to our previous works.",2022-07-25T17:03:56Z,2022-07-25T17:03:56Z,http://arxiv.org/abs/2207.12348v1,http://arxiv.org/pdf/2207.12348v1,eess.IV
DiffeoRaptor: Diffeomorphic Inter-modal Image Registration using RaPTOR,"Nima Masoumi, Hassan Rivaz, M. Omair Ahmad, Yiming Xiao","Purpose: Diffeomorphic image registration is essential in many medical imaging applications. Several registration algorithms of such type have been proposed, but primarily for intra-contrast alignment. Currently, efficient inter-modal/contrast diffeomorphic registration, which is vital in numerous applications, remains a challenging task. Methods: We proposed a novel inter-modal/contrast registration algorithm that leverages Robust PaTch-based cOrrelation Ratio (RaPTOR) metric to allow inter-modal/contrast image alignment and bandlimited geodesic shooting demonstrated in Fourier Approximated Lie Algebras (FLASH) algorithm for fast diffeomorphic registration. Results: The proposed algorithm, named DiffeoRaptor, was validated with three public databases for the tasks of brain and abdominal image registration while comparing the results against three state-of-the-art techniques, including FLASH, NiftyReg, and Symmetric image normalization (SyN). Conclusions: Our results demonstrated that DiffeoRaptor offered comparable or better registration performance in terms of registration accuracy. Moreover, DiffeoRaptor produces smoother deformations than SyN in inter-modal and contrast registration. The code for DiffeoRaptor is publicly available at https://github.com/nimamasoumi/DiffeoRaptor.",2022-09-12T20:35:05Z,2022-09-12T20:35:05Z,http://arxiv.org/abs/2209.05600v1,http://arxiv.org/pdf/2209.05600v1,eess.IV
Spatio-spectral Image Reconstruction Using Non-local Filtering,"Frank Sippel, Jürgen Seiler, André Kaup","In many image processing tasks it occurs that pixels or blocks of pixels are missing or lost in only some channels. For example during defective transmissions of RGB images, it may happen that one or more blocks in one color channel are lost. Nearly all modern applications in image processing and transmission use at least three color channels, some of the applications employ even more bands, for example in the infrared and ultraviolet area of the light spectrum. Typically, only some pixels and blocks in a subset of color channels are distorted. Thus, other channels can be used to reconstruct the missing pixels, which is called spatio-spectral reconstruction. Current state-of-the-art methods purely rely on the local neighborhood, which works well for homogeneous regions. However, in high-frequency regions like edges or textures, these methods fail to properly model the relationship between color bands. Hence, this paper introduces non-local filtering for building a linear regression model that describes the inter-band relationship and is used to reconstruct the missing pixels. Our novel method is able to increase the PSNR on average by 2 dB and yields visually much more appealing images in high-frequency regions.",2022-09-16T12:29:17Z,2022-09-16T12:29:17Z,http://arxiv.org/abs/2209.07890v1,http://arxiv.org/pdf/2209.07890v1,eess.IV
Unsupervised particle sorting for cryo-EM using probabilistic PCA,"Gili Weiss-Dicker, Amitay Eldar, Yoel Shkolinsky, Tamir Bendory","Single-particle cryo-electron microscopy (cryo-EM) is a leading technology to resolve the structure of molecules. Early in the process, the user detects potential particle images in the raw data. Typically, there are many false detections as a result of high levels of noise and contamination. Currently, removing the false detections requires human intervention to sort the hundred thousands of images. We propose a statistically-established unsupervised algorithm to remove non-particle images. We model the particle images as a union of low-dimensional subspaces, assuming non-particle images are arbitrarily scattered in the high-dimensional space. The algorithm is based on an extension of the probabilistic PCA framework to robustly learn a non-linear model of union of subspaces. This provides a flexible model for cryo-EM data, and allows to automatically remove images that correspond to pure noise and contamination. Numerical experiments corroborate the effectiveness of the sorting algorithm.",2022-10-23T18:21:51Z,2023-03-07T08:52:37Z,http://arxiv.org/abs/2210.12811v2,http://arxiv.org/pdf/2210.12811v2,"eess.IV, eess.SP"
Low Rank Quaternion Matrix Completion Based on Quaternion QR   Decomposition and Sparse Regularizer,"Juan Han, Liqiao Yang, Kit Ian Kou, Jifei Miao, Lizhi Liu","Matrix completion is one of the most challenging problems in computer vision. Recently, quaternion representations of color images have achieved competitive performance in many fields. Because it treats the color image as a whole, the coupling information between the three channels of the color image is better utilized. Due to this, low-rank quaternion matrix completion (LRQMC) algorithms have gained considerable attention from researchers. In contrast to the traditional quaternion matrix completion algorithms based on quaternion singular value decomposition (QSVD), we propose a novel method based on quaternion Qatar Riyal decomposition (QQR). In the first part of the paper, a novel method for calculating an approximate QSVD based on iterative QQR is proposed (CQSVD-QQR), whose computational complexity is lower than that of QSVD. The largest $r \ (r>0)$ singular values of a given quaternion matrix can be computed by using CQSVD-QQR. Then, we propose a new quaternion matrix completion method based on CQSVD-QQR which combines low-rank and sparse priors of color images. Experimental results on color images and color medical images demonstrate that our model outperforms those state-of-the-art methods.",2022-11-23T09:15:14Z,2022-11-23T09:15:14Z,http://arxiv.org/abs/2211.12793v1,http://arxiv.org/pdf/2211.12793v1,eess.IV
FPGA-Based In-Vivo Calcium Image Decoding for Closed-Loop Feedback   Applications,"Zhe Chen, Garrett J. Blair, Chengdi Cao, Jim Zhou, Daniel Aharoni, Peyman Golshani, Hugh T. Blair, Jason Cong","Miniaturized calcium imaging is an emerging neural recording technique that has been widely used for monitoring neural activity on a large scale at a specific brain region of rats or mice. Most existing calcium-image analysis pipelines operate offline. This results in long processing latency, making it difficult to realize closed-loop feedback stimulation for brain research. In recent work, we have proposed an FPGA-based real-time calcium image processing pipeline for closed-loop feedback applications. It can perform real-time calcium image motion correction, enhancement, fast trace extraction, and real-time decoding from extracted traces. Here, we extend this work by proposing a variety of neural network based methods for real-time decoding and evaluate the tradeoff among these decoding methods and accelerator designs. We introduced the implementation of the neural network based decoders on the FPGA, and showed their speedup against the implementation on the ARM processor. Our FPGA implementation enables the real-time calcium image decoding with sub-ms processing latency for closed-loop feedback applications.",2022-12-09T09:12:26Z,2023-04-17T00:53:07Z,http://arxiv.org/abs/2212.04736v2,http://arxiv.org/pdf/2212.04736v2,eess.IV
Lightweight Image Inpainting by Stripe Window Transformer with Joint   Attention to CNN,"Tsung-Jung Liu, Bo-Wei Chen, Kuan-Hsien Liu","Image inpainting is an important task in computer vision. As admirable methods are presented, the inpainted image is getting closer to reality. However, the result is still not good enough in the reconstructed texture and structure based on human vision. Although recent advances in computer hardware have enabled the development of larger and more complex models, there is still a need for lightweight models that can be used by individuals and small-sized institutions. Therefore, we propose a lightweight model that combines a specialized transformer with a traditional convolutional neural network (CNN). Furthermore, we have noticed most researchers only consider three primary colors (RGB) in inpainted images, but we think this is not enough. So we propose a new loss function to intensify color details. Extensive experiments on commonly seen datasets (Places2 and CelebA) validate the efficacy of our proposed model compared with other state-of-the-art methods.   Index Terms: HSV color space, image inpainting, joint attention, stripe window, transformer",2023-01-02T08:07:50Z,2023-08-24T01:54:59Z,http://arxiv.org/abs/2301.00553v2,http://arxiv.org/pdf/2301.00553v2,eess.IV
Multi-Task Learning for Screen Content Image Coding,"Rashid Zamanshoar Heris, Ivan V. Bajić","With the rise of remote work and collaboration, compression of screen content images (SCI) is becoming increasingly important. While there are efficient codecs for natural images, as well as codecs for purely-synthetic images, those SCIs that contain both synthetic and natural content pose a particular challenge. In this paper, we propose a learning-based image coding model developed for such SCIs. By training an encoder to provide a latent representation suitable for two tasks -- input reconstruction and synthetic/natural region segmentation -- we create an effective SCI image codec whose strong performance is verified through experiments. Once trained, the second task (segmentation) need not be used; the codec still benefits from the segmentation-friendly latent representation.",2023-02-03T21:43:08Z,2023-02-03T21:43:08Z,http://arxiv.org/abs/2302.02014v1,http://arxiv.org/pdf/2302.02014v1,eess.IV
Structural Similarity: When to Use Deep Generative Models on Imbalanced   Image Dataset Augmentation,"Chenqi Guo, Fabian Benitez-Quiroz, Qianli Feng, Aleix Martinez","Improving the performance on an imbalanced training set is one of the main challenges in nowadays Machine Learning. One way to augment and thus re-balance the image dataset is through existing deep generative models, like class-conditional Generative Adversarial Networks (cGAN) or Diffusion Models by synthesizing images on each of the tail-class. Our experiments on imbalanced image dataset classification show that, the validation accuracy improvement with such re-balancing method is related to the image similarity between different classes. Thus, to quantify this image dataset class similarity, we propose a measurement called Super-Sub Class Structural Similarity (SSIM-supSubCls) based on Structural Similarity (SSIM). A deep generative model data augmentation classification (GM-augCls) pipeline is also provided to verify this metric correlates with the accuracy enhancement. We further quantify the relationship between them, discovering that the accuracy improvement decays exponentially with respect to SSIM-supSubCls values.",2023-03-08T19:42:34Z,2023-03-08T19:42:34Z,http://arxiv.org/abs/2303.04854v1,http://arxiv.org/pdf/2303.04854v1,eess.IV
MF-JMoDL-Net: A Deep Network for Azimuth Undersampling Pattern Design   and Ambiguity Suppression for Sparse SAR Imaging,"Yuwei Wu, Zhe Zhang, Xiaolan Qiu, Yao Zhao, Weidong Yu","repetition frequency (PRF). Given the system complexity and resource constraints, it is often difficult to achieve high imaging performance and low ambiguity without compromising the swath. In this paper, we propose a joint optimization framework for sparse strip SAR imaging algorithms and azimuth undersampling patterns based on a deep convolutional neural network, combined with matched filter (MF) approximate measurement operators and inverse MF operators, referred to as MF-JMoDL-Net, for sparse SAR imaging methods. Compared with conventional sparse SAR imaging, MF-JMoDL-Net enables us to alleviate the limitations imposed by PRF. In the proposed scheme, joint and continuous optimization of azimuth undersampling patterns and convolutional neural network parameters are implemented to suppress azimuth ambiguity and enhance sparse SAR imaging quality. Experiments and comparisons under various conditions demonstrate the effectiveness and superiority of the proposed framework in imaging results.",2023-03-20T01:46:39Z,2023-03-20T01:46:39Z,http://arxiv.org/abs/2303.10823v1,http://arxiv.org/pdf/2303.10823v1,eess.SP
Lightweight High-Performance Blind Image Quality Assessment,"Zhanxuan Mei, Yun-Cheng Wang, Xingze He, Yong Yan, C. -C. Jay Kuo","Blind image quality assessment (BIQA) is a task that predicts the perceptual quality of an image without its reference. Research on BIQA attracts growing attention due to the increasing amount of user-generated images and emerging mobile applications where reference images are unavailable. The problem is challenging due to the wide range of content and mixed distortion types. Many existing BIQA methods use deep neural networks (DNNs) to achieve high performance. However, their large model sizes hinder their applicability to edge or mobile devices. To meet the need, a novel BIQA method with a small model, low computational complexity, and high performance is proposed and named ""GreenBIQA"" in this work. GreenBIQA includes five steps: 1) image cropping, 2) unsupervised representation generation, 3) supervised feature selection, 4) distortion-specific prediction, and 5) regression and decision ensemble. Experimental results show that the performance of GreenBIQA is comparable with that of state-of-the-art deep-learning (DL) solutions while demanding a much smaller model size and significantly lower computational complexity.",2023-03-23T06:04:57Z,2023-03-23T06:04:57Z,http://arxiv.org/abs/2303.13057v1,http://arxiv.org/pdf/2303.13057v1,eess.IV
Regularized Shallow Image Prior for Electrical Impedance Tomography,"Zhe Liu, Zhou Chen, Qi Wang, Sheng Zhang, Yunjie Yang","Untrained Neural Network Prior (UNNP) based algorithms have gained increasing popularity in tomographic imaging, as they offer superior performance compared to hand-crafted priors and do not require training. UNNP-based methods usually rely on deep architectures which are known for their excellent feature extraction ability compared to shallow ones. Contrary to common UNNP-based approaches, we propose a regularized shallow image prior method that combines UNNP with hand-crafted prior for Electrical Impedance Tomography (EIT). Our approach employs a 3-layer Multi-Layer Perceptron (MLP) as the UNNP in regularizing 2D and 3D EIT inversion. We demonstrate the influence of two typical hand-crafted regularizations when representing the conductivity distribution with shallow MLPs. We show considerably improved EIT image quality compared to conventional regularization algorithms, especially in structure preservation. The results suggest that combining the shallow image prior and the hand-crafted regularization can achieve similar performance to the Deep Image Prior (DIP) but with less architectural dependency and complexity of the neural network.",2023-03-30T22:30:32Z,2023-03-30T22:30:32Z,http://arxiv.org/abs/2303.17735v1,http://arxiv.org/pdf/2303.17735v1,eess.IV
Image Segmentation For Improved Lossless Screen Content Compression,"Shabhrish Reddy Uddehal, Tilo Strutz, Hannah Och, André Kaup","In recent years, it has been found that screen content images (SCI) can be effectively compressed based on appropriate probability modelling and suitable entropy coding methods such as arithmetic coding. The key objective is determining the best probability distribution for each pixel position. This strategy works particularly well for images with synthetic (textual) content. However, usually screen content images not only consist of synthetic but also pictorial (natural) regions. These images require diverse models of probability distributions to be optimally compressed. One way to achieve this goal is to separate synthetic and natural regions. This paper proposes a segmentation method that identifies natural regions enabling better adaptive treatment. It supplements a compression method known as Soft Context Formation (SCF) and operates as a pre-processing step. If at least one natural segment is found within the SCI, it is split into two sub images (natural and synthetic parts), and the process of modelling and coding is performed separately for both. For SCIs with natural regions, the proposed method achieves a bit-rate reduction of up to 11.6% and 1.52% with respect to HEVC and the previous version of the SCF.",2023-05-10T09:09:01Z,2023-05-10T09:09:01Z,http://arxiv.org/abs/2305.05996v1,http://arxiv.org/pdf/2305.05996v1,eess.IV
VoDEx: a Python library for time annotation and management of volumetric   functional imaging data,"Anna Nadtochiy, Peter Luu, Scott E. Fraser, Thai V. Truong","Summary: In functional imaging studies, accurately synchronizing the time course of experimental manipulations and stimulus presentations with resulting imaging data is crucial for analysis. Current software tools lack such functionality, requiring manual processing of the experimental and imaging data, which is error-prone and potentially non-reproducible. We present VoDEx, an open-source Python library that streamlines the data management and analysis of functional imaging data. VoDEx synchronizes the experimental timeline and events (eg. presented stimuli, recorded behavior) with imaging data. VoDEx provides tools for logging and storing the timeline annotation, and enables retrieval of imaging data based on specific time-based and manipulation-based experimental conditions.   Availability and Implementation: VoDEx is an open-source Python library and can be installed via the ""pip install"" command. It is released under a BSD license, and its source code is publicly accessible on GitHub https://github.com/LemonJust/vodex. A graphical interface is available as a napari-vodex plugin, which can be installed through the napari plugins menu or using ""pip install."" The source code for the napari plugin is available on GitHub https://github.com/LemonJust/napari-vodex.",2023-05-11T05:00:16Z,2023-05-11T05:00:16Z,http://arxiv.org/abs/2305.07438v1,http://arxiv.org/pdf/2305.07438v1,q-bio.QM
A Review of the Recent Developments in the Fabrication Processes of CMOS   Image Sensors for Smartphones,"Kirthika Nahalingam, Linda P. B. Katehi","CMOS Image Sensors are experiencing significant growth due to their capabilities to be integrated in smartphones with refined image quality. One of the major contributions to the growth of image sensors is the innovation brought about in their fabrication processes. This paper presents a detailed review of the different fabrication processes of the CMOS Image Sensors and its impact on the image quality of smartphone pictures. Fabrication of CMOS image sensors using wafer bonding technologies such as Through Silicon Vias and CuCu hybrid bonding along with their experimental results are discussed. A 2 layer architecture of photodiode and pixel transistors has adopted the 3D sequential integration, by which the wafers are bonded together one after the other in the fabrication process. Electrical characteristics and reliability test results are presented for the former two fabrication processes and the improvements in the pixels performance such as conversion gain, quantum efficiency, full well capacity and dynamic range for the 2 layer architecture are discussed.",2023-06-08T16:40:28Z,2023-06-08T16:40:28Z,http://arxiv.org/abs/2306.05339v1,http://arxiv.org/pdf/2306.05339v1,eess.SP
Enhanced Residual SwinV2 Transformer for Learned Image Compression,"Yongqiang Wang, Feng Liang, Haisheng Fu, Jie Liang, Haipeng Qin, Junzhe Liang","Recently, the deep learning technology has been successfully applied in the field of image compression, leading to superior rate-distortion performance. However, a challenge of many learning-based approaches is that they often achieve better performance via sacrificing complexity, which making practical deployment difficult. To alleviate this issue, in this paper, we propose an effective and efficient learned image compression framework based on an enhanced residual Swinv2 transformer. To enhance the nonlinear representation of images in our framework, we use a feature enhancement module that consists of three consecutive convolutional layers. In the subsequent coding and hyper coding steps, we utilize a SwinV2 transformer-based attention mechanism to process the input image. The SwinV2 model can help to reduce model complexity while maintaining high performance. Experimental results show that the proposed method achieves comparable performance compared to some recent learned image compression methods on Kodak and Tecnick datasets, and outperforms some traditional codecs including VVC. In particular, our method achieves comparable results while reducing model complexity by 56% compared to these recent methods.",2023-08-23T01:50:54Z,2023-08-23T01:50:54Z,http://arxiv.org/abs/2308.11864v1,http://arxiv.org/pdf/2308.11864v1,eess.IV
ORMIR_XCT: A Python package for high resolution peripheral quantitative   computed tomography image processing,"Michael T. Kuczynski, Nathan J. Neeteson, Kathryn S. Stok, Andrew J. Burghardt, Michelle A. Espinosa Hernandez, Jared Vicory, Justin J. Tse, Pholpat Durongbhan, Serena Bonaretti, Andy Kin On Wong, Steven K. Boyd, Sarah L. Manske","High resolution peripheral quantitative computed tomography (HR-pQCT) is an imaging technique capable of imaging trabecular bone in-vivo. HR-pQCT has a wide range of applications, primarily focused on bone to improve our understanding of musculoskeletal diseases, assess epidemiological associations, and evaluate the effects of pharmaceutical interventions. Processing HR-pQCT images has largely been supported using the scanner manufacturer scripting language (Image Processing Language, IPL, Scanco Medical). However, by expanding image processing workflows outside of the scanner manufacturer software environment, users have the flexibility to apply more advanced mathematical techniques and leverage modern software packages to improve image processing. The ORMIR_XCT Python package was developed to reimplement some existing IPL workflows and provide an open and reproducible package allowing for the development of advanced HR-pQCT data processing workflows.",2023-09-08T21:27:11Z,2023-09-08T21:27:11Z,http://arxiv.org/abs/2309.04602v1,http://arxiv.org/pdf/2309.04602v1,q-bio.QM
Bloch Equation Enables Physics-informed Neural Network in Parametric   Magnetic Resonance Imaging,"Qingrui Cai, Liuhong Zhu, Jianjun Zhou, Chen Qian, Di Guo, Xiaobo Qu","Magnetic resonance imaging (MRI) is an important non-invasive imaging method in clinical diagnosis. Beyond the common image structures, parametric imaging can provide the intrinsic tissue property thus could be used in quantitative evaluation. The emerging deep learning approach provides fast and accurate parameter estimation but still encounters the lack of network interpretation and enough training data. Even with a large amount of training data, the mismatch between the training and target data may introduce errors. Here, we propose one way that solely relies on the target scanned data and does not need a pre-defined training database. We provide a proof-of-concept that embeds the physical rule of MRI, the Bloch equation, into the loss of physics-informed neural network (PINN). PINN enables learning the Bloch equation, estimating the T2 parameter, and generating a series of physically synthetic data. Experimental results are conducted on phantom and cardiac imaging to demonstrate its potential in quantitative MRI.",2023-09-21T03:53:33Z,2023-09-21T03:53:33Z,http://arxiv.org/abs/2309.11763v1,http://arxiv.org/pdf/2309.11763v1,eess.IV
Hessian-based Similarity Metric for Multimodal Medical Image   Registration,"Mohammadreza Eskandari, Houssem-Eddine Gueziri, D. Louis Collins","One of the fundamental elements of both traditional and certain deep learning medical image registration algorithms is measuring the similarity/dissimilarity between two images. In this work, we propose an analytical solution for measuring similarity between two different medical image modalities based on the Hessian of their intensities. First, assuming a functional dependence between the intensities of two perfectly corresponding patches, we investigate how their Hessians relate to each other. Secondly, we suggest a closed-form expression to quantify the deviation from this relationship, given arbitrary pairs of image patches. We propose a geometrical interpretation of the new similarity metric and an efficient implementation for registration. We demonstrate the robustness of the metric to intensity nonuniformities using synthetic bias fields. By integrating the new metric in an affine registration framework, we evaluate its performance for MRI and ultrasound registration in the context of image-guided neurosurgery using target registration error and computation time.",2023-10-06T04:40:07Z,2023-10-06T04:40:07Z,http://arxiv.org/abs/2310.04009v1,http://arxiv.org/pdf/2310.04009v1,eess.IV
Compression Ratio Learning and Semantic Communications for Video Imaging,"Bowen Zhang, Zhijin Qin, Geoffrey Ye Li","Camera sensors have been widely used in intelligent robotic systems. Developing camera sensors with high sensing efficiency has always been important to reduce the power, memory, and other related resources. Inspired by recent success on programmable sensors and deep optic methods, we design a novel video compressed sensing system with spatially-variant compression ratios, which achieves higher imaging quality than the existing snapshot compressed imaging methods with the same sensing costs. In this article, we also investigate the data transmission methods for programmable sensors, where the performance of communication systems is evaluated by the reconstructed images or videos rather than the transmission of sensor data itself. Usually, different reconstruction algorithms are designed for applications in high dynamic range imaging, video compressive sensing, or motion debluring. This task-aware property inspires a semantic communication framework for programmable sensors. In this work, a policy-gradient based reinforcement learning method is introduced to achieve the explicit trade-off between the compression (or transmission) rate and the image distortion. Numerical results show the superiority of the proposed methods over existing baselines.",2023-10-10T01:45:13Z,2023-10-10T01:45:13Z,http://arxiv.org/abs/2310.06246v1,http://arxiv.org/pdf/2310.06246v1,eess.IV
"Development and application of SEM/EDS in biological, biomedical &   nanotechnological research",Aniruddha Acharya,"This comprehensive review discusses the development of scanning electron microscopy and the application of this technology in different fields such as biology, nanobiotechnology and biomedical science. Besides being a tool for high resolution imaging of surface or topography, the technology is coupled with analytical techniques such as energy dispersive spectroscopy for elemental mapping. Since the commercialization of the technology, it has developed manifold and currently very high-resolution nano scale imaging is possible by this technology. The development of FIB-SEM has allowed three-dimensional imaging of materials while the development of cryostage allows imaging of hydrated biological samples. Though variable pressure or environmental SEM can be used for imaging hydrated samples, they cannot capture a high-resolution image. SBEM and ATUM-SEM has automated the sampling process while improved and more powerful software along with user-friendly computer interface has made image analysis faster and more reliable. This review presents one of the most widely used analytical techniques used across the globe for scientific investigation. The power and potential of SEM is expanding with the development of accessory technology.",2023-11-01T17:14:52Z,2023-11-01T17:14:52Z,http://arxiv.org/abs/2311.00667v1,http://arxiv.org/pdf/2311.00667v1,q-bio.QM
Joint Deep Image Restoration and Unsupervised Quality Assessment,"Hakan Emre Gedik, Abhinau K. Venkataramanan, Alan C. Bovik","Deep learning techniques have revolutionized the fields of image restoration and image quality assessment in recent years. While image restoration methods typically utilize synthetically distorted training data for training, deep quality assessment models often require expensive labeled subjective data. However, recent studies have shown that activations of deep neural networks trained for visual modeling tasks can also be used for perceptual quality assessment of images. Following this intuition, we propose a novel attention-based convolutional neural network capable of simultaneously performing both image restoration and quality assessment. We achieve this by training a JPEG deblocking network augmented with ""quality attention"" maps and demonstrating state-of-the-art deblocking accuracy, achieving a high correlation of predicted quality with human opinion scores.",2023-11-27T23:32:20Z,2023-11-27T23:32:20Z,http://arxiv.org/abs/2311.16372v1,http://arxiv.org/pdf/2311.16372v1,eess.IV
Digital twin-assisted three-dimensional electrical capacitance   tomography for multiphase flow imaging,"Shengnan Wang, Yi Li, Zhou Chen, Yunjie Yang","Three-dimensional electrical capacitance tomography (3D-ECT) has shown promise for visualizing industrial multiphase flows. However, existing 3D-ECT approaches suffer from limited imaging resolution and lack assessment metrics, hampering their effectiveness in quantitative multiphase flow imaging. This paper presents a digital twin (DT)-assisted 3D-ECT, aiming to overcome these limitations and enhance our understanding of multiphase flow dynamics. The DT framework incorporates a 3D fluid-electrostatic field coupling model (3D-FECM) that digitally represents the physical 3D-ECT system, which enables us to simulate real multiphase flows and generate a comprehensive virtual multiphase flow 3D imaging dataset. Additionally, the framework includes a deep neural network named 3D deep back projection (3D-DBP), which learns multiphase flow features from the virtual dataset and enables more accurate 3D flow imaging in the real world. The DT-assisted 3D-ECT was validated through virtual and physical experiments, demonstrating superior image quality, noise robustness and computational efficiency compared to conventional 3D-ECT approaches. This research contributes to developing accurate and reliable 3D-ECT techniques and their implementation in multiphase flow systems across various industries.",2023-12-22T07:46:46Z,2023-12-22T07:46:46Z,http://arxiv.org/abs/2312.14496v1,http://arxiv.org/pdf/2312.14496v1,eess.IV
Proximal Gradient Descent Unfolding Dense-spatial Spectral-attention   Transformer for Compressive Spectral Imaging,"Ziyan Chen, Jing Cheng","The Coded Aperture Snapshot Spectral Compressive Imaging (CASSI) system modulates three-dimensional hyperspectral images into two-dimensional compressed images in a single exposure. Subsequently, three-dimensional hyperspectral images (HSI) can be reconstructed from the two-dimensional compressed measurements using reconstruction algorithms. Among these methods, deep unfolding techniques have demonstrated excellent performance, with RDLUF-MixS^2 achieving the best reconstruction results. However, RDLUF-MixS^2 requires extensive training time, taking approximately 14 days to train RDLUF-MixS^2-9stg on a single RTX 3090 GPU, making it computationally expensive. Furthermore, RDLUF-MixS^2 performs poorly on real data, resulting in significant artifacts in the reconstructed images. In this study, we introduce the Dense-spatial Spectral-attention Transformer (DST) into the Proximal Gradient Descent Unfolding Framework (PGDUF), creating a novel approach called Proximal Gradient Descent Unfolding Dense-spatial Spectral-attention Transformer (PGDUDST). Compared to RDLUF-MixS^2, PGDUDST not only surpasses the network reconstruction performance limit of RDLUF-MixS^2 but also achieves faster convergence. PGDUDST requires only 58% of the training time of RDLUF-MixS^2-9stg to achieve comparable reconstruction results. Additionally, PGDUDST significantly alleviates the artifact issues caused by RDLUF-MixS^2 in real experimental data, demonstrating superior performance and producing clearer reconstructed images.",2023-12-25T05:51:10Z,2023-12-25T05:51:10Z,http://arxiv.org/abs/2312.16237v1,http://arxiv.org/pdf/2312.16237v1,eess.SP
"Effective stripe artefact removal by a variational method: application   to light-sheet microscopy, FIB-SEM and remote sensing images","Niklas Rottmayer, Claudia Redenbach, Florian Fahrbach","Light-sheet fluorescence microscopy (LSFM) is used to capture volume images of biological specimens. It offers high contrast deep inside densely fluorescence labelled samples, fast acquisition speed and minimal harmful effects on the sample. However, LSFM images often show strong stripe artifacts originating from light-matter interactions. We propose a robust variational method suitable for removing stripes which outperforms existing methods and offers flexibility through two adjustable parameters. This tool is widely applicable to improve visual quality as well as facilitate downstream processing and analysis of images acquired on systems that do not provide hardware-based destriping methods. An evaluation of methods is performed on LSFM, focused ion beam scanning electron microscopy (FIB-SEM) and remote sensing data, supplemented by synthetic LSFM images. The latter is obtained by simulating the imaging process on virtual samples.",2024-01-25T14:58:47Z,2024-04-04T10:55:04Z,http://arxiv.org/abs/2401.14220v2,http://arxiv.org/pdf/2401.14220v2,eess.IV
Microwave lymphedema assessment using deep learning with contour   assisted backprojection,"Yuyi Chang, Nithin Sugavanam, Emre Ertin","We present a method for early detection of lymphatic fluid accumulation in lymphedema patients based on microwave imaging of the limb volume across an air gap. The proposed algorithm uses contour information of the imaged limb surface to approximate the wave propagation velocity locally to solve the eikonal equation for implementing the adjoint imaging operator. This modified backprojection algorithm results in focused imagery close to the limb surface where lymphatic fluid accumulation presents itself. Next, a deep neural network based on U-Net architecture is employed to identify the location and extent of the lymphatic fluid. Simulation studies with various upper and lower arm profiles compare the focusing performance of the proposed contour assisted backprojection imaging with the baseline imaging approach that assumes homogeneous media. The empirical results of the simulation experiments show that the proposed imaging method significantly improves the ability of the deepnet model to identify the location and the volume of the excess fluid in the limb.",2024-01-26T16:04:43Z,2024-03-13T17:58:08Z,http://arxiv.org/abs/2401.14970v2,http://arxiv.org/pdf/2401.14970v2,"eess.SP, eess.IV"
Saliency-aware End-to-end Learned Variable-Bitrate 360-degree Image   Compression,"Oguzhan Gungordu, A. Murat Tekalp","Effective compression of 360$^\circ$ images, also referred to as omnidirectional images (ODIs), is of high interest for various virtual reality (VR) and related applications. 2D image compression methods ignore the equator-biased nature of ODIs and fail to address oversampling near the poles, leading to inefficient compression when applied to ODI. We present a new learned saliency-aware 360$^\circ$ image compression architecture that prioritizes bit allocation to more significant regions, considering the unique properties of ODIs. By assigning fewer bits to less important regions, significant data size reduction can be achieved while maintaining high visual quality in the significant regions. To the best of our knowledge, this is the first study that proposes an end-to-end variable-rate model to compress 360$^\circ$ images leveraging saliency information. The results show significant bit-rate savings over the state-of-the-art learned and traditional ODI compression methods at similar perceptual visual quality.",2024-02-14T00:13:39Z,2024-02-14T00:13:39Z,http://arxiv.org/abs/2402.08862v1,http://arxiv.org/pdf/2402.08862v1,eess.IV
GreenSaliency: A Lightweight and Efficient Image Saliency Detection   Method,"Zhanxuan Mei, Yun-Cheng Wang, C. -C. Jay Kuo","Image saliency detection is crucial in understanding human gaze patterns from visual stimuli. The escalating demand for research in image saliency detection is driven by the growing necessity to incorporate such techniques into various computer vision tasks and to understand human visual systems. Many existing image saliency detection methods rely on deep neural networks (DNNs) to achieve good performance. However, the high computational complexity associated with these approaches impedes their integration with other modules or deployment on resource-constrained platforms, such as mobile devices. To address this need, we propose a novel image saliency detection method named GreenSaliency, which has a small model size, minimal carbon footprint, and low computational complexity. GreenSaliency can be a competitive alternative to the existing deep-learning-based (DL-based) image saliency detection methods with limited computation resources. GreenSaliency comprises two primary steps: 1) multi-layer hybrid feature extraction and 2) multi-path saliency prediction. Experimental results demonstrate that GreenSaliency achieves comparable performance to the state-of-the-art DL-based methods while possessing a considerably smaller model size and significantly reduced computational complexity.",2024-03-30T05:46:20Z,2024-03-30T05:46:20Z,http://arxiv.org/abs/2404.00253v1,http://arxiv.org/pdf/2404.00253v1,eess.IV
STAIC regularization for spatio-temporal image reconstruction,"Deepak G Skariah, Muthuvel Arigovindan",We propose a regularization-based image restoration scheme for 2D images recorded over time (2D+t). We design an infimal convolution-based regularization function which we call spatio-temporal Adaptive Infimal Convolution (STAIC) regularization. We formulate the infimal convolution in the form of an additive decomposition of the 2D+t image such that the extent of spatial and temporal smoothing is controlled in a spatially and temporally varying manner. This makes the regularization adaptable to the local characteristics of the motion leading to an improved ability to handle noise. We also develop a minimization method for image reconstruction by using the proposed form of regularization. We demonstrate the effectiveness of the proposed regularization using TIRF images recorded over time and compare with some selected existing regularizations.,2024-04-07T20:49:26Z,2024-04-07T20:49:26Z,http://arxiv.org/abs/2404.05070v1,http://arxiv.org/pdf/2404.05070v1,eess.IV
Transformer-Based Local Feature Matching for Multimodal Image   Registration,"Remi Delaunay, Ruisi Zhang, Filipe C. Pedrosa, Navid Feizi, Dianne Sacco, Rajni Patel, Jayender Jagadeesan","Ultrasound imaging is a cost-effective and radiation-free modality for visualizing anatomical structures in real-time, making it ideal for guiding surgical interventions. However, its limited field-of-view, speckle noise, and imaging artifacts make it difficult to interpret the images for inexperienced users. In this paper, we propose a new 2D ultrasound to 3D CT registration method to improve surgical guidance during ultrasound-guided interventions. Our approach adopts a dense feature matching method called LoFTR to our multimodal registration problem. We learn to predict dense coarse-to-fine correspondences using a Transformer-based architecture to estimate a robust rigid transformation between a 2D ultrasound frame and a CT scan. Additionally, a fully differentiable pose estimation method is introduced, optimizing LoFTR on pose estimation error during training. Experiments conducted on a multimodal dataset of ex vivo porcine kidneys demonstrate the method's promising results for intraoperative, trackerless ultrasound pose estimation. By mapping 2D ultrasound frames into the 3D CT volume space, the method provides intraoperative guidance, potentially improving surgical workflows and image interpretation.",2024-04-25T17:49:28Z,2024-04-25T17:49:28Z,http://arxiv.org/abs/2404.16802v1,http://arxiv.org/pdf/2404.16802v1,eess.IV
Compressive Sensing Imaging Using Caustic Lens Mask Generated by   Periodic Perturbation in a Ripple Tank,"Doğan Tunca Arık, Asaf Behzat Şahin, Özgün Ersoy","Terahertz imaging shows significant potential across diverse fields, yet the cost-effectiveness of multi-pixel imaging equipment remains an obstacle for many researchers. To tackle this issue, the utilization of single-pixel imaging arises as a lower-cost option, however, the data collection process necessary for reconstructing images is time-consuming. Compressive Sensing offers a promising solution by enabling image generation with fewer measurements than required by Nyquist's theorem, yet long processing times remain an issue, especially for large-sized images. Our proposed solution to this issue involves using caustic lens effect induced by perturbations in a ripple tank as a sampling mask. The dynamic characteristics of the ripple tank introduce randomness into the sampling process, thereby reducing measurement time through exploitation of the inherent sparsity of THz band signals. In this study, a Convolutional Neural Network was used to conduct target classification, based on the distinctive signal patterns obtained via the caustic lens mask. The suggested classifier obtained a 95.16 % accuracy rate in differentiating targets resembling Latin letters.",2024-05-01T09:27:49Z,2024-05-01T09:27:49Z,http://arxiv.org/abs/2405.00407v1,http://arxiv.org/pdf/2405.00407v1,eess.SP
